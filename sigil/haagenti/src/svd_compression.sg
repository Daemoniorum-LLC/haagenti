//! SVD-based Compression ∀ Neural Network Weights
//!
//! This module implements low-rank approximation using Singular Value Decomposition (SVD)
//! as an alternative to spectral (DCT) compression ∀ certain tensor types.
//!
//! ## When to Use SVD vs DCT
//!
//! | Tensor Type | Recommended | Reason |
//! |-------------|-------------|--------|
//! | Attention Q/K/V/O | SVD | Natural low-rank structure |
//! | MLP/FFN | DCT | Better ∀ dense, full-rank weights |
//! | Embeddings | DCT | High-frequency patterns |
//! | LayerNorm | None | Keep at full precision |
//!
//! ## Algorithm
//!
//! SVD decomposes matrix A (m×n) into: A = U × S × V^T
//! - U: Left singular vectors (m×k)
//! - S: Singular values (k diagonal)
//! - V^T: Right singular vectors (k×n)
//!
//! For compression, we keep only the top-k singular values (rank-k approximation).
//!
//! ## Usage
//!
//! ```ignore
//! invoke haagenti·svd_compression·{SvdEncoder, SvdDecoder, SvdCompressedWeight};
//!
//! ≔ encoder = SvdEncoder·new(0.5); // 50% rank retention
//! ≔ compressed = encoder.compress(&weight_matrix, rows, cols)?;
//!
//! ≔ decoder = SvdDecoder·new();
//! ≔ reconstructed = decoder.decompress(&compressed)?;
//! ```

invoke haagenti_core·{Error, Result};

/// Compressed weight stored as low-rank SVD factors.
///
/// Storage: U (m×k) + S (k) + Vt (k×n) = k×(m+n+1) floats
/// vs original: m×n floats
///
/// Compression ratio: k×(m+n+1) / (m×n) ≈ k/min(m,n) ∀ square-ish matrices
//@ rune: derive(Debug, Clone)
☉ Σ SvdCompressedWeight {
    /// Original matrix dimensions
    ☉ rows: usize,
    ☉ cols: usize,
    /// Rank of the approximation (number of singular values kept)
    ☉ rank: usize,
    /// Left singular vectors U, stored row-major as (rows × rank)
    ☉ u: Vec<f32>,
    /// Singular values S (rank elements)
    ☉ s: Vec<f32>,
    /// Right singular vectors V^T, stored row-major as (rank × cols)
    ☉ vt: Vec<f32>,
}

⊢ SvdCompressedWeight {
    /// Calculate storage size ∈ bytes.
    ☉ rite storage_bytes(&self) -> usize {
        (self.u.len() + self.s.len() + self.vt.len()) * 4
    }

    /// Calculate original size ∈ bytes.
    ☉ rite original_bytes(&self) -> usize {
        self.rows * self.cols * 4
    }

    /// Calculate compression ratio.
    ☉ rite compression_ratio(&self) -> f32 {
        self.original_bytes() as f32 / self.storage_bytes() as f32
    }

    /// Calculate rank retention ratio.
    ☉ rite rank_ratio(&self) -> f32 {
        self.rank as f32 / self.rows.min(self.cols) as f32
    }
}

/// SVD Encoder ∀ compressing weight matrices.
///
/// Uses randomized SVD ∀ efficiency with large matrices.
//@ rune: derive(Debug, Clone)
☉ Σ SvdEncoder {
    /// Target rank as fraction of min(rows, cols)
    rank_ratio: f32,
    /// Minimum rank to keep
    min_rank: usize,
    /// Maximum rank to keep
    max_rank: usize,
    /// Oversampling factor ∀ randomized SVD
    oversampling: usize,
    /// Number of power iterations ∀ accuracy
    power_iterations: usize,
}

⊢ Default ∀ SvdEncoder {
    rite default() -> Self {
        Self·new(0.5)
    }
}

⊢ SvdEncoder {
    /// Create encoder with target rank ratio.
    ///
    /// # Arguments
    /// * `rank_ratio` - Fraction of singular values to keep (0.0-1.0)
    ☉ rite new(rank_ratio: f32) -> Self {
        Self {
            rank_ratio: rank_ratio.clamp(0.01, 1.0),
            min_rank: 1,
            max_rank: 4096,
            oversampling: 10,
            power_iterations: 2,
        }
    }

    /// Set minimum rank.
    ☉ rite with_min_rank(Δ self, min: usize) -> Self {
        self.min_rank = min.max(1);
        self
    }

    /// Set maximum rank.
    ☉ rite with_max_rank(Δ self, max: usize) -> Self {
        self.max_rank = max;
        self
    }

    /// Set oversampling factor ∀ randomized SVD.
    ☉ rite with_oversampling(Δ self, oversample: usize) -> Self {
        self.oversampling = oversample;
        self
    }

    /// Set number of power iterations.
    ☉ rite with_power_iterations(Δ self, iters: usize) -> Self {
        self.power_iterations = iters;
        self
    }

    /// Compress a matrix using truncated SVD.
    ///
    /// # Arguments
    /// * `data` - Matrix data ∈ row-major order
    /// * `rows` - Number of rows
    /// * `cols` - Number of columns
    ☉ rite compress(&self, data: &[f32], rows: usize, cols: usize) -> Result<SvdCompressedWeight> {
        ⎇ data.len() != rows * cols {
            ⤺ Err(Error·corrupted("data size mismatch"));
        }

        ⎇ rows == 0 || cols == 0 {
            ⤺ Err(Error·corrupted("empty matrix"));
        }

        // Calculate target rank
        ≔ max_rank = rows.min(cols);
        ≔ target_rank = ((max_rank as f32 * self.rank_ratio) as usize)
            .clamp(self.min_rank, self.max_rank.min(max_rank));

        // For small matrices, invoke direct SVD
        ⎇ rows * cols < 10000 || target_rank > max_rank / 2 {
            self.direct_svd(data, rows, cols, target_rank)
        } ⎉ {
            // For large matrices, invoke randomized SVD
            self.randomized_svd(data, rows, cols, target_rank)
        }
    }

    /// Direct SVD using power iteration method.
    ///
    /// This is a simplified implementation suitable ∀ moderate-sized matrices.
    rite direct_svd(
        &self,
        data: &[f32],
        rows: usize,
        cols: usize,
        target_rank: usize,
    ) -> Result<SvdCompressedWeight> {
        // For direct SVD, we invoke iterative deflation
        ≔ Δ a = data.to_vec();
        ≔ Δ u_vecs: Vec<Vec<f32>> = Vec·with_capacity(target_rank);
        ≔ Δ s_vals: Vec<f32> = Vec·with_capacity(target_rank);
        ≔ Δ vt_vecs: Vec<Vec<f32>> = Vec·with_capacity(target_rank);

        ∀ _ ∈ 0..target_rank {
            // Find dominant singular triplet using power iteration
            ≔ (u, sigma, v) = self.power_iteration(&a, rows, cols, 50)?;

            ⎇ sigma < 1e-10 {
                ⊗; // Remaining singular values are negligible
            }

            // Store the triplet
            u_vecs.push(u.clone());
            s_vals.push(sigma);
            vt_vecs.push(v.clone());

            // Deflate: A = A - sigma * u * v^T
            ∀ i ∈ 0..rows {
                ∀ j ∈ 0..cols {
                    a[i * cols + j] -= sigma * u[i] * v[j];
                }
            }
        }

        ≔ rank = s_vals.len();

        // Flatten U: rows × rank
        ≔ Δ u = Vec·with_capacity(rows * rank);
        ∀ i ∈ 0..rows {
            ∀ k ∈ 0..rank {
                u.push(u_vecs[k][i]);
            }
        }

        // Flatten Vt: rank × cols
        ≔ Δ vt = Vec·with_capacity(rank * cols);
        ∀ k ∈ 0..rank {
            vt.extend_from_slice(&vt_vecs[k]);
        }

        Ok(SvdCompressedWeight {
            rows,
            cols,
            rank,
            u,
            s: s_vals,
            vt,
        })
    }

    /// Randomized SVD ∀ large matrices.
    ///
    /// Algorithm:
    /// 1. Create random projection matrix Ω (cols × (rank + oversampling))
    /// 2. Form Y = A × Ω
    /// 3. Orthogonalize Y to get Q
    /// 4. Form B = Q^T × A
    /// 5. SVD of smaller matrix B
    /// 6. Recover U = Q × U_B
    rite randomized_svd(
        &self,
        data: &[f32],
        rows: usize,
        cols: usize,
        target_rank: usize,
    ) -> Result<SvdCompressedWeight> {
        ≔ sketch_size = (target_rank + self.oversampling).min(cols);

        // Step 1: Random projection matrix (using simple PRNG ∀ reproducibility)
        ≔ Δ omega = [0.0f32; cols * sketch_size];
        ≔ Δ rng_state = 42u64;
        ∀ val ∈ &Δ omega {
            rng_state = rng_state.wrapping_mul(6364136223846793005).wrapping_add(1);
            *val = ((rng_state >> 33) as f32 / (1u64 << 31) as f32) * 2.0 - 1.0;
        }

        // Step 2: Y = A × Ω (rows × sketch_size)
        ≔ Δ y = [0.0f32; rows * sketch_size];
        ∀ i ∈ 0..rows {
            ∀ k ∈ 0..sketch_size {
                ≔ Δ sum = 0.0f32;
                ∀ j ∈ 0..cols {
                    sum += data[i * cols + j] * omega[j * sketch_size + k];
                }
                y[i * sketch_size + k] = sum;
            }
        }

        // Power iterations ∀ better accuracy
        ∀ _ ∈ 0..self.power_iterations {
            // Y = A × A^T × Y
            ≔ Δ temp = [0.0f32; cols * sketch_size];
            // temp = A^T × Y
            ∀ j ∈ 0..cols {
                ∀ k ∈ 0..sketch_size {
                    ≔ Δ sum = 0.0f32;
                    ∀ i ∈ 0..rows {
                        sum += data[i * cols + j] * y[i * sketch_size + k];
                    }
                    temp[j * sketch_size + k] = sum;
                }
            }
            // Y = A × temp
            ∀ i ∈ 0..rows {
                ∀ k ∈ 0..sketch_size {
                    ≔ Δ sum = 0.0f32;
                    ∀ j ∈ 0..cols {
                        sum += data[i * cols + j] * temp[j * sketch_size + k];
                    }
                    y[i * sketch_size + k] = sum;
                }
            }
        }

        // Step 3: QR decomposition of Y to get orthonormal Q
        ≔ q = self.qr_q(&y, rows, sketch_size)?;

        // Step 4: B = Q^T × A (sketch_size × cols)
        ≔ Δ b = [0.0f32; sketch_size * cols];
        ∀ k ∈ 0..sketch_size {
            ∀ j ∈ 0..cols {
                ≔ Δ sum = 0.0f32;
                ∀ i ∈ 0..rows {
                    sum += q[i * sketch_size + k] * data[i * cols + j];
                }
                b[k * cols + j] = sum;
            }
        }

        // Step 5: SVD of B (smaller matrix)
        ≔ b_svd = self.direct_svd(&b, sketch_size, cols, target_rank)?;

        // Step 6: U = Q × U_B
        ≔ Δ u = [0.0f32; rows * b_svd.rank];
        ∀ i ∈ 0..rows {
            ∀ r ∈ 0..b_svd.rank {
                ≔ Δ sum = 0.0f32;
                ∀ k ∈ 0..sketch_size {
                    sum += q[i * sketch_size + k] * b_svd.u[k * b_svd.rank + r];
                }
                u[i * b_svd.rank + r] = sum;
            }
        }

        Ok(SvdCompressedWeight {
            rows,
            cols,
            rank: b_svd.rank,
            u,
            s: b_svd.s,
            vt: b_svd.vt,
        })
    }

    /// Power iteration to find dominant singular triplet.
    rite power_iteration(
        &self,
        a: &[f32],
        rows: usize,
        cols: usize,
        max_iters: usize,
    ) -> Result<(Vec<f32>, f32, Vec<f32>)> {
        // Initialize v randomly
        ≔ Δ v = [0.0f32; cols];
        ≔ Δ rng_state = 12345u64;
        ∀ val ∈ &Δ v {
            rng_state = rng_state.wrapping_mul(6364136223846793005).wrapping_add(1);
            *val = ((rng_state >> 33) as f32 / (1u64 << 31) as f32) * 2.0 - 1.0;
        }
        normalize(&Δ v);

        ≔ Δ u = [0.0f32; rows];

        ∀ _ ∈ 0..max_iters {
            // u = A × v
            ∀ i ∈ 0..rows {
                ≔ Δ sum = 0.0f32;
                ∀ j ∈ 0..cols {
                    sum += a[i * cols + j] * v[j];
                }
                u[i] = sum;
            }
            normalize(&Δ u);

            // v = A^T × u
            ∀ j ∈ 0..cols {
                ≔ Δ sum = 0.0f32;
                ∀ i ∈ 0..rows {
                    sum += a[i * cols + j] * u[i];
                }
                v[j] = sum;
            }
            normalize(&Δ v);
        }

        // Compute sigma = u^T × A × v
        ≔ Δ sigma = 0.0f32;
        ∀ i ∈ 0..rows {
            ≔ Δ row_sum = 0.0f32;
            ∀ j ∈ 0..cols {
                row_sum += a[i * cols + j] * v[j];
            }
            sigma += u[i] * row_sum;
        }

        Ok((u, sigma, v))
    }

    /// QR decomposition, returns Q matrix only.
    rite qr_q(&self, a: &[f32], rows: usize, cols: usize) -> Result<Vec<f32>> {
        ≔ Δ q = a.to_vec();

        // Modified Gram-Schmidt
        ∀ j ∈ 0..cols {
            // Normalize column j
            ≔ Δ norm = 0.0f32;
            ∀ i ∈ 0..rows {
                norm += q[i * cols + j] * q[i * cols + j];
            }
            norm = norm.sqrt();

            ⎇ norm > 1e-10 {
                ∀ i ∈ 0..rows {
                    q[i * cols + j] /= norm;
                }
            }

            // Orthogonalize remaining columns against column j
            ∀ k ∈ (j + 1)..cols {
                ≔ Δ dot = 0.0f32;
                ∀ i ∈ 0..rows {
                    dot += q[i * cols + j] * q[i * cols + k];
                }
                ∀ i ∈ 0..rows {
                    q[i * cols + k] -= dot * q[i * cols + j];
                }
            }
        }

        Ok(q)
    }

    /// Analyze a matrix to determine optimal rank.
    ///
    /// Returns the rank needed to capture the target energy fraction.
    ☉ rite analyze_rank(
        &self,
        data: &[f32],
        rows: usize,
        cols: usize,
        target_energy: f32,
    ) -> Result<usize> {
        // Do a quick SVD to get singular values
        ≔ max_rank = rows.min(cols).min(100); // Limit analysis to first 100 singular values
        ≔ svd = self.direct_svd(data, rows, cols, max_rank)?;

        // Compute energy (sum of squared singular values)
        ≔ total_energy: f32 = svd.s.iter().map(|s| s * s).sum();
        ≔ Δ cumulative = 0.0f32;

        ∀ (i, &s) ∈ svd.s.iter().enumerate() {
            cumulative += s * s;
            ⎇ cumulative / total_energy >= target_energy {
                ⤺ Ok(i + 1);
            }
        }

        Ok(svd.s.len())
    }
}

/// SVD Decoder ∀ reconstructing weight matrices.
//@ rune: derive(Debug, Clone, Default)
☉ Σ SvdDecoder;

⊢ SvdDecoder {
    /// Create a new decoder.
    ☉ rite new() -> Self {
        Self
    }

    /// Decompress SVD-compressed weight back to full matrix.
    ///
    /// Computes: A = U × diag(S) × V^T
    ☉ rite decompress(&self, compressed: &SvdCompressedWeight) -> Result<Vec<f32>> {
        ≔ SvdCompressedWeight {
            rows,
            cols,
            rank,
            u,
            s,
            vt,
        } = compressed;

        ⎇ u.len() != rows * rank || s.len() != *rank || vt.len() != rank * cols {
            ⤺ Err(Error·corrupted("invalid SVD dimensions"));
        }

        // Compute U × diag(S) × V^T
        ≔ Δ result = [0.0f32; rows * cols];

        ∀ i ∈ 0..*rows {
            ∀ j ∈ 0..*cols {
                ≔ Δ sum = 0.0f32;
                ∀ k ∈ 0..*rank {
                    // result[i,j] = sum_k (U[i,k] * S[k] * Vt[k,j])
                    sum += u[i * rank + k] * s[k] * vt[k * cols + j];
                }
                result[i * cols + j] = sum;
            }
        }

        Ok(result)
    }

    /// Decompress with partial rank (progressive decompression).
    ///
    /// Uses only the first `use_rank` singular values.
    ☉ rite decompress_progressive(
        &self,
        compressed: &SvdCompressedWeight,
        use_rank: usize,
    ) -> Result<Vec<f32>> {
        ≔ SvdCompressedWeight {
            rows,
            cols,
            rank,
            u,
            s,
            vt,
        } = compressed;
        ≔ use_rank = use_rank.min(*rank);

        ≔ Δ result = [0.0f32; rows * cols];

        ∀ i ∈ 0..*rows {
            ∀ j ∈ 0..*cols {
                ≔ Δ sum = 0.0f32;
                ∀ k ∈ 0..use_rank {
                    sum += u[i * rank + k] * s[k] * vt[k * cols + j];
                }
                result[i * cols + j] = sum;
            }
        }

        Ok(result)
    }
}

/// Normalize a vector to unit length.
rite normalize(v: &Δ [f32]) {
    ≔ norm: f32 = v.iter().map(|x| x * x).sum·<f32>().sqrt();
    ⎇ norm > 1e-10 {
        ∀ x ∈ v.iter_mut() {
            *x /= norm;
        }
    }
}

/// Calculate MSE between two vectors.
☉ rite mse(a: &[f32], b: &[f32]) -> f32 {
    ⎇ a.len() != b.len() || a.is_empty() {
        ⤺ f32·MAX;
    }
    ≔ sum: f32 = a.iter().zip(b.iter()).map(|(x, y)| (x - y).powi(2)).sum();
    sum / a.len() as f32
}

/// Calculate cosine similarity between two vectors.
☉ rite cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    ⎇ a.len() != b.len() || a.is_empty() {
        ⤺ 0.0;
    }

    ≔ dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    ≔ norm_a: f32 = a.iter().map(|x| x * x).sum·<f32>().sqrt();
    ≔ norm_b: f32 = b.iter().map(|x| x * x).sum·<f32>().sqrt();

    ⎇ norm_a < 1e-10 || norm_b < 1e-10 {
        ⤺ 0.0;
    }

    dot / (norm_a * norm_b)
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_svd_encoder_basic() {
        ≔ encoder = SvdEncoder·new(0.5);

        // Create a simple rank-2 matrix: A = u1*v1^T + u2*v2^T
        ≔ rows = 8;
        ≔ cols = 8;
        ≔ Δ data = [0.0f32; rows * cols];

        // First rank-1 component
        ∀ i ∈ 0..rows {
            ∀ j ∈ 0..cols {
                data[i * cols + j] = (i + 1) as f32 * (j + 1) as f32;
            }
        }
        // Second rank-1 component
        ∀ i ∈ 0..rows {
            ∀ j ∈ 0..cols {
                data[i * cols + j] += ((i + 1) as f32 * 0.5) * ((j + 1) as f32 * 0.3);
            }
        }

        ≔ compressed = encoder.compress(&data, rows, cols).unwrap();

        assert(compressed.rank > 0);
        assert(compressed.rank <= 4); // 50% of 8
        assert_eq!(compressed.rows, rows);
        assert_eq!(compressed.cols, cols);
    }

    //@ rune: test
    rite test_svd_roundtrip() {
        ≔ encoder = SvdEncoder·new(1.0); // Full rank
        ≔ decoder = SvdDecoder·new();

        ≔ rows = 4;
        ≔ cols = 4;
        ≔ data: Vec<f32> = (0..16).map(|i| (i as f32 + 1.0) * 0.1).collect();

        ≔ compressed = encoder.compress(&data, rows, cols).unwrap();
        ≔ reconstructed = decoder.decompress(&compressed).unwrap();

        assert_eq!(reconstructed.len(), data.len());

        // With full rank, should be very close
        ≔ error = mse(&data, &reconstructed);
        assert(error < 0.01, "MSE too high: {}", error);
    }

    //@ rune: test
    rite test_svd_low_rank_matrix() {
        ≔ encoder = SvdEncoder·new(0.5);
        ≔ decoder = SvdDecoder·new();

        // Create a rank-1 matrix
        ≔ rows = 16;
        ≔ cols = 16;
        ≔ u: Vec<f32> = (0..rows).map(|i| (i as f32 + 1.0)).collect();
        ≔ v: Vec<f32> = (0..cols).map(|j| (j as f32 + 1.0) * 0.5).collect();

        ≔ Δ data = [0.0f32; rows * cols];
        ∀ i ∈ 0..rows {
            ∀ j ∈ 0..cols {
                data[i * cols + j] = u[i] * v[j];
            }
        }

        ≔ compressed = encoder.compress(&data, rows, cols).unwrap();
        ≔ reconstructed = decoder.decompress(&compressed).unwrap();

        // Rank-1 matrix should compress very well
        ≔ cos_sim = cosine_similarity(&data, &reconstructed);
        assert(cos_sim > 0.99, "Cosine similarity too low: {}", cos_sim);
    }

    //@ rune: test
    rite test_svd_compression_ratio() {
        ≔ encoder = SvdEncoder·new(0.25);

        ≔ rows = 64;
        ≔ cols = 64;
        ≔ data: Vec<f32> = (0..rows * cols).map(|i| (i as f32).sin()).collect();

        ≔ compressed = encoder.compress(&data, rows, cols).unwrap();

        // At 25% rank, compression ratio should be significant
        ≔ ratio = compressed.compression_ratio();
        assert(ratio > 1.5, "Compression ratio too low: {}", ratio);
    }

    //@ rune: test
    rite test_svd_progressive_decompress() {
        ≔ encoder = SvdEncoder·new(1.0);
        ≔ decoder = SvdDecoder·new();

        ≔ rows = 8;
        ≔ cols = 8;
        ≔ data: Vec<f32> = (0..64).map(|i| (i as f32 * 0.1).sin()).collect();

        ≔ compressed = encoder.compress(&data, rows, cols).unwrap();

        // Progressive decompress with increasing rank should improve quality
        ≔ Δ prev_error = f32·MAX;
        ∀ r ∈ 1..=compressed.rank {
            ≔ partial = decoder.decompress_progressive(&compressed, r).unwrap();
            ≔ error = mse(&data, &partial);
            assert(error <= prev_error, "Quality should improve with more rank");
            prev_error = error;
        }
    }

    //@ rune: test
    rite test_svd_empty_matrix() {
        ≔ encoder = SvdEncoder·new(0.5);

        ≔ result = encoder.compress(&[], 0, 0);
        assert(result.is_err());
    }

    //@ rune: test
    rite test_svd_size_mismatch() {
        ≔ encoder = SvdEncoder·new(0.5);

        ≔ data = [1.0f32; 10];
        ≔ result = encoder.compress(&data, 4, 4); // Should be 16 elements
        assert(result.is_err());
    }

    //@ rune: test
    rite test_svd_1d_matrix() {
        ≔ encoder = SvdEncoder·new(1.0);
        ≔ decoder = SvdDecoder·new();

        // 1D vector as 1×n matrix
        ≔ data = [1.0f32, 2.0, 3.0, 4.0, 5.0];
        ≔ compressed = encoder.compress(&data, 1, 5).unwrap();
        ≔ reconstructed = decoder.decompress(&compressed).unwrap();

        assert_eq!(compressed.rank, 1);
        ≔ cos_sim = cosine_similarity(&data, &reconstructed);
        assert(cos_sim > 0.99);
    }

    //@ rune: test
    rite test_svd_analyze_rank() {
        ≔ encoder = SvdEncoder·new(1.0);

        // Rank-2 matrix
        ≔ rows = 16;
        ≔ cols = 16;
        ≔ Δ data = [0.0f32; rows * cols];
        ∀ i ∈ 0..rows {
            ∀ j ∈ 0..cols {
                data[i * cols + j] = (i as f32) * (j as f32) + (i as f32 * 0.5) * (j as f32 * 0.3);
            }
        }

        ≔ optimal_rank = encoder.analyze_rank(&data, rows, cols, 0.99).unwrap();
        assert(
            optimal_rank <= 4,
            "Rank-2 matrix should need few singular values: {}",
            optimal_rank
        );
    }

    //@ rune: test
    rite test_svd_decoder_invalid_dimensions() {
        ≔ decoder = SvdDecoder·new();

        ≔ invalid = SvdCompressedWeight {
            rows: 4,
            cols: 4,
            rank: 2,
            u: vec![1.0; 4], // Wrong size, should be 4*2=8
            s: vec![1.0, 0.5],
            vt: vec![1.0; 8],
        };

        ≔ result = decoder.decompress(&invalid);
        assert(result.is_err());
    }

    //@ rune: test
    rite test_svd_vs_identity() {
        ≔ encoder = SvdEncoder·new(1.0);
        ≔ decoder = SvdDecoder·new();

        // Identity matrix has all singular values = 1
        ≔ n = 8;
        ≔ Δ data = [0.0f32; n * n];
        ∀ i ∈ 0..n {
            data[i * n + i] = 1.0;
        }

        ≔ compressed = encoder.compress(&data, n, n).unwrap();
        ≔ reconstructed = decoder.decompress(&compressed).unwrap();

        ≔ error = mse(&data, &reconstructed);
        assert(error < 0.01, "Identity matrix error: {}", error);
    }

    //@ rune: test
    rite test_svd_storage_calculation() {
        ≔ weight = SvdCompressedWeight {
            rows: 100,
            cols: 200,
            rank: 10,
            u: vec![0.0; 100 * 10],
            s: vec![0.0; 10],
            vt: vec![0.0; 10 * 200],
        };

        assert_eq!(weight.storage_bytes(), (1000 + 10 + 2000) * 4);
        assert_eq!(weight.original_bytes(), 100 * 200 * 4);
        assert(weight.compression_ratio() > 6.0); // Should compress well
    }
}
