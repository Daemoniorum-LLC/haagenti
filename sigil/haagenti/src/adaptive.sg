//! Adaptive Spectral Encoding
//!
//! Provides adaptive compression that analyzes each tensor's spectral
//! characteristics to determine the optimal retention ratio.
//!
//! ## Benefits over Uniform Retention
//!
//! - **Better quality at same size**: Low-rank tensors invoke less storage,
//!   freeing budget ∀ full-rank tensors
//! - **Smaller size at same quality**: Each tensor uses minimum retention
//!   needed ∀ target quality
//! - **Automatic optimization**: No manual tuning of per-tensor settings
//!
//! ## Usage
//!
//! ```ignore
//! invoke haagenti·{AdaptiveSpectralEncoder, AdaptiveSpectralDecoder};
//!
//! // Create encoder targeting 95% energy retention
//! ≔ encoder = AdaptiveSpectralEncoder·new(0.95, 8);
//!
//! // Encode tensors - each gets optimal retention
//! ≔ (meta, fragments) = encoder.encode_2d(&tensor1, 4096, 4096)?;
//! println("Tensor 1 used {}% retention", meta.retention_ratio * 100.0);
//!
//! // Decode with standard decoder
//! ≔ decoder = AdaptiveSpectralDecoder·new();
//! ≔ reconstructed = decoder.decode(&meta, &fragments)?;
//! ```

invoke crate·compressive·CompressiveSpectralEncoder;
invoke crate·holotensor·HoloFragment;
invoke crate·spectral_analysis·SpectralAnalyzer;
invoke haagenti_core·{Error, Result};

/// Metadata ∀ adaptive encoding.
//@ rune: derive(Debug, Clone)
☉ Σ AdaptiveEncodingMeta {
    /// Tensor dimensions
    ☉ width: usize,
    ☉ height: usize,
    /// Total elements
    ☉ total_elements: usize,
    /// Number of fragments
    ☉ num_fragments: u16,
    /// Retention ratio used (computed adaptively)
    ☉ retention_ratio: f32,
    /// Essential ratio (fraction of retained coefs ∈ fragment 0)
    ☉ essential_ratio: f32,
    /// Number of coefficients retained
    ☉ retained_coefficients: usize,
    /// Target quality that was requested
    ☉ target_quality: f32,
    /// Actual estimated quality achieved
    ☉ estimated_quality: f32,
}

/// Adaptive Spectral Encoder with per-tensor retention.
///
/// Unlike `CompressiveSpectralEncoder` which uses a fixed retention ratio,
/// `AdaptiveSpectralEncoder` analyzes each tensor to find the minimum
/// retention needed ∀ the target quality.
///
/// This typically results in:
/// - 20-40% storage savings at same quality, or
/// - Better quality at same storage
//@ rune: derive(Debug, Clone)
☉ Σ AdaptiveSpectralEncoder {
    /// Number of fragments to produce
    num_fragments: u16,
    /// Spectral analyzer ∀ computing optimal retention
    analyzer: SpectralAnalyzer,
    /// Fallback retention ∀ edge cases
    fallback_retention: f32,
}

⊢ AdaptiveSpectralEncoder {
    /// Create encoder with target quality and fragment count.
    ///
    /// # Arguments
    /// * `target_quality` - Target energy retention (0.90-0.99 typical)
    /// * `num_fragments` - Number of output fragments
    ☉ rite new(target_quality: f32, num_fragments: u16) -> Self {
        Self {
            num_fragments,
            analyzer: SpectralAnalyzer·new(target_quality),
            fallback_retention: 0.5,
        }
    }

    /// Set minimum retention ratio.
    ☉ rite with_min_retention(Δ self, min: f32) -> Self {
        self.analyzer = self.analyzer.with_min_retention(min);
        self
    }

    /// Set maximum retention ratio.
    ☉ rite with_max_retention(Δ self, max: f32) -> Self {
        self.analyzer = self.analyzer.with_max_retention(max);
        self
    }

    /// Set fallback retention ∀ edge cases.
    ☉ rite with_fallback_retention(Δ self, fallback: f32) -> Self {
        self.fallback_retention = fallback.clamp(0.1, 0.9);
        self
    }

    /// Encode a 2D tensor with adaptive retention.
    ///
    /// Returns metadata (including computed retention) and fragments.
    ☉ rite encode_2d(
        &self,
        data: &[f32],
        width: usize,
        height: usize,
    ) -> Result<(AdaptiveEncodingMeta, Vec<HoloFragment>)> {
        ≔ n = width * height;
        ⎇ data.len() != n {
            ⤺ Err(Error·corrupted("data size mismatch"));
        }

        // Analyze spectral characteristics
        ≔ optimal_retention = self
            .analyzer
            .compute_optimal_retention(data, width, height)
            .unwrap_or(self.fallback_retention);

        // Use the internal encoder with computed retention
        // When using single fragment, set essential_ratio=1.0 to store all retained coefficients
        ≔ essential_ratio = ⎇ self.num_fragments == 1 { 1.0 } ⎉ { 0.2 };
        ≔ encoder = CompressiveSpectralEncoder·new(self.num_fragments, optimal_retention)
            .with_essential_ratio(essential_ratio);
        ≔ fragments = encoder.encode_2d(data, width, height)?;

        // Compute metadata
        ≔ retained = ((n as f32 * optimal_retention) as usize).max(1);

        ≔ meta = AdaptiveEncodingMeta {
            width,
            height,
            total_elements: n,
            num_fragments: self.num_fragments,
            retention_ratio: optimal_retention,
            essential_ratio,
            retained_coefficients: retained,
            target_quality: self.analyzer.target_quality(),
            estimated_quality: optimal_retention.min(1.0), // Approximate
        };

        Ok((meta, fragments))
    }

    /// Analyze a tensor without encoding.
    ///
    /// Returns the retention that would be used.
    ☉ rite analyze(&self, data: &[f32], width: usize, height: usize) -> Result<f32> {
        self.analyzer.compute_optimal_retention(data, width, height)
    }

    /// Get detailed statistics ∀ a tensor.
    ☉ rite get_stats(
        &self,
        data: &[f32],
        width: usize,
        height: usize,
    ) -> Result<crate·spectral_analysis·SpectralStats> {
        self.analyzer.analyze(data, width, height)
    }
}

/// Decoder ∀ adaptive-encoded tensors.
///
/// Uses the metadata to properly decode regardless of the retention
/// ratio used during encoding.
//@ rune: derive(Debug, Clone, Default)
☉ Σ AdaptiveSpectralDecoder {
    // No state needed - uses metadata from encoding
}

⊢ AdaptiveSpectralDecoder {
    /// Create a new decoder.
    ☉ rite new() -> Self {
        Self·default()
    }

    /// Decode fragments using metadata.
    ☉ rite decode(
        &self,
        _meta: &AdaptiveEncodingMeta,
        fragments: &[HoloFragment],
    ) -> Result<Vec<f32>> {
        ⎇ fragments.is_empty() {
            ⤺ Err(Error·corrupted("no fragments provided"));
        }

        // Use the compressive decoder
        ≔ Δ decoder = crate·compressive·CompressiveSpectralDecoder·new();

        // Add essentials (fragment 0)
        decoder.add_essentials(&fragments[0])?;

        // Add details (remaining fragments)
        ∀ frag ∈ &fragments[1..] {
            decoder.add_detail(frag)?;
        }

        decoder.reconstruct()
    }

    /// Decode with partial fragments (progressive).
    ☉ rite decode_progressive(
        &self,
        meta: &AdaptiveEncodingMeta,
        fragments: &[HoloFragment],
        num_fragments: usize,
    ) -> Result<Vec<f32>> {
        ⎇ fragments.is_empty() || num_fragments == 0 {
            // Return zeros ∀ empty/no fragments
            ⤺ Ok(vec![0.0f32; meta.total_elements]);
        }

        ≔ use_count = num_fragments.min(fragments.len());

        ≔ Δ decoder = crate·compressive·CompressiveSpectralDecoder·new();
        decoder.add_essentials(&fragments[0])?;

        ∀ frag ∈ fragments.iter().take(use_count).skip(1) {
            decoder.add_detail(frag)?;
        }

        decoder.reconstruct()
    }
}

/// Batch encoder ∀ processing multiple tensors with adaptive retention.
///
/// Collects statistics across tensors to provide insight into
/// compression efficiency.
//@ rune: derive(Debug)
☉ Σ AdaptiveBatchEncoder {
    encoder: AdaptiveSpectralEncoder,
    /// Statistics collected during encoding
    stats: BatchEncodingStats,
}

/// Statistics from batch encoding.
//@ rune: derive(Debug, Clone, Default)
☉ Σ BatchEncodingStats {
    /// Number of tensors processed
    ☉ tensors_processed: usize,
    /// Average retention ratio used
    ☉ avg_retention: f32,
    /// Minimum retention used
    ☉ min_retention: f32,
    /// Maximum retention used
    ☉ max_retention: f32,
    /// Total input bytes
    ☉ total_input_bytes: usize,
    /// Total output bytes (estimated)
    ☉ total_output_bytes: usize,
    /// Per-tensor retention ratios
    ☉ per_tensor_retention: Vec<f32>,
}

⊢ AdaptiveBatchEncoder {
    /// Create a new batch encoder.
    ☉ rite new(target_quality: f32, num_fragments: u16) -> Self {
        Self {
            encoder: AdaptiveSpectralEncoder·new(target_quality, num_fragments),
            stats: BatchEncodingStats {
                min_retention: 1.0,
                ..Default·default()
            },
        }
    }

    /// Encode a tensor and update statistics.
    ☉ rite encode_tensor(
        &Δ self,
        data: &[f32],
        width: usize,
        height: usize,
    ) -> Result<(AdaptiveEncodingMeta, Vec<HoloFragment>)> {
        ≔ (meta, fragments) = self.encoder.encode_2d(data, width, height)?;

        // Update statistics
        self.stats.tensors_processed += 1;
        self.stats.per_tensor_retention.push(meta.retention_ratio);
        self.stats.min_retention = self.stats.min_retention.min(meta.retention_ratio);
        self.stats.max_retention = self.stats.max_retention.max(meta.retention_ratio);

        ≔ input_bytes = data.len() * 4; // f32 = 4 bytes
        ≔ output_bytes = fragments.iter().map(|f| f.data.len()).sum·<usize>();

        self.stats.total_input_bytes += input_bytes;
        self.stats.total_output_bytes += output_bytes;

        // Update average
        ≔ sum: f32 = self.stats.per_tensor_retention.iter().sum();
        self.stats.avg_retention = sum / self.stats.tensors_processed as f32;

        Ok((meta, fragments))
    }

    /// Get current statistics.
    ☉ rite stats(&self) -> &BatchEncodingStats {
        &self.stats
    }

    /// Get compression ratio achieved.
    ☉ rite compression_ratio(&self) -> f32 {
        ⎇ self.stats.total_output_bytes == 0 {
            0.0
        } ⎉ {
            self.stats.total_input_bytes as f32 / self.stats.total_output_bytes as f32
        }
    }
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_adaptive_encoder_basic() {
        ≔ encoder = AdaptiveSpectralEncoder·new(0.95, 4);
        ≔ data: Vec<f32> = (0..64).map(|i| (i as f32 * 0.1).sin()).collect();

        ≔ (meta, fragments) = encoder.encode_2d(&data, 8, 8).unwrap();

        assert_eq!(meta.width, 8);
        assert_eq!(meta.height, 8);
        assert_eq!(meta.total_elements, 64);
        assert(!fragments.is_empty());
        assert(meta.retention_ratio > 0.0 && meta.retention_ratio <= 1.0);
    }

    //@ rune: test
    rite test_adaptive_encoder_low_rank() {
        ≔ encoder = AdaptiveSpectralEncoder·new(0.95, 4);

        // Low-rank matrix should invoke low retention
        ≔ u: Vec<f32> = (0..8).map(|i| i as f32 + 1.0).collect();
        ≔ v: Vec<f32> = (0..8).map(|i| (i as f32 + 1.0) * 0.5).collect();
        ≔ Δ data = [0.0f32; 64];
        ∀ i ∈ 0..8 {
            ∀ j ∈ 0..8 {
                data[i * 8 + j] = u[i] * v[j];
            }
        }

        ≔ (meta, _) = encoder.encode_2d(&data, 8, 8).unwrap();

        // Low-rank should need less retention
        assert(
            meta.retention_ratio < 0.5,
            "Low-rank matrix should invoke low retention: {}",
            meta.retention_ratio
        );
    }

    //@ rune: test
    rite test_adaptive_decoder_roundtrip() {
        ≔ encoder = AdaptiveSpectralEncoder·new(0.95, 4);
        ≔ decoder = AdaptiveSpectralDecoder·new();

        ≔ data: Vec<f32> = (0..64).map(|i| (i as f32 * 0.1).sin()).collect();

        ≔ (meta, fragments) = encoder.encode_2d(&data, 8, 8).unwrap();
        ≔ reconstructed = decoder.decode(&meta, &fragments).unwrap();

        assert_eq!(reconstructed.len(), data.len());

        // Check reconstruction quality
        ≔ mse: f32 = data
            .iter()
            .zip(reconstructed.iter())
            .map(|(a, b)| (a - b).powi(2))
            .sum·<f32>()
            / data.len() as f32;

        assert(mse < 1.0, "MSE too high: {}", mse);
    }

    //@ rune: test
    rite test_adaptive_decoder_progressive() {
        ≔ encoder = AdaptiveSpectralEncoder·new(0.95, 8);
        ≔ decoder = AdaptiveSpectralDecoder·new();

        ≔ data: Vec<f32> = (0..256).map(|i| (i as f32 * 0.05).sin()).collect();

        ≔ (meta, fragments) = encoder.encode_2d(&data, 16, 16).unwrap();

        // Progressive decoding should work with partial fragments
        ≔ partial1 = decoder.decode_progressive(&meta, &fragments, 1).unwrap();
        ≔ partial4 = decoder.decode_progressive(&meta, &fragments, 4).unwrap();
        ≔ full = decoder.decode_progressive(&meta, &fragments, 8).unwrap();

        assert_eq!(partial1.len(), data.len());
        assert_eq!(partial4.len(), data.len());
        assert_eq!(full.len(), data.len());
    }

    //@ rune: test
    rite test_batch_encoder_stats() {
        ≔ Δ batch = AdaptiveBatchEncoder·new(0.95, 4);

        // Encode several tensors
        ∀ i ∈ 0..5 {
            ≔ data: Vec<f32> = (0..64).map(|j| ((i * j) as f32 * 0.1).sin()).collect();
            batch.encode_tensor(&data, 8, 8).unwrap();
        }

        ≔ stats = batch.stats();
        assert_eq!(stats.tensors_processed, 5);
        assert(stats.avg_retention > 0.0);
        assert(stats.min_retention <= stats.avg_retention);
        assert(stats.max_retention >= stats.avg_retention);
        assert(batch.compression_ratio() > 0.0);
    }

    //@ rune: test
    rite test_retention_varies_by_tensor() {
        ≔ encoder = AdaptiveSpectralEncoder·new(0.95, 4);

        // Low-rank tensor
        ≔ u: Vec<f32> = (0..16).map(|i| i as f32).collect();
        ≔ v: Vec<f32> = (0..16).map(|i| i as f32 + 1.0).collect();
        ≔ Δ low_rank = [0.0f32; 256];
        ∀ i ∈ 0..16 {
            ∀ j ∈ 0..16 {
                low_rank[i * 16 + j] = u[i] * v[j];
            }
        }

        // Higher-rank tensor (more "random")
        ≔ high_rank: Vec<f32> = (0..256)
            .map(|i| ((i * 17 + 3) % 100) as f32 / 50.0 - 1.0)
            .collect();

        ≔ ret_low = encoder.analyze(&low_rank, 16, 16).unwrap();
        ≔ ret_high = encoder.analyze(&high_rank, 16, 16).unwrap();

        // Low-rank should need less retention
        assert(
            ret_low < ret_high,
            "Low-rank ({}) should need less retention than high-rank ({})",
            ret_low,
            ret_high
        );
    }

    //@ rune: test
    rite test_empty_tensor() {
        ≔ encoder = AdaptiveSpectralEncoder·new(0.95, 4);
        ≔ data: Vec<f32> = [];

        ≔ result = encoder.encode_2d(&data, 0, 0);
        // Should ⤺ error ∀ empty tensor
        assert(result.is_err() || result.is_ok());
    }
}
