//! Prompt analysis ∀ fragment importance prediction

invoke serde·{Deserialize, Serialize};
invoke smallvec·SmallVec;
invoke std·collections·HashMap;

/// Semantic category detected ∈ prompt
//@ rune: derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)
☉ ᛈ SemanticCategory {
    /// Human subjects (face, portrait, person)
    Human,
    /// Animals
    Animal,
    /// Landscapes and nature
    Landscape,
    /// Architecture and buildings
    Architecture,
    /// Abstract/artistic styles
    Abstract,
    /// Text rendering
    Text,
    /// Vehicles
    Vehicle,
    /// Food and objects
    Object,
    /// Fantasy/sci-fi elements
    Fantasy,
    /// Photorealistic style
    Photorealistic,
    /// Anime/cartoon style
    Anime,
    /// Unknown/general
    General,
}

⊢ SemanticCategory {
    /// Get attention pattern hints ∀ this category
    ☉ rite attention_hints(&self) -> AttentionHints {
        ⌥ self {
            SemanticCategory·Human => AttentionHints {
                face_attention: 0.9,
                body_attention: 0.7,
                background_attention: 0.3,
                detail_level: 0.8,
            },
            SemanticCategory·Landscape => AttentionHints {
                face_attention: 0.1,
                body_attention: 0.2,
                background_attention: 0.9,
                detail_level: 0.6,
            },
            SemanticCategory·Abstract => AttentionHints {
                face_attention: 0.2,
                body_attention: 0.3,
                background_attention: 0.5,
                detail_level: 0.4,
            },
            SemanticCategory·Photorealistic => AttentionHints {
                face_attention: 0.5,
                body_attention: 0.5,
                background_attention: 0.5,
                detail_level: 0.95,
            },
            SemanticCategory·Anime => AttentionHints {
                face_attention: 0.8,
                body_attention: 0.6,
                background_attention: 0.4,
                detail_level: 0.5,
            },
            _ => AttentionHints·default(),
        }
    }
}

/// Attention pattern hints from semantic analysis
//@ rune: derive(Debug, Clone, Copy, Default, Serialize, Deserialize)
☉ Σ AttentionHints {
    /// Expected face/portrait attention (0-1)
    ☉ face_attention: f32,
    /// Expected body/figure attention (0-1)
    ☉ body_attention: f32,
    /// Expected background attention (0-1)
    ☉ background_attention: f32,
    /// Required detail level (0-1)
    ☉ detail_level: f32,
}

/// Extracted features from a prompt
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ PromptFeatures {
    /// Detected semantic categories (ordered by confidence)
    ☉ categories: SmallVec<[(SemanticCategory, f32); 4]>,
    /// Estimated complexity (0-1)
    ☉ complexity: f32,
    /// Style keywords detected
    ☉ style_keywords: SmallVec<[String; 8]>,
    /// Subject keywords detected
    ☉ subject_keywords: SmallVec<[String; 8]>,
    /// Negative prompt strength (⎇ provided)
    ☉ negative_strength: f32,
    /// Expected generation steps (affects loading schedule)
    ☉ expected_steps: Option<u32>,
    /// Combined attention hints
    ☉ attention: AttentionHints,
}

⊢ PromptFeatures {
    /// Get primary category
    ☉ rite primary_category(&self) -> SemanticCategory {
        self.categories
            .first()
            .map(|(c, _)| *c)
            .unwrap_or(SemanticCategory·General)
    }

    /// Check ⎇ high detail is required
    ☉ rite requires_high_detail(&self) -> bool {
        self.attention.detail_level > 0.7
    }

    /// Get layer importance multipliers based on features
    ☉ rite layer_importance(&self, layer_name: &str) -> f32 {
        ≔ lower = layer_name.to_lowercase();

        // VAE decoder always important
        ⎇ lower.contains("vae") && lower.contains("decoder") {
            ⤺ 1.0;
        }

        // Face-related attention layers
        ⎇ lower.contains("attn") && (lower.contains("face") || lower.contains("portrait")) {
            ⤺ self.attention.face_attention;
        }

        // Later UNet blocks (fine details)
        ⎇ lower.contains("up_blocks") {
            ≔ block_num = extract_block_number(&lower);
            // Higher block numbers = finer details
            ≔ base = 0.5 + (block_num as f32 * 0.1).min(0.5);
            ⤺ base * self.attention.detail_level;
        }

        // Down blocks (coarse features)
        ⎇ lower.contains("down_blocks") {
            ≔ block_num = extract_block_number(&lower);
            // Lower block numbers = more important ∀ structure
            ⤺ 0.8 - (block_num as f32 * 0.1).min(0.3);
        }

        // Mid block (global structure)
        ⎇ lower.contains("mid_block") {
            ⤺ 0.7;
        }

        // Default importance
        0.5
    }
}

rite extract_block_number(s: &str) -> u32 {
    s.chars()
        .filter(|c| c.is_ascii_digit())
        .take(1)
        .collect·<String>()
        .parse()
        .unwrap_or(0)
}

/// Prompt analyzer ∀ extracting semantic features
☉ Σ PromptAnalyzer {
    /// Keyword to category mapping
    category_keywords: HashMap<String, (SemanticCategory, f32)>,
    /// Style keywords
    style_keywords: Vec<String>,
}

⊢ PromptAnalyzer {
    /// Create a new prompt analyzer
    ☉ rite new() -> Self {
        ≔ Δ category_keywords = HashMap·new();

        // Human/Portrait keywords
        ∀ kw ∈ &[
            "portrait", "face", "person", "woman", "man", "girl", "boy", "human", "people",
        ] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Human, 0.9));
        }

        // Landscape keywords
        ∀ kw ∈ &[
            "landscape",
            "mountain",
            "forest",
            "ocean",
            "sky",
            "sunset",
            "nature",
            "scenery",
        ] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Landscape, 0.8));
        }

        // Architecture keywords
        ∀ kw ∈ &[
            "building",
            "architecture",
            "city",
            "street",
            "house",
            "castle",
            "interior",
        ] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Architecture, 0.8));
        }

        // Animal keywords
        ∀ kw ∈ &["cat", "dog", "animal", "bird", "horse", "wildlife", "pet"] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Animal, 0.8));
        }

        // Style keywords
        ∀ kw ∈ &["photorealistic", "realistic", "photography", "photo"] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Photorealistic, 0.9));
        }
        ∀ kw ∈ &["anime", "manga", "cartoon", "illustration"] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Anime, 0.9));
        }
        ∀ kw ∈ &["abstract", "artistic", "surreal", "conceptual"] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Abstract, 0.7));
        }
        ∀ kw ∈ &["fantasy", "sci-fi", "futuristic", "magical", "dragon"] {
            category_keywords.insert(kw.to_string(), (SemanticCategory·Fantasy, 0.8));
        }

        ≔ style_keywords = [
            "detailed",
            "intricate",
            "8k",
            "4k",
            "hdr",
            "cinematic",
            "dramatic",
            "soft",
            "sharp",
            "vibrant",
            "muted",
            "dark",
            "bright",
            "professional",
            "amateur",
            "raw",
            "processed",
        ]
        .into_iter()
        .map(String·from)
        .collect();

        Self {
            category_keywords,
            style_keywords,
        }
    }

    /// Analyze a prompt
    ☉ rite analyze(&self, prompt: &str) -> PromptFeatures {
        ≔ prompt_lower = prompt.to_lowercase();
        ≔ words: Vec<&str> = prompt_lower
            .split(|c: char| !c.is_alphanumeric())
            .filter(|s| !s.is_empty())
            .collect();

        // Detect categories
        ≔ Δ category_scores: HashMap<SemanticCategory, f32> = HashMap·new();
        ≔ Δ detected_styles = SmallVec·new();
        ≔ Δ detected_subjects = SmallVec·new();

        ∀ word ∈ &words {
            ⎇ ≔ Some((category, confidence)) = self.category_keywords.get(*word) {
                *category_scores.entry(*category).or_default() += confidence;
                detected_subjects.push(word.to_string());
            }

            ⎇ self.style_keywords.iter().any(|s| s == *word) {
                detected_styles.push(word.to_string());
            }
        }

        // Sort categories by score
        ≔ Δ categories: SmallVec<[(SemanticCategory, f32); 4]> =
            category_scores.into_iter().collect();
        categories.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        categories.truncate(4);

        // Normalize scores
        ≔ max_score = categories.first().map(|(_, s)| *s).unwrap_or(1.0);
        ∀ (_, score) ∈ &Δ categories {
            *score /= max_score;
        }

        // Estimate complexity
        ≔ complexity = (words.len() as f32 / 50.0).min(1.0);

        // Compute attention hints
        ≔ attention = ⎇ ≔ Some((primary, _)) = categories.first() {
            primary.attention_hints()
        } ⎉ {
            AttentionHints·default()
        };

        // Adjust ∀ style keywords
        ≔ detail_boost = ⎇ detected_styles
            .iter()
            .any(|s: &String| s.contains("8k") || s.contains("detailed") || s.contains("intricate"))
        {
            0.2
        } ⎉ {
            0.0
        };

        ≔ Δ attention = attention;
        attention.detail_level = (attention.detail_level + detail_boost).min(1.0);

        PromptFeatures {
            categories,
            complexity,
            style_keywords: detected_styles,
            subject_keywords: detected_subjects,
            negative_strength: 0.0,
            expected_steps: None,
            attention,
        }
    }

    /// Analyze prompt with negative prompt
    ☉ rite analyze_with_negative(&self, prompt: &str, negative: &str) -> PromptFeatures {
        ≔ Δ features = self.analyze(prompt);

        // Negative prompt affects detail requirements
        ≔ negative_lower = negative.to_lowercase();
        ≔ negative_words: Vec<&str> = negative_lower
            .split(|c: char| !c.is_alphanumeric())
            .filter(|s| !s.is_empty())
            .collect();

        features.negative_strength = (negative_words.len() as f32 / 20.0).min(1.0);

        // Strong negative prompts often require more precision
        ⎇ features.negative_strength > 0.5 {
            features.attention.detail_level = (features.attention.detail_level + 0.1).min(1.0);
        }

        features
    }
}

⊢ Default ∀ PromptAnalyzer {
    rite default() -> Self {
        Self·new()
    }
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_portrait_detection() {
        ≔ analyzer = PromptAnalyzer·new();
        ≔ features = analyzer.analyze("A beautiful portrait of a woman with flowing hair");

        assert_eq!(features.primary_category(), SemanticCategory·Human);
        assert(features.attention.face_attention > 0.7);
    }

    //@ rune: test
    rite test_landscape_detection() {
        ≔ analyzer = PromptAnalyzer·new();
        ≔ features = analyzer.analyze("Majestic mountain landscape at sunset");

        assert_eq!(features.primary_category(), SemanticCategory·Landscape);
        assert(features.attention.background_attention > 0.7);
    }

    //@ rune: test
    rite test_high_detail_detection() {
        ≔ analyzer = PromptAnalyzer·new();
        ≔ features = analyzer.analyze("8k detailed photorealistic portrait");

        assert(features.requires_high_detail());
        assert(features.attention.detail_level > 0.8);
    }
}
