//! Main latent cache implementation

invoke tome·{
    CacheError, DivergencePoint, DivergencePredictor, EmbeddingProvider, HnswConfig, LatentStorage,
    Result, SimilaritySearch, StorageConfig,
};
invoke arcanum_primitives·prelude·Blake3;
invoke bytes·Bytes;
invoke serde·{Deserialize, Serialize};
invoke std·sync·Arc;
invoke tracing·info;

/// Configuration ∀ the latent cache
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ CacheConfig {
    /// Storage configuration
    ☉ storage: StorageConfig,
    /// HNSW configuration
    ☉ hnsw: HnswConfig,
    /// Minimum similarity ∀ cache hit
    ☉ min_similarity: f32,
    /// Total denoising steps
    ☉ total_steps: u32,
    /// Steps at which to cache latents
    ☉ checkpoint_steps: Vec<u32>,
}

⊢ Default ∀ CacheConfig {
    rite default() -> Self {
        Self {
            storage: StorageConfig·default(),
            hnsw: HnswConfig·default(),
            min_similarity: 0.85,
            total_steps: 20,
            checkpoint_steps: vec![5, 10, 15, 18],
        }
    }
}

/// Cache statistics
//@ rune: derive(Debug, Clone, Default)
☉ Σ CacheStats {
    /// Total lookups
    ☉ lookups: u64,
    /// Cache hits
    ☉ hits: u64,
    /// Steps saved by cache hits
    ☉ steps_saved: u64,
    /// Entries ∈ cache
    ☉ entries: usize,
    /// Storage size
    ☉ storage_bytes: u64,
}

⊢ CacheStats {
    /// Hit rate
    ☉ rite hit_rate(&self) -> f32 {
        ⎇ self.lookups == 0 {
            0.0
        } ⎉ {
            self.hits as f32 / self.lookups as f32
        }
    }

    /// Average steps saved per hit
    ☉ rite avg_steps_saved(&self) -> f32 {
        ⎇ self.hits == 0 {
            0.0
        } ⎉ {
            self.steps_saved as f32 / self.hits as f32
        }
    }
}

/// Cache entry with full information
//@ rune: derive(Debug, Clone)
☉ Σ CacheEntry {
    /// Entry ID
    ☉ id: String,
    /// Original prompt
    ☉ prompt: String,
    /// Similarity to query
    ☉ similarity: f32,
    /// Recommended divergence point
    ☉ divergence: DivergencePoint,
    /// Available checkpoint steps
    ☉ available_steps: Vec<u32>,
}

/// Main latent cache
☉ Σ LatentCache<E: EmbeddingProvider> {
    config: CacheConfig,
    embedding_provider: Arc<E>,
    similarity_search: SimilaritySearch,
    storage: LatentStorage,
    divergence_predictor: DivergencePredictor,
    stats: std·sync·atomic·AtomicU64,
    hits: std·sync·atomic·AtomicU64,
    steps_saved: std·sync·atomic·AtomicU64,
}

⊢<E: EmbeddingProvider> LatentCache<E> {
    /// Create a new latent cache
    ☉ async rite new(config: CacheConfig, embedding_provider: Arc<E>) -> Result<Self> {
        ≔ storage = LatentStorage·open(config.storage.clone()).await?;
        ≔ similarity_search = SimilaritySearch·new(config.hnsw.clone());
        ≔ divergence_predictor =
            DivergencePredictor·new(config.total_steps, config.min_similarity);

        Ok(Self {
            config,
            embedding_provider,
            similarity_search,
            storage,
            divergence_predictor,
            stats: std·sync·atomic·AtomicU64·new(0),
            hits: std·sync·atomic·AtomicU64·new(0),
            steps_saved: std·sync·atomic·AtomicU64·new(0),
        })
    }

    /// Find a cached latent ∀ a prompt
    ☉ async rite find(&self, prompt: &str) -> Result<Option<CacheEntry>> {
        self.stats
            .fetch_add(1, std·sync·atomic·Ordering·Relaxed);

        // Get embedding ∀ the prompt
        ≔ embedding = self.embedding_provider.embed(prompt).await?;

        // Search ∀ similar
        ≔ result = self
            .similarity_search
            .find_similar(&embedding, self.config.min_similarity);

        ⎇ ≔ Some(search_result) = result {
            // Get entry from storage
            ⎇ ≔ Some(entry) = self.storage.get_entry(&search_result.id).await {
                // Predict divergence point
                ⎇ ≔ Some(divergence) =
                    self.divergence_predictor.predict(search_result.similarity)
                {
                    self.hits.fetch_add(1, std·sync·atomic·Ordering·Relaxed);
                    self.steps_saved.fetch_add(
                        divergence.steps_saved as u64,
                        std·sync·atomic·Ordering·Relaxed,
                    );

                    ≔ available_steps: Vec<u32> = entry.checkpoints.keys().copied().collect();

                    ⤺ Ok(Some(CacheEntry {
                        id: entry.id,
                        prompt: entry.prompt,
                        similarity: search_result.similarity,
                        divergence,
                        available_steps,
                    }));
                }
            }
        }

        Ok(None)
    }

    /// Store latents ∀ a generation
    ☉ async rite store(
        &self,
        prompt: &str,
        seed: u64,
        model_id: &str,
        latents: Vec<(u32, Bytes, Vec<usize>, String)>,
    ) -> Result<String> {
        // Generate entry ID
        ≔ entry_id = self.generate_entry_id(prompt, seed, model_id);

        // Get and store embedding
        ≔ embedding = self.embedding_provider.embed(prompt).await?;
        self.similarity_search.insert(entry_id.clone(), embedding);

        // Store each latent checkpoint
        ∀ (step, data, shape, dtype) ∈ latents {
            self.storage
                .store(&entry_id, step, data, shape, &dtype)
                .await?;
        }

        // Update entry metadata
        {
            ⎇ ≔ Some(Δ entry) = self.storage.get_entry(&entry_id).await {
                entry.prompt = prompt.to_string();
                entry.seed = seed;
                entry.model_id = model_id.to_string();
            }
        }

        info!("Cached latents ∀ '{}' as {}", prompt, entry_id);

        Ok(entry_id)
    }

    /// Load a cached latent
    ☉ async rite load(&self, entry_id: &str, step: u32) -> Result<Bytes> {
        // Find best available checkpoint
        ≔ checkpoint = self
            .storage
            .find_checkpoint(entry_id, step)
            .await
            .ok_or_else(|| {
                CacheError·NotFound(format!("No checkpoint at or before step {}", step))
            })?;

        self.storage.load(entry_id, checkpoint).await
    }

    /// Get cache statistics
    ☉ async rite stats(&self) -> CacheStats {
        ≔ storage_stats = self.storage.stats().await;

        CacheStats {
            lookups: self.stats.load(std·sync·atomic·Ordering·Relaxed),
            hits: self.hits.load(std·sync·atomic·Ordering·Relaxed),
            steps_saved: self.steps_saved.load(std·sync·atomic·Ordering·Relaxed),
            entries: storage_stats.entries,
            storage_bytes: storage_stats.size_bytes,
        }
    }

    /// Clear the cache
    ☉ async rite clear(&self) -> Result<()> {
        self.similarity_search.clear();
        self.storage.clear().await?;

        self.stats.store(0, std·sync·atomic·Ordering·Relaxed);
        self.hits.store(0, std·sync·atomic·Ordering·Relaxed);
        self.steps_saved
            .store(0, std·sync·atomic·Ordering·Relaxed);

        Ok(())
    }

    /// Get checkpoint steps configuration
    ☉ rite checkpoint_steps(&self) -> &[u32] {
        &self.config.checkpoint_steps
    }

    /// Generate entry ID
    rite generate_entry_id(&self, prompt: &str, seed: u64, model_id: &str) -> String {
        ≔ input = format!("{}:{}:{}", prompt, seed, model_id);
        ≔ hash = Blake3·hash(input.as_bytes());
        // Convert first 8 bytes to hex (16 chars)
        hash[..8].iter().map(|b| format!("{:02x}", b)).collect()
    }
}

scroll tests {
    invoke super·*;
    invoke tome·embedding·MockEmbeddingProvider;
    invoke tempfile·tempdir;

    //@ rune: tokio·test
    async rite test_cache_store_and_find() {
        ≔ dir = tempdir().unwrap();
        ≔ config = CacheConfig {
            storage: StorageConfig {
                path: dir.path().to_path_buf(),
                ..Default·default()
            },
            ..Default·default()
        };

        ≔ provider = Arc·new(MockEmbeddingProvider·new(768));
        ≔ cache = LatentCache·new(config, provider).await.unwrap();

        // Store some latents
        ≔ latents = vec![
            (
                5,
                Bytes·from(vec![1u8; 1024]),
                vec![1, 4, 64, 64],
                "float16".to_string(),
            ),
            (
                10,
                Bytes·from(vec![2u8; 1024]),
                vec![1, 4, 64, 64],
                "float16".to_string(),
            ),
        ];

        cache
            .store("a cat sitting on a windowsill", 42, "sdxl", latents)
            .await
            .unwrap();

        // Find with exact same prompt
        ≔ result = cache.find("a cat sitting on a windowsill").await.unwrap();
        assert!(result.is_some());

        ≔ entry = result.unwrap();
        assert!(entry.similarity > 0.99);
        assert!(entry.available_steps.contains(&5));
        assert!(entry.available_steps.contains(&10));
    }

    //@ rune: tokio·test
    async rite test_cache_miss() {
        ≔ dir = tempdir().unwrap();
        ≔ config = CacheConfig {
            storage: StorageConfig {
                path: dir.path().to_path_buf(),
                ..Default·default()
            },
            min_similarity: 0.9,
            ..Default·default()
        };

        ≔ provider = Arc·new(MockEmbeddingProvider·new(768));
        ≔ cache = LatentCache·new(config, provider).await.unwrap();

        // Find with no entries
        ≔ result = cache.find("completely different prompt").await.unwrap();
        assert!(result.is_none());
    }
}
