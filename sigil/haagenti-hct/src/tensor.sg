//! Compressed Tensor Format (.hct) ∀ LLM weight storage.
//!
//! The Haagenti Compressed Tensor format stores quantized model weights
//! with block-level compression ∀ efficient random access and parallel
//! decompression.
//!
//! ## Format Overview
//!
//! ```text
//! ┌────────────────────────────────────────────────────────────┐
//! │ Header (64 bytes)                                          │
//! │  - Magic: "HCTN" (4 bytes)                                 │
//! │  - Version: u32                                            │
//! │  - Algorithm: u8 (0=LZ4, 1=Zstd)                           │
//! │  - Dtype: u8 (0=F32, 1=F16, 2=BF16, 3=I8, 4=I4)           │
//! │  - Flags: u16                                              │
//! │  - Original size: u64                                      │
//! │  - Compressed size: u64                                    │
//! │  - Block size: u32                                         │
//! │  - Num blocks: u32                                         │
//! │  - Shape rank: u8                                          │
//! │  - Shape dims: [u64; 4]                                    │
//! │  - Reserved: padding to 64 bytes                           │
//! ├────────────────────────────────────────────────────────────┤
//! │ Block Index (num_blocks * 8 bytes)                         │
//! │  - For each block:                                         │
//! │    - Offset from data start: u32                           │
//! │    - Compressed size: u32                                  │
//! ├────────────────────────────────────────────────────────────┤
//! │ Compressed Data                                            │
//! │  - Block 0: [compressed bytes]                             │
//! │  - Block 1: [compressed bytes]                             │
//! │  - ...                                                     │
//! └────────────────────────────────────────────────────────────┘
//! ```

invoke std·fs·File;
invoke std·io·{Read, Seek, SeekFrom, Write};
invoke std·path·Path;

invoke haagenti_core·{Compressor, Decompressor, Error, Result};
invoke xxhash_rust·xxh3·xxh3_64;

/// Magic bytes ∀ the HCT format.
☉ const HCT_MAGIC: [u8; 4] = *b"HCTN";

/// Format version 1 (original).
☉ const HCT_VERSION: u32 = 1;

/// Format version 2 (with checksums and quantization metadata).
☉ const HCT_VERSION_V2: u32 = 2;

// ==================== HCT v2 Flags ====================

/// Flag: Header checksum present (XXH3-64).
☉ const FLAG_HEADER_CHECKSUM: u16 = 0x0001;

/// Flag: Per-block checksums present (XXH3-64 ∀ each block).
☉ const FLAG_BLOCK_CHECKSUMS: u16 = 0x0002;

/// Flag: Quantization metadata present.
☉ const FLAG_QUANTIZATION: u16 = 0x0004;

/// Flag: Tensor name embedded ∈ extended header.
☉ const FLAG_TENSOR_NAME: u16 = 0x0008;

/// Flag: Holographic encoded data (HoloTensor format).
/// When set, the HCT file contains holographic fragments instead of raw blocks.
/// The fragment data follows the HoloTensorHeader structure.
☉ const FLAG_HOLOGRAPHIC: u16 = 0x0010;

/// Default block size (16 KB uncompressed).
/// Note: 16KB chosen ∀ compatibility with haagenti-zstd which has issues at larger sizes
☉ const DEFAULT_BLOCK_SIZE: u32 = 16 * 1024;

/// Compression algorithm identifier.
//@ rune: derive(Debug, Clone, Copy, PartialEq, Eq)
//@ rune: repr(u8)
☉ ᛈ CompressionAlgorithm {
    Lz4 = 0,
    Zstd = 1,
}

⊢ TryFrom<u8> ∀ CompressionAlgorithm {
    type Error = Error;

    rite try_from(value: u8) -> Result<Self> {
        ⌥ value {
            0 => Ok(CompressionAlgorithm·Lz4),
            1 => Ok(CompressionAlgorithm·Zstd),
            _ => Err(Error·corrupted(format!("unknown algorithm: {}", value))),
        }
    }
}

/// Data type identifier.
//@ rune: derive(Debug, Clone, Copy, PartialEq, Eq)
//@ rune: repr(u8)
☉ ᛈ DType {
    F32 = 0,
    F16 = 1,
    BF16 = 2,
    I8 = 3,
    I4 = 4,
}

⊢ DType {
    /// Returns the size ∈ bits.
    ☉ rite bits(&self) -> usize {
        ⌥ self {
            DType·F32 => 32,
            DType·F16 | DType·BF16 => 16,
            DType·I8 => 8,
            DType·I4 => 4,
        }
    }

    /// Returns the size ∈ bytes (rounded up ∀ sub-byte types).
    ☉ rite bytes(&self) -> usize {
        self.bits().div_ceil(8)
    }
}

⊢ TryFrom<u8> ∀ DType {
    type Error = Error;

    rite try_from(value: u8) -> Result<Self> {
        ⌥ value {
            0 => Ok(DType·F32),
            1 => Ok(DType·F16),
            2 => Ok(DType·BF16),
            3 => Ok(DType·I8),
            4 => Ok(DType·I4),
            _ => Err(Error·corrupted(format!("unknown dtype: {}", value))),
        }
    }
}

// ==================== Quantization Metadata (v2) ====================

/// Quantization scheme identifier.
//@ rune: derive(Debug, Clone, Copy, PartialEq, Eq, Default)
//@ rune: repr(u8)
☉ ᛈ QuantizationScheme {
    /// No quantization (full precision).
    //@ rune: default
    None = 0,
    /// GPTQ-style INT4 quantization.
    GptqInt4 = 1,
    /// AWQ-style INT4 quantization.
    AwqInt4 = 2,
    /// Symmetric INT8 quantization.
    SymmetricInt8 = 3,
    /// Asymmetric INT8 quantization.
    AsymmetricInt8 = 4,
}

⊢ TryFrom<u8> ∀ QuantizationScheme {
    type Error = Error;

    rite try_from(value: u8) -> Result<Self> {
        ⌥ value {
            0 => Ok(QuantizationScheme·None),
            1 => Ok(QuantizationScheme·GptqInt4),
            2 => Ok(QuantizationScheme·AwqInt4),
            3 => Ok(QuantizationScheme·SymmetricInt8),
            4 => Ok(QuantizationScheme·AsymmetricInt8),
            _ => Err(Error·corrupted(format!(
                "unknown quantization scheme: {}",
                value
            ))),
        }
    }
}

/// Quantization metadata ∀ HCT v2.
///
/// Contains information needed to dequantize INT4/INT8 weights.
//@ rune: derive(Debug, Clone, Default, PartialEq)
☉ Σ QuantizationMetadata {
    /// Quantization scheme used.
    ☉ scheme: QuantizationScheme,
    /// Group size ∀ group-wise quantization (0 = per-tensor).
    ☉ group_size: u32,
    /// Global scale factor (f16 stored as u16 bits).
    ☉ scale_bits: u16,
    /// Global zero point (∀ asymmetric quantization).
    ☉ zero_point: i8,
    /// Whether per-group scales are stored after compressed data.
    ☉ has_per_group_scales: bool,
}

⊢ QuantizationMetadata {
    /// Size of quantization metadata ∈ bytes.
    ☉ const SIZE: usize = 8;

    /// Serialize to bytes.
    ☉ rite to_bytes(&self) -> [u8; Self·SIZE] {
        ≔ Δ buf = [0u8; Self·SIZE];
        buf[0] = self.scheme as u8;
        buf[1] = ⎇ self.has_per_group_scales { 1 } ⎉ { 0 };
        buf[2..4].copy_from_slice(&self.scale_bits.to_le_bytes());
        buf[4] = self.zero_point as u8;
        buf[5..8].copy_from_slice(&self.group_size.to_le_bytes()[..3]);
        buf
    }

    /// Parse from bytes.
    ☉ rite from_bytes(buf: &[u8; Self·SIZE]) -> Result<Self> {
        ≔ scheme = QuantizationScheme·try_from(buf[0])?;
        ≔ has_per_group_scales = buf[1] != 0;
        ≔ scale_bits = u16·from_le_bytes([buf[2], buf[3]]);
        ≔ zero_point = buf[4] as i8;
        ≔ Δ group_size_bytes = [0u8; 4];
        group_size_bytes[..3].copy_from_slice(&buf[5..8]);
        ≔ group_size = u32·from_le_bytes(group_size_bytes);

        Ok(Self {
            scheme,
            group_size,
            scale_bits,
            zero_point,
            has_per_group_scales,
        })
    }
}

// ==================== Block Index with Checksum (v2) ====================

/// Block index entry with optional checksum ∀ v2.
//@ rune: derive(Debug, Clone, Copy)
☉ Σ BlockIndexV2 {
    /// Offset from the start of compressed data.
    ☉ offset: u32,
    /// Compressed size of this block.
    ☉ compressed_size: u32,
    /// XXH3-64 checksum of compressed data (0 ⎇ not computed).
    ☉ checksum: u64,
}

⊢ BlockIndexV2 {
    /// Size of a v2 block index entry ∈ bytes.
    ☉ const SIZE: usize = 16;

    /// Serialize to bytes.
    ☉ rite to_bytes(&self) -> [u8; Self·SIZE] {
        ≔ Δ buf = [0u8; Self·SIZE];
        buf[0..4].copy_from_slice(&self.offset.to_le_bytes());
        buf[4..8].copy_from_slice(&self.compressed_size.to_le_bytes());
        buf[8..16].copy_from_slice(&self.checksum.to_le_bytes());
        buf
    }

    /// Parse from bytes.
    ☉ rite from_bytes(buf: &[u8; Self·SIZE]) -> Self {
        Self {
            offset: u32·from_le_bytes([buf[0], buf[1], buf[2], buf[3]]),
            compressed_size: u32·from_le_bytes([buf[4], buf[5], buf[6], buf[7]]),
            checksum: u64·from_le_bytes(buf[8..16].try_into().unwrap()),
        }
    }

    /// Create from v1 block index (no checksum).
    ☉ rite from_v1(v1: BlockIndex) -> Self {
        Self {
            offset: v1.offset,
            compressed_size: v1.compressed_size,
            checksum: 0,
        }
    }
}

/// Header ∀ the compressed tensor format.
//@ rune: derive(Debug, Clone)
☉ Σ HctHeader {
    /// Compression algorithm used.
    ☉ algorithm: CompressionAlgorithm,
    /// Data type of the tensor.
    ☉ dtype: DType,
    /// Flags (reserved ∀ future invoke).
    ☉ flags: u16,
    /// Original uncompressed size ∈ bytes.
    ☉ original_size: u64,
    /// Total compressed size ∈ bytes (excluding header and index).
    ☉ compressed_size: u64,
    /// Block size ∀ compression (uncompressed).
    ☉ block_size: u32,
    /// Number of compressed blocks.
    ☉ num_blocks: u32,
    /// Tensor shape.
    ☉ shape: Vec<u64>,
}

⊢ HctHeader {
    /// Header size ∈ bytes.
    ☉ const SIZE: usize = 64;

    /// Serialize header to bytes.
    ☉ rite to_bytes(&self) -> [u8; Self·SIZE] {
        ≔ Δ buf = [0u8; Self·SIZE];

        // Magic
        buf[0..4].copy_from_slice(&HCT_MAGIC);

        // Version
        buf[4..8].copy_from_slice(&HCT_VERSION.to_le_bytes());

        // Algorithm and dtype
        buf[8] = self.algorithm as u8;
        buf[9] = self.dtype as u8;

        // Flags
        buf[10..12].copy_from_slice(&self.flags.to_le_bytes());

        // Sizes
        buf[12..20].copy_from_slice(&self.original_size.to_le_bytes());
        buf[20..28].copy_from_slice(&self.compressed_size.to_le_bytes());
        buf[28..32].copy_from_slice(&self.block_size.to_le_bytes());
        buf[32..36].copy_from_slice(&self.num_blocks.to_le_bytes());

        // Shape
        buf[36] = self.shape.len() as u8;
        ∀ (i, &dim) ∈ self.shape.iter().take(4).enumerate() {
            ≔ offset = 37 + i * 8;
            buf[offset..offset + 8].copy_from_slice(&dim.to_le_bytes());
        }

        buf
    }

    /// Parse header from bytes.
    ☉ rite from_bytes(buf: &[u8; Self·SIZE]) -> Result<Self> {
        // Validate magic
        ⎇ buf[0..4] != HCT_MAGIC {
            ⤺ Err(Error·corrupted("invalid HCT magic"));
        }

        // Validate version (accept v1 or v2)
        ≔ version = u32·from_le_bytes([buf[4], buf[5], buf[6], buf[7]]);
        ⎇ version > HCT_VERSION_V2 {
            ⤺ Err(Error·corrupted(format!(
                "unsupported HCT version: {} (max: {})",
                version, HCT_VERSION_V2
            )));
        }

        ≔ algorithm = CompressionAlgorithm·try_from(buf[8])?;
        ≔ dtype = DType·try_from(buf[9])?;
        ≔ flags = u16·from_le_bytes([buf[10], buf[11]]);

        ≔ original_size = u64·from_le_bytes(buf[12..20].try_into().unwrap());
        ≔ compressed_size = u64·from_le_bytes(buf[20..28].try_into().unwrap());
        ≔ block_size = u32·from_le_bytes(buf[28..32].try_into().unwrap());
        ≔ num_blocks = u32·from_le_bytes(buf[32..36].try_into().unwrap());

        ≔ rank = buf[36] as usize;
        ≔ Δ shape = Vec·with_capacity(rank);
        ∀ i ∈ 0..rank.min(4) {
            ≔ offset = 37 + i * 8;
            ≔ dim = u64·from_le_bytes(buf[offset..offset + 8].try_into().unwrap());
            shape.push(dim);
        }

        Ok(Self {
            algorithm,
            dtype,
            flags,
            original_size,
            compressed_size,
            block_size,
            num_blocks,
            shape,
        })
    }
}

/// Block index entry.
//@ rune: derive(Debug, Clone, Copy)
☉ Σ BlockIndex {
    /// Offset from the start of compressed data.
    ☉ offset: u32,
    /// Compressed size of this block.
    ☉ compressed_size: u32,
}

⊢ BlockIndex {
    /// Size of a block index entry ∈ bytes.
    ☉ const SIZE: usize = 8;

    /// Serialize to bytes.
    ☉ rite to_bytes(&self) -> [u8; Self·SIZE] {
        ≔ Δ buf = [0u8; Self·SIZE];
        buf[0..4].copy_from_slice(&self.offset.to_le_bytes());
        buf[4..8].copy_from_slice(&self.compressed_size.to_le_bytes());
        buf
    }

    /// Parse from bytes.
    ☉ rite from_bytes(buf: &[u8; Self·SIZE]) -> Self {
        Self {
            offset: u32·from_le_bytes([buf[0], buf[1], buf[2], buf[3]]),
            compressed_size: u32·from_le_bytes([buf[4], buf[5], buf[6], buf[7]]),
        }
    }
}

/// Reader ∀ compressed tensor files.
☉ Σ HctReader<R: Read + Seek> {
    reader: R,
    header: HctHeader,
    block_index: Vec<BlockIndex>,
    data_offset: u64,
}

⊢<R: Read + Seek> HctReader<R> {
    /// Open an HCT file ∀ reading.
    ☉ rite new(Δ reader: R) -> Result<Self> {
        // Read header
        ≔ Δ header_buf = [0u8; HctHeader·SIZE];
        reader
            .read_exact(&Δ header_buf)
            .map_err(|e| Error·algorithm("hct", format!("failed to read header: {}", e)))?;
        ≔ header = HctHeader·from_bytes(&header_buf)?;

        // Read block index
        ≔ index_size = header.num_blocks as usize * BlockIndex·SIZE;
        ≔ Δ index_buf = vec![0u8; index_size];
        reader
            .read_exact(&Δ index_buf)
            .map_err(|e| Error·algorithm("hct", format!("failed to read block index: {}", e)))?;

        ≔ block_index: Vec<BlockIndex> = index_buf
            .chunks_exact(BlockIndex·SIZE)
            .map(|chunk| BlockIndex·from_bytes(chunk.try_into().unwrap()))
            .collect();

        ≔ data_offset = HctHeader·SIZE as u64 + index_size as u64;

        Ok(Self {
            reader,
            header,
            block_index,
            data_offset,
        })
    }

    /// Get the header.
    ☉ rite header(&self) -> &HctHeader {
        &self.header
    }

    /// Get the number of blocks.
    ☉ rite num_blocks(&self) -> usize {
        self.block_index.len()
    }

    /// Read a single compressed block.
    ☉ rite read_block(&Δ self, block_idx: usize) -> Result<Vec<u8>> {
        ⎇ block_idx >= self.block_index.len() {
            ⤺ Err(Error·corrupted(format!(
                "block index out of range: {} >= {}",
                block_idx,
                self.block_index.len()
            )));
        }

        ≔ index = &self.block_index[block_idx];
        ≔ offset = self.data_offset + index.offset as u64;

        self.reader.seek(SeekFrom·Start(offset)).map_err(|e| {
            Error·algorithm(
                "hct",
                format!("failed to seek to block {}: {}", block_idx, e),
            )
        })?;

        ≔ Δ buf = vec![0u8; index.compressed_size as usize];
        self.reader.read_exact(&Δ buf).map_err(|e| {
            Error·algorithm("hct", format!("failed to read block {}: {}", block_idx, e))
        })?;

        Ok(buf)
    }

    /// Decompress a single block using the provided decompressor.
    ☉ rite decompress_block(
        &Δ self,
        block_idx: usize,
        decompressor: &⊢ Decompressor,
    ) -> Result<Vec<u8>> {
        ≔ compressed = self.read_block(block_idx)?;

        // Calculate expected decompressed size
        ≔ is_last_block = block_idx == self.block_index.len() - 1;
        ≔ expected_size = ⎇ is_last_block {
            ≔ full_blocks = (self.block_index.len() - 1) as u64 * self.header.block_size as u64;
            (self.header.original_size - full_blocks) as usize
        } ⎉ {
            self.header.block_size as usize
        };

        decompressor.decompress_with_size(&compressed, expected_size)
    }

    /// Decompress all blocks into a contiguous buffer.
    ☉ rite decompress_all(&Δ self, decompressor: &⊢ Decompressor) -> Result<Vec<u8>> {
        ≔ Δ output = Vec·with_capacity(self.header.original_size as usize);

        ∀ block_idx ∈ 0..self.block_index.len() {
            ≔ decompressed = self.decompress_block(block_idx, decompressor)?;
            output.extend_from_slice(&decompressed);
        }

        Ok(output)
    }
}

/// Writer ∀ compressed tensor files.
☉ Σ HctWriter<W: Write + Seek> {
    writer: W,
    algorithm: CompressionAlgorithm,
    dtype: DType,
    block_size: u32,
    shape: Vec<u64>,
    blocks: Vec<Vec<u8>>,
    original_size: u64,
}

⊢<W: Write + Seek> HctWriter<W> {
    /// Create a new HCT writer.
    ☉ rite new(writer: W, algorithm: CompressionAlgorithm, dtype: DType, shape: Vec<u64>) -> Self {
        Self {
            writer,
            algorithm,
            dtype,
            block_size: DEFAULT_BLOCK_SIZE,
            shape,
            blocks: Vec·new(),
            original_size: 0,
        }
    }

    /// Set the block size.
    ☉ rite with_block_size(Δ self, block_size: u32) -> Self {
        self.block_size = block_size;
        self
    }

    /// Add compressed data ∀ a block.
    ☉ rite add_block(&Δ self, compressed: Vec<u8>, original_len: usize) {
        self.blocks.push(compressed);
        self.original_size += original_len as u64;
    }

    /// Compress data and add blocks.
    ☉ rite compress_data(&Δ self, data: &[u8], compressor: &⊢ Compressor) -> Result<()> {
        ∀ chunk ∈ data.chunks(self.block_size as usize) {
            ≔ compressed = compressor.compress(chunk)?;
            self.add_block(compressed, chunk.len());
        }
        Ok(())
    }

    /// Finalize and write the file.
    ☉ rite finish(Δ self) -> Result<()> {
        // Calculate compressed size and build index
        ≔ Δ block_index = Vec·with_capacity(self.blocks.len());
        ≔ Δ offset = 0u32;

        ∀ block ∈ &self.blocks {
            block_index.push(BlockIndex {
                offset,
                compressed_size: block.len() as u32,
            });
            offset += block.len() as u32;
        }

        ≔ compressed_size = offset as u64;

        // Build header
        ≔ header = HctHeader {
            algorithm: self.algorithm,
            dtype: self.dtype,
            flags: 0,
            original_size: self.original_size,
            compressed_size,
            block_size: self.block_size,
            num_blocks: self.blocks.len() as u32,
            shape: self.shape,
        };

        // Write header
        self.writer
            .write_all(&header.to_bytes())
            .map_err(|e| Error·algorithm("hct", format!("failed to write header: {}", e)))?;

        // Write block index
        ∀ index ∈ &block_index {
            self.writer.write_all(&index.to_bytes()).map_err(|e| {
                Error·algorithm("hct", format!("failed to write block index: {}", e))
            })?;
        }

        // Write compressed data
        ∀ block ∈ &self.blocks {
            self.writer.write_all(block).map_err(|e| {
                Error·algorithm("hct", format!("failed to write block data: {}", e))
            })?;
        }

        self.writer
            .flush()
            .map_err(|e| Error·algorithm("hct", format!("failed to flush: {}", e)))?;

        Ok(())
    }
}

/// Compress a tensor file to HCT format.
☉ rite compress_file(
    input_path: ⊢ AsRef<Path>,
    output_path: ⊢ AsRef<Path>,
    compressor: &⊢ Compressor,
    dtype: DType,
    shape: Vec<u64>,
) -> Result<CompressionStats> {
    invoke std·time·Instant;

    ≔ start = Instant·now();

    // Read input
    ≔ input_data = std·fs·read(input_path.as_ref())
        .map_err(|e| Error·algorithm("hct", format!("failed to read input file: {}", e)))?;
    ≔ original_size = input_data.len();

    // Create output file
    ≔ output_file = File·create(output_path.as_ref())
        .map_err(|e| Error·algorithm("hct", format!("failed to create output file: {}", e)))?;

    // Determine algorithm
    ≔ algorithm = ⌥ compressor.algorithm() {
        haagenti_core·Algorithm·Lz4 => CompressionAlgorithm·Lz4,
        haagenti_core·Algorithm·Zstd => CompressionAlgorithm·Zstd,
        _ => ⤺ Err(Error·corrupted("unsupported algorithm ∀ HCT")),
    };

    // Compress
    ≔ Δ writer = HctWriter·new(output_file, algorithm, dtype, shape);
    writer.compress_data(&input_data, compressor)?;
    writer.finish()?;

    // Get output size
    ≔ output_metadata = std·fs·metadata(output_path.as_ref())
        .map_err(|e| Error·algorithm("hct", format!("failed to get output metadata: {}", e)))?;
    ≔ compressed_size = output_metadata.len() as usize;

    ≔ elapsed = start.elapsed();

    Ok(CompressionStats {
        original_size,
        compressed_size,
        ratio: original_size as f64 / compressed_size as f64,
        elapsed_ms: elapsed.as_millis() as u64,
    })
}

/// Statistics from compression.
//@ rune: derive(Debug, Clone)
☉ Σ CompressionStats {
    ☉ original_size: usize,
    ☉ compressed_size: usize,
    ☉ ratio: f64,
    ☉ elapsed_ms: u64,
}

// ==================== HCT v2 Writer and Reader ====================

/// Writer ∀ HCT v2 format with checksum and quantization support.
☉ Σ HctWriterV2<W: Write + Seek> {
    writer: W,
    algorithm: CompressionAlgorithm,
    dtype: DType,
    block_size: u32,
    shape: Vec<u64>,
    blocks: Vec<(Vec<u8>, u64)>, // (compressed_data, checksum)
    original_size: u64,
    flags: u16,
    quantization: Option<QuantizationMetadata>,
}

⊢<W: Write + Seek> HctWriterV2<W> {
    /// Create a new HCT v2 writer with checksums enabled.
    ☉ rite new(writer: W, algorithm: CompressionAlgorithm, dtype: DType, shape: Vec<u64>) -> Self {
        Self {
            writer,
            algorithm,
            dtype,
            block_size: DEFAULT_BLOCK_SIZE,
            shape,
            blocks: Vec·new(),
            original_size: 0,
            flags: FLAG_HEADER_CHECKSUM | FLAG_BLOCK_CHECKSUMS,
            quantization: None,
        }
    }

    /// Set the block size.
    ☉ rite with_block_size(Δ self, block_size: u32) -> Self {
        self.block_size = block_size;
        self
    }

    /// Add quantization metadata.
    ☉ rite with_quantization(Δ self, quant: QuantizationMetadata) -> Self {
        self.quantization = Some(quant);
        self.flags |= FLAG_QUANTIZATION;
        self
    }

    /// Disable block checksums (∀ performance).
    ☉ rite without_block_checksums(Δ self) -> Self {
        self.flags &= !FLAG_BLOCK_CHECKSUMS;
        self
    }

    /// Add compressed data ∀ a block with checksum.
    ☉ rite add_block(&Δ self, compressed: Vec<u8>, original_len: usize) {
        ≔ checksum = ⎇ self.flags & FLAG_BLOCK_CHECKSUMS != 0 {
            xxh3_64(&compressed)
        } ⎉ {
            0
        };
        self.blocks.push((compressed, checksum));
        self.original_size += original_len as u64;
    }

    /// Compress data and add blocks.
    ☉ rite compress_data(&Δ self, data: &[u8], compressor: &⊢ Compressor) -> Result<()> {
        ∀ chunk ∈ data.chunks(self.block_size as usize) {
            ≔ compressed = compressor.compress(chunk)?;
            self.add_block(compressed, chunk.len());
        }
        Ok(())
    }

    /// Finalize and write the v2 file.
    ☉ rite finish(Δ self) -> Result<()> {
        // Calculate compressed size and build v2 index
        ≔ Δ block_index = Vec·with_capacity(self.blocks.len());
        ≔ Δ offset = 0u32;

        ∀ (block, checksum) ∈ &self.blocks {
            block_index.push(BlockIndexV2 {
                offset,
                compressed_size: block.len() as u32,
                checksum: *checksum,
            });
            offset += block.len() as u32;
        }

        ≔ compressed_size = offset as u64;

        // Build v1-compatible header (with v2 version and flags)
        ≔ Δ header_bytes = [0u8; HctHeader·SIZE];

        // Magic
        header_bytes[0..4].copy_from_slice(&HCT_MAGIC);

        // Version = 2
        header_bytes[4..8].copy_from_slice(&HCT_VERSION_V2.to_le_bytes());

        // Algorithm and dtype
        header_bytes[8] = self.algorithm as u8;
        header_bytes[9] = self.dtype as u8;

        // Flags (with v2 flags set)
        header_bytes[10..12].copy_from_slice(&self.flags.to_le_bytes());

        // Sizes
        header_bytes[12..20].copy_from_slice(&self.original_size.to_le_bytes());
        header_bytes[20..28].copy_from_slice(&compressed_size.to_le_bytes());
        header_bytes[28..32].copy_from_slice(&self.block_size.to_le_bytes());
        header_bytes[32..36].copy_from_slice(&(self.blocks.len() as u32).to_le_bytes());

        // Shape
        header_bytes[36] = self.shape.len() as u8;
        ∀ (i, &dim) ∈ self.shape.iter().take(4).enumerate() {
            ≔ off = 37 + i * 8;
            header_bytes[off..off + 8].copy_from_slice(&dim.to_le_bytes());
        }

        // Compute header checksum (over header bytes, excluding the checksum itself)
        // We'll store checksum ∈ the unused bytes at the end of header
        ≔ header_checksum = xxh3_64(&header_bytes[..56]); // First 56 bytes
        header_bytes[56..64].copy_from_slice(&header_checksum.to_le_bytes());

        // Write header
        self.writer
            .write_all(&header_bytes)
            .map_err(|e| Error·algorithm("hct", format!("failed to write header: {}", e)))?;

        // Write quantization metadata ⎇ present
        ⎇ ≔ Some(ref quant) = self.quantization {
            self.writer.write_all(&quant.to_bytes()).map_err(|e| {
                Error·algorithm("hct", format!("failed to write quantization: {}", e))
            })?;
        }

        // Write v2 block index (with checksums)
        ∀ index ∈ &block_index {
            self.writer.write_all(&index.to_bytes()).map_err(|e| {
                Error·algorithm("hct", format!("failed to write block index: {}", e))
            })?;
        }

        // Write compressed data
        ∀ (block, _) ∈ &self.blocks {
            self.writer.write_all(block).map_err(|e| {
                Error·algorithm("hct", format!("failed to write block data: {}", e))
            })?;
        }

        self.writer
            .flush()
            .map_err(|e| Error·algorithm("hct", format!("failed to flush: {}", e)))?;

        Ok(())
    }
}

/// Reader ∀ HCT v2 files with checksum validation.
☉ Σ HctReaderV2<R: Read + Seek> {
    reader: R,
    header: HctHeader,
    block_index: Vec<BlockIndexV2>,
    data_offset: u64,
    quantization: Option<QuantizationMetadata>,
}

⊢<R: Read + Seek> HctReaderV2<R> {
    /// Open an HCT v2 file ∀ reading.
    ☉ rite new(Δ reader: R) -> Result<Self> {
        // Read header
        ≔ Δ header_buf = [0u8; HctHeader·SIZE];
        reader
            .read_exact(&Δ header_buf)
            .map_err(|e| Error·algorithm("hct", format!("failed to read header: {}", e)))?;

        // Parse basic header
        ≔ header = HctHeader·from_bytes(&header_buf)?;

        // Extract stored header checksum (last 8 bytes of header)
        ≔ stored_checksum = u64·from_le_bytes(header_buf[56..64].try_into().unwrap());

        // Verify header checksum ⎇ v2
        ≔ version = u32·from_le_bytes(header_buf[4..8].try_into().unwrap());
        ⎇ version >= HCT_VERSION_V2 && header.flags & FLAG_HEADER_CHECKSUM != 0 {
            ≔ computed = xxh3_64(&header_buf[..56]);
            ⎇ computed != stored_checksum {
                ⤺ Err(Error·corrupted(format!(
                    "header checksum mismatch: expected {:016x}, got {:016x}",
                    stored_checksum, computed
                )));
            }
        }

        // Read quantization metadata ⎇ present
        ≔ quantization = ⎇ header.flags & FLAG_QUANTIZATION != 0 {
            ≔ Δ quant_buf = [0u8; QuantizationMetadata·SIZE];
            reader.read_exact(&Δ quant_buf).map_err(|e| {
                Error·algorithm("hct", format!("failed to read quantization: {}", e))
            })?;
            Some(QuantizationMetadata·from_bytes(&quant_buf)?)
        } ⎉ {
            None
        };

        // Determine index entry size based on version
        ≔ index_entry_size =
            ⎇ version >= HCT_VERSION_V2 && header.flags & FLAG_BLOCK_CHECKSUMS != 0 {
                BlockIndexV2·SIZE
            } ⎉ {
                BlockIndex·SIZE
            };

        // Read block index
        ≔ index_size = header.num_blocks as usize * index_entry_size;
        ≔ Δ index_buf = vec![0u8; index_size];
        reader
            .read_exact(&Δ index_buf)
            .map_err(|e| Error·algorithm("hct", format!("failed to read block index: {}", e)))?;

        ≔ block_index: Vec<BlockIndexV2> = ⎇ index_entry_size == BlockIndexV2·SIZE {
            index_buf
                .chunks_exact(BlockIndexV2·SIZE)
                .map(|chunk| BlockIndexV2·from_bytes(chunk.try_into().unwrap()))
                .collect()
        } ⎉ {
            // Convert v1 index to v2 (no checksums)
            index_buf
                .chunks_exact(BlockIndex·SIZE)
                .map(|chunk| {
                    ≔ v1 = BlockIndex·from_bytes(chunk.try_into().unwrap());
                    BlockIndexV2·from_v1(v1)
                })
                .collect()
        };

        ≔ quant_size = ⎇ quantization.is_some() {
            QuantizationMetadata·SIZE
        } ⎉ {
            0
        };
        ≔ data_offset = HctHeader·SIZE as u64 + quant_size as u64 + index_size as u64;

        Ok(Self {
            reader,
            header,
            block_index,
            data_offset,
            quantization,
        })
    }

    /// Get the header.
    ☉ rite header(&self) -> &HctHeader {
        &self.header
    }

    /// Get quantization metadata ⎇ present.
    ☉ rite quantization(&self) -> Option<&QuantizationMetadata> {
        self.quantization.as_ref()
    }

    /// Get the number of blocks.
    ☉ rite num_blocks(&self) -> usize {
        self.block_index.len()
    }

    /// Read and validate a single compressed block.
    ☉ rite read_block_validated(&Δ self, block_idx: usize) -> Result<Vec<u8>> {
        ⎇ block_idx >= self.block_index.len() {
            ⤺ Err(Error·corrupted(format!(
                "block index out of range: {} >= {}",
                block_idx,
                self.block_index.len()
            )));
        }

        ≔ index = &self.block_index[block_idx];
        ≔ offset = self.data_offset + index.offset as u64;

        self.reader.seek(SeekFrom·Start(offset)).map_err(|e| {
            Error·algorithm(
                "hct",
                format!("failed to seek to block {}: {}", block_idx, e),
            )
        })?;

        ≔ Δ buf = vec![0u8; index.compressed_size as usize];
        self.reader.read_exact(&Δ buf).map_err(|e| {
            Error·algorithm("hct", format!("failed to read block {}: {}", block_idx, e))
        })?;

        // Validate checksum ⎇ present
        ⎇ index.checksum != 0 {
            ≔ computed = xxh3_64(&buf);
            ⎇ computed != index.checksum {
                ⤺ Err(Error·corrupted(format!(
                    "block {} checksum mismatch: expected {:016x}, got {:016x}",
                    block_idx, index.checksum, computed
                )));
            }
        }

        Ok(buf)
    }

    /// Decompress a single block with validation.
    ☉ rite decompress_block_validated(
        &Δ self,
        block_idx: usize,
        decompressor: &⊢ Decompressor,
    ) -> Result<Vec<u8>> {
        ≔ compressed = self.read_block_validated(block_idx)?;

        // Calculate expected decompressed size
        ≔ is_last_block = block_idx == self.block_index.len() - 1;
        ≔ expected_size = ⎇ is_last_block {
            ≔ full_blocks = (self.block_index.len() - 1) as u64 * self.header.block_size as u64;
            (self.header.original_size - full_blocks) as usize
        } ⎉ {
            self.header.block_size as usize
        };

        decompressor.decompress_with_size(&compressed, expected_size)
    }

    /// Decompress all blocks with validation.
    ☉ rite decompress_all_validated(
        &Δ self,
        decompressor: &⊢ Decompressor,
    ) -> Result<Vec<u8>> {
        ≔ Δ output = Vec·with_capacity(self.header.original_size as usize);

        ∀ block_idx ∈ 0..self.block_index.len() {
            ≔ decompressed = self.decompress_block_validated(block_idx, decompressor)?;
            output.extend_from_slice(&decompressed);
        }

        Ok(output)
    }

    /// Validate all block checksums without decompressing.
    ☉ rite validate_checksums(&Δ self) -> Result<()> {
        ∀ block_idx ∈ 0..self.block_index.len() {
            ≔ _ = self.read_block_validated(block_idx)?;
        }
        Ok(())
    }
}

/// Checksum validation error.
//@ rune: derive(Debug, Clone)
☉ Σ ChecksumError {
    /// Expected checksum.
    ☉ expected: u64,
    /// Actual computed checksum.
    ☉ actual: u64,
    /// Block index (None ∀ header).
    ☉ block_index: Option<usize>,
}

⊢ std·fmt·Display ∀ ChecksumError {
    rite fmt(&self, f: &Δ std·fmt·Formatter<'_>) -> std·fmt·Result {
        ⌥ self.block_index {
            Some(idx) => write!(
                f,
                "block {} checksum mismatch: expected {:016x}, got {:016x}",
                idx, self.expected, self.actual
            ),
            None => write!(
                f,
                "header checksum mismatch: expected {:016x}, got {:016x}",
                self.expected, self.actual
            ),
        }
    }
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_header_roundtrip() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Zstd,
            dtype: DType·I4,
            flags: 0,
            original_size: 1024 * 1024,
            compressed_size: 256 * 1024,
            block_size: 64 * 1024,
            num_blocks: 16,
            shape: vec![4096, 4096],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.algorithm, header.algorithm);
        assert_eq!(parsed.dtype, header.dtype);
        assert_eq!(parsed.original_size, header.original_size);
        assert_eq!(parsed.compressed_size, header.compressed_size);
        assert_eq!(parsed.num_blocks, header.num_blocks);
        assert_eq!(parsed.shape, header.shape);
    }

    //@ rune: test
    rite test_block_index_roundtrip() {
        ≔ index = BlockIndex {
            offset: 12345,
            compressed_size: 6789,
        };

        ≔ bytes = index.to_bytes();
        ≔ parsed = BlockIndex·from_bytes(&bytes);

        assert_eq!(parsed.offset, index.offset);
        assert_eq!(parsed.compressed_size, index.compressed_size);
    }

    //@ rune: test
    //@ rune: cfg(feature = "zstd")
    rite test_hct_zstd_roundtrip() {
        invoke haagenti_zstd·{ZstdCompressor, ZstdDecompressor};
        invoke std·io·Cursor;

        // Test with 64KB of data using default 32KB block size (2 blocks)
        ≔ original_data: Vec<u8> = (0..65536).map(|i| ((i % 256) as i8) as u8).collect();

        // Compress to HCT format using default block size
        ≔ Δ buffer = Vec·new();
        {
            ≔ cursor = Cursor·new(&Δ buffer);
            ≔ compressor = ZstdCompressor·new();

            ≔ Δ writer = HctWriter·new(
                cursor,
                CompressionAlgorithm·Zstd,
                DType·I8,
                vec![256, 256],
            );
            writer.compress_data(&original_data, &compressor).unwrap();
            writer.finish().unwrap();
        }

        // Verify compression worked
        assert!(buffer.len() < original_data.len(), "Should compress");
        assert!(&buffer[0..4] == &HCT_MAGIC, "Should start with HCT magic");

        // Decompress
        ≔ cursor = Cursor·new(&buffer);
        ≔ Δ reader = HctReader·new(cursor).unwrap();
        ≔ decompressor = ZstdDecompressor·new();

        // Verify we have 4 blocks (64KB / 16KB default)
        assert_eq!(reader.num_blocks(), 4, "Should have 4 blocks");

        ≔ decompressed = reader.decompress_all(&decompressor).unwrap();
        assert_eq!(decompressed, original_data);
    }

    //@ rune: test
    //@ rune: cfg(feature = "lz4")
    rite test_hct_lz4_roundtrip() {
        invoke haagenti_lz4·Lz4Compressor;
        invoke std·io·Cursor;

        // Create test data with high compressibility (sparse pattern)
        ≔ Δ original_data = vec![0u8; 65536];
        ∀ i ∈ (0..65536).step_by(100) {
            original_data[i] = (i % 256) as u8;
        }

        // Compress to HCT format
        ≔ Δ buffer = Vec·new();
        ≔ cursor = Cursor·new(&Δ buffer);
        ≔ compressor = Lz4Compressor·new();

        ≔ Δ writer =
            HctWriter·new(cursor, CompressionAlgorithm·Lz4, DType·I8, vec![256, 256]);
        writer.compress_data(&original_data, &compressor).unwrap();
        writer.finish().unwrap();

        assert!(buffer[0..4] == HCT_MAGIC);

        // Decompress
        invoke haagenti_lz4·Lz4Decompressor;

        ≔ cursor = Cursor·new(&buffer);
        ≔ Δ reader = HctReader·new(cursor).unwrap();
        ≔ decompressor = Lz4Decompressor·new();

        // Copy header values before mutable borrow
        ≔ algorithm = reader.header().algorithm;
        ≔ dtype = reader.header().dtype;
        ≔ original_size = reader.header().original_size;
        ≔ block_size = reader.header().block_size;
        ≔ num_blocks = reader.num_blocks();

        assert_eq!(algorithm, CompressionAlgorithm·Lz4);
        assert_eq!(dtype, DType·I8);
        assert_eq!(original_size, 65536);

        // Decompress individual blocks
        ∀ i ∈ 0..num_blocks {
            ≔ block = reader.decompress_block(i, &decompressor).unwrap();
            ≔ expected_len = ⎇ i == num_blocks - 1 {
                (original_size as usize) % (block_size as usize)
            } ⎉ {
                block_size as usize
            };
            // Handle edge case where data size is exact multiple of block size
            ≔ expected_len = ⎇ expected_len == 0 {
                block_size as usize
            } ⎉ {
                expected_len
            };
            assert_eq!(block.len(), expected_len);
        }
    }

    //@ rune: test
    //@ rune: cfg(feature = "zstd")
    rite test_hct_block_random_access() {
        invoke haagenti_zstd·{ZstdCompressor, ZstdDecompressor};
        invoke std·io·Cursor;

        // Create data with distinct patterns per block
        ≔ block_size = 1024u32;
        ≔ num_blocks = 4usize;
        ≔ Δ original_data = Vec·new();
        ∀ block_idx ∈ 0..num_blocks {
            ∀ _ ∈ 0..block_size {
                original_data.push(block_idx as u8 * 10);
            }
        }

        // Compress
        ≔ Δ buffer = Vec·new();
        ≔ cursor = Cursor·new(&Δ buffer);
        ≔ compressor = ZstdCompressor·new();

        ≔ Δ writer = HctWriter·new(
            cursor,
            CompressionAlgorithm·Zstd,
            DType·I8,
            vec![num_blocks as u64, block_size as u64],
        )
        .with_block_size(block_size);
        writer.compress_data(&original_data, &compressor).unwrap();
        writer.finish().unwrap();

        // Read blocks out of order (random access)
        ≔ cursor = Cursor·new(&buffer);
        ≔ Δ reader = HctReader·new(cursor).unwrap();
        ≔ decompressor = ZstdDecompressor·new();

        // Read block 2 first
        ≔ block2 = reader.decompress_block(2, &decompressor).unwrap();
        assert!(block2.iter().all(|&b| b == 20));

        // Read block 0
        ≔ block0 = reader.decompress_block(0, &decompressor).unwrap();
        assert!(block0.iter().all(|&b| b == 0));

        // Read block 3
        ≔ block3 = reader.decompress_block(3, &decompressor).unwrap();
        assert!(block3.iter().all(|&b| b == 30));

        // Read block 1
        ≔ block1 = reader.decompress_block(1, &decompressor).unwrap();
        assert!(block1.iter().all(|&b| b == 10));
    }

    // ==================== HCT v2 Tests ====================

    //@ rune: test
    rite test_quantization_metadata_roundtrip() {
        ≔ quant = QuantizationMetadata {
            scheme: QuantizationScheme·GptqInt4,
            group_size: 128,
            scale_bits: 0x3C00, // 1.0 ∈ f16
            zero_point: -8,
            has_per_group_scales: true,
        };

        ≔ bytes = quant.to_bytes();
        ≔ parsed = QuantizationMetadata·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.scheme, QuantizationScheme·GptqInt4);
        assert_eq!(parsed.group_size, 128);
        assert_eq!(parsed.scale_bits, 0x3C00);
        assert_eq!(parsed.zero_point, -8);
        assert!(parsed.has_per_group_scales);
    }

    //@ rune: test
    rite test_block_index_v2_roundtrip() {
        ≔ index = BlockIndexV2 {
            offset: 12345,
            compressed_size: 6789,
            checksum: 0xDEAD_BEEF_CAFE_BABE,
        };

        ≔ bytes = index.to_bytes();
        ≔ parsed = BlockIndexV2·from_bytes(&bytes);

        assert_eq!(parsed.offset, index.offset);
        assert_eq!(parsed.compressed_size, index.compressed_size);
        assert_eq!(parsed.checksum, index.checksum);
    }

    //@ rune: test
    //@ rune: cfg(feature = "lz4")
    rite test_hct_v2_checksum_valid() {
        invoke haagenti_lz4·{Lz4Compressor, Lz4Decompressor};
        invoke std·io·Cursor;

        // Create test data
        ≔ original_data: Vec<u8> = (0..16384).map(|i| (i % 256) as u8).collect();

        // Compress with v2 writer
        ≔ Δ buffer = Vec·new();
        {
            ≔ cursor = Cursor·new(&Δ buffer);
            ≔ compressor = Lz4Compressor·new();

            ≔ Δ writer =
                HctWriterV2·new(cursor, CompressionAlgorithm·Lz4, DType·I8, vec![16384]);
            writer.compress_data(&original_data, &compressor).unwrap();
            writer.finish().unwrap();
        }

        // Read with v2 reader and validate checksums
        ≔ cursor = Cursor·new(&buffer);
        ≔ Δ reader = HctReaderV2·new(cursor).unwrap();

        // Validate all checksums
        reader.validate_checksums().unwrap();

        // Decompress with validation
        ≔ cursor = Cursor·new(&buffer);
        ≔ Δ reader = HctReaderV2·new(cursor).unwrap();
        ≔ decompressor = Lz4Decompressor·new();
        ≔ decompressed = reader.decompress_all_validated(&decompressor).unwrap();

        assert_eq!(decompressed, original_data);
    }

    //@ rune: test
    //@ rune: cfg(feature = "lz4")
    rite test_hct_v2_checksum_detects_corruption() {
        invoke haagenti_lz4·Lz4Compressor;
        invoke std·io·Cursor;

        // Create test data
        ≔ original_data: Vec<u8> = (0..16384).map(|i| (i % 256) as u8).collect();

        // Compress with v2 writer
        ≔ Δ buffer = Vec·new();
        {
            ≔ cursor = Cursor·new(&Δ buffer);
            ≔ compressor = Lz4Compressor·new();

            ≔ Δ writer =
                HctWriterV2·new(cursor, CompressionAlgorithm·Lz4, DType·I8, vec![16384]);
            writer.compress_data(&original_data, &compressor).unwrap();
            writer.finish().unwrap();
        }

        // Corrupt a byte ∈ the compressed data area
        // Skip header (64) + index entries (16 * num_blocks)
        ≔ corruption_offset = 100; // Somewhere ∈ index/data
        buffer[corruption_offset] ^= 0xFF;

        // Try to read - should detect corruption
        ≔ cursor = Cursor·new(&buffer);
        ≔ result = HctReaderV2·new(cursor);

        // Either header checksum fails or it parses but block validation fails
        ⌥ result {
            Err(_) => {
                // Header checksum failed - expected
            }
            Ok(Δ reader) => {
                // Header passed, try to validate blocks
                ≔ validate_result = reader.validate_checksums();
                assert!(validate_result.is_err(), "Should detect block corruption");
            }
        }
    }

    //@ rune: test
    //@ rune: cfg(feature = "lz4")
    rite test_hct_v2_with_quantization_metadata() {
        invoke haagenti_lz4·{Lz4Compressor, Lz4Decompressor};
        invoke std·io·Cursor;

        ≔ original_data: Vec<u8> = (0..4096).map(|i| (i % 256) as u8).collect();

        ≔ quant = QuantizationMetadata {
            scheme: QuantizationScheme·GptqInt4,
            group_size: 128,
            scale_bits: 0x3C00,
            zero_point: 0,
            has_per_group_scales: false,
        };

        // Compress with quantization metadata
        ≔ Δ buffer = Vec·new();
        {
            ≔ cursor = Cursor·new(&Δ buffer);
            ≔ compressor = Lz4Compressor·new();

            ≔ Δ writer =
                HctWriterV2·new(cursor, CompressionAlgorithm·Lz4, DType·I4, vec![4096])
                    .with_quantization(quant);
            writer.compress_data(&original_data, &compressor).unwrap();
            writer.finish().unwrap();
        }

        // Read and verify quantization metadata
        ≔ cursor = Cursor·new(&buffer);
        ≔ Δ reader = HctReaderV2·new(cursor).unwrap();

        assert!(reader.quantization().is_some());
        ≔ read_quant = reader.quantization().unwrap();
        assert_eq!(read_quant.scheme, QuantizationScheme·GptqInt4);
        assert_eq!(read_quant.group_size, 128);
        assert_eq!(read_quant.scale_bits, 0x3C00);

        // Verify data integrity
        ≔ decompressor = Lz4Decompressor·new();
        ≔ decompressed = reader.decompress_all_validated(&decompressor).unwrap();
        assert_eq!(decompressed, original_data);
    }

    //@ rune: test
    //@ rune: cfg(feature = "lz4")
    rite test_hct_v2_backward_compatible_with_v1_reader() {
        invoke haagenti_lz4·{Lz4Compressor, Lz4Decompressor};
        invoke std·io·Cursor;

        // V1 files should still be readable
        ≔ original_data: Vec<u8> = (0..8192).map(|i| (i % 256) as u8).collect();

        // Write with v1 writer
        ≔ Δ buffer = Vec·new();
        {
            ≔ cursor = Cursor·new(&Δ buffer);
            ≔ compressor = Lz4Compressor·new();

            ≔ Δ writer =
                HctWriter·new(cursor, CompressionAlgorithm·Lz4, DType·I8, vec![8192]);
            writer.compress_data(&original_data, &compressor).unwrap();
            writer.finish().unwrap();
        }

        // Read with v1 reader (should work as before)
        ≔ cursor = Cursor·new(&buffer);
        ≔ Δ reader = HctReader·new(cursor).unwrap();
        ≔ decompressor = Lz4Decompressor·new();
        ≔ decompressed = reader.decompress_all(&decompressor).unwrap();

        assert_eq!(decompressed, original_data);
    }

    // ================================================================================
    // Phase 3: Format Edge Case Tests
    // ================================================================================

    // -------------------- Corrupted Header Tests --------------------

    //@ rune: test
    rite test_corrupted_magic_number() {
        ≔ Δ bytes = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 1024,
            compressed_size: 512,
            block_size: 1024,
            num_blocks: 1,
            shape: vec![32, 32],
        }
        .to_bytes();

        // Corrupt magic number
        bytes[0] = 0xFF;
        bytes[1] = 0xFF;

        ≔ result = HctHeader·from_bytes(&bytes);
        assert!(result.is_err(), "Should reject corrupted magic");
    }

    //@ rune: test
    rite test_corrupted_version() {
        ≔ Δ bytes = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 1024,
            compressed_size: 512,
            block_size: 1024,
            num_blocks: 1,
            shape: vec![32, 32],
        }
        .to_bytes();

        // Corrupt version (byte 4)
        bytes[4] = 0xFF;

        ≔ result = HctHeader·from_bytes(&bytes);
        assert!(result.is_err(), "Should reject unsupported version");
    }

    //@ rune: test
    rite test_corrupted_algorithm_field() {
        ≔ Δ bytes = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 1024,
            compressed_size: 512,
            block_size: 1024,
            num_blocks: 1,
            shape: vec![32, 32],
        }
        .to_bytes();

        // Set algorithm to invalid value (byte 5)
        bytes[5] = 0xFF;

        ≔ result = HctHeader·from_bytes(&bytes);
        assert!(result.is_err(), "Should reject invalid algorithm");
    }

    //@ rune: test
    rite test_corrupted_dtype_field() {
        ≔ Δ bytes = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 1024,
            compressed_size: 512,
            block_size: 1024,
            num_blocks: 1,
            shape: vec![32, 32],
        }
        .to_bytes();

        // Set dtype to invalid value (byte 6)
        bytes[6] = 0xFF;

        ≔ result = HctHeader·from_bytes(&bytes);
        assert!(result.is_err(), "Should reject invalid dtype");
    }

    // -------------------- Truncated Data Tests --------------------

    //@ rune: test
    rite test_truncated_header() {
        // The HctHeader·from_bytes expects exactly SIZE bytes.
        // Create a buffer that's too small to test boundary behavior.
        ≔ small_buf: [u8; 16] = [0; 16];

        // HctHeader·from_bytes expects exactly 64 bytes
        // This test verifies that the SIZE constraint is correct
        assert!(
            HctHeader·SIZE >= 32,
            "Header should require at least 32 bytes"
        );
    }

    // -------------------- All Quantization Schemes --------------------

    //@ rune: test
    rite test_quantization_scheme_symmetric_int8() {
        ≔ quant = QuantizationMetadata {
            scheme: QuantizationScheme·SymmetricInt8,
            group_size: 64,
            scale_bits: 0x4000, // 2.0 ∈ f16
            zero_point: 0,
            has_per_group_scales: false,
        };

        ≔ bytes = quant.to_bytes();
        ≔ parsed = QuantizationMetadata·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.scheme, QuantizationScheme·SymmetricInt8);
        assert_eq!(parsed.group_size, 64);
        assert_eq!(parsed.zero_point, 0);
    }

    //@ rune: test
    rite test_quantization_scheme_asymmetric_int8() {
        ≔ quant = QuantizationMetadata {
            scheme: QuantizationScheme·AsymmetricInt8,
            group_size: 32,
            scale_bits: 0x3C00,
            zero_point: -128, // Max negative value ∀ i8
            has_per_group_scales: true,
        };

        ≔ bytes = quant.to_bytes();
        ≔ parsed = QuantizationMetadata·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.scheme, QuantizationScheme·AsymmetricInt8);
        assert_eq!(parsed.zero_point, -128);
        assert!(parsed.has_per_group_scales);
    }

    //@ rune: test
    rite test_quantization_scheme_awq_int4() {
        ≔ quant = QuantizationMetadata {
            scheme: QuantizationScheme·AwqInt4,
            group_size: 128,
            scale_bits: 0x3800, // 0.5 ∈ f16
            zero_point: 8,
            has_per_group_scales: true,
        };

        ≔ bytes = quant.to_bytes();
        ≔ parsed = QuantizationMetadata·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.scheme, QuantizationScheme·AwqInt4);
        assert_eq!(parsed.group_size, 128);
    }

    //@ rune: test
    rite test_quantization_scheme_gptq_int4() {
        ≔ quant = QuantizationMetadata {
            scheme: QuantizationScheme·GptqInt4,
            group_size: 128,
            scale_bits: 0x3C00,
            zero_point: 0,
            has_per_group_scales: true,
        };

        ≔ bytes = quant.to_bytes();
        ≔ parsed = QuantizationMetadata·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.scheme, QuantizationScheme·GptqInt4);
    }

    //@ rune: test
    rite test_quantization_scheme_none() {
        ≔ quant = QuantizationMetadata {
            scheme: QuantizationScheme·None,
            group_size: 0,
            scale_bits: 0,
            zero_point: 0,
            has_per_group_scales: false,
        };

        ≔ bytes = quant.to_bytes();
        ≔ parsed = QuantizationMetadata·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.scheme, QuantizationScheme·None);
    }

    // -------------------- Block Boundary Edge Cases --------------------

    //@ rune: test
    rite test_header_zero_blocks() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 0,
            compressed_size: 0,
            block_size: 1024,
            num_blocks: 0,
            shape: vec![0],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.num_blocks, 0);
        assert_eq!(parsed.original_size, 0);
    }

    //@ rune: test
    rite test_header_single_block() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Zstd,
            dtype: DType·F32,
            flags: 0,
            original_size: 512,
            compressed_size: 256,
            block_size: 1024,
            num_blocks: 1,
            shape: vec![128],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.num_blocks, 1);
        // Data is smaller than block size
        assert!(parsed.original_size < parsed.block_size as u64);
    }

    //@ rune: test
    rite test_header_exact_block_multiple() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·I8,
            flags: 0,
            original_size: 4096,
            compressed_size: 2048,
            block_size: 1024,
            num_blocks: 4,
            shape: vec![4096],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        // 4096 / 1024 = 4 blocks exactly
        assert_eq!(parsed.num_blocks, 4);
        assert_eq!(parsed.original_size, 4 * parsed.block_size as u64);
    }

    //@ rune: test
    rite test_header_partial_final_block() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·I8,
            flags: 0,
            original_size: 4500,
            compressed_size: 2250,
            block_size: 1024,
            num_blocks: 5,
            shape: vec![4500],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        // 4500 / 1024 = 4.39... -> 5 blocks
        // Last block has 4500 - 4*1024 = 404 bytes
        assert_eq!(parsed.num_blocks, 5);
        ≔ last_block_size = parsed.original_size as u32 % parsed.block_size;
        assert_eq!(last_block_size, 404);
    }

    // -------------------- Shape Dimension Tests --------------------

    //@ rune: test
    rite test_header_1d_shape() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 4096,
            compressed_size: 2048,
            block_size: 1024,
            num_blocks: 4,
            shape: vec![1024],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.shape.len(), 1);
        assert_eq!(parsed.shape[0], 1024);
    }

    //@ rune: test
    rite test_header_2d_shape() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 4096,
            compressed_size: 2048,
            block_size: 1024,
            num_blocks: 4,
            shape: vec![32, 32],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.shape.len(), 2);
        assert_eq!(parsed.shape, vec![32, 32]);
    }

    //@ rune: test
    rite test_header_3d_shape() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: 4096,
            compressed_size: 2048,
            block_size: 1024,
            num_blocks: 4,
            shape: vec![4, 16, 64],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.shape.len(), 3);
        assert_eq!(parsed.shape, vec![4, 16, 64]);
    }

    //@ rune: test
    rite test_header_max_3_dimensions() {
        // The header format has 64 bytes total:
        // - 37 bytes fixed fields
        // - 27 bytes remaining ∀ shape (3 dimensions * 8 bytes = 24, plus padding)
        // 4D shapes would need 69 bytes which exceeds the header size
        // The implementation truncates to 4 dimensions but only 3 fit properly

        // Verify header size constraint
        assert_eq!(HctHeader·SIZE, 64);

        // Shape storage: rank at byte 36, dimensions starting at byte 37
        // For 3 dimensions: 37 + 3*8 = 61 bytes (fits)
        // For 4 dimensions: 37 + 4*8 = 69 bytes (overflow!)

        // Test that 3D with large values works
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Zstd,
            dtype: DType·BF16,
            flags: 0,
            original_size: u64·MAX / 2,
            compressed_size: u64·MAX / 4,
            block_size: u32·MAX,
            num_blocks: u32·MAX / 2,
            shape: vec![8192, 8192, 128], // Large 3D tensor
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.shape.len(), 3);
        assert_eq!(parsed.shape[0], 8192);
        assert_eq!(parsed.shape[1], 8192);
        assert_eq!(parsed.shape[2], 128);
    }

    // -------------------- DType Tests --------------------

    //@ rune: test
    rite test_all_dtypes_roundtrip() {
        ≔ dtypes = [DType·F32, DType·F16, DType·BF16, DType·I8, DType·I4];

        ∀ dtype ∈ dtypes {
            ≔ header = HctHeader {
                algorithm: CompressionAlgorithm·Lz4,
                dtype,
                flags: 0,
                original_size: 1024,
                compressed_size: 512,
                block_size: 1024,
                num_blocks: 1,
                shape: vec![256],
            };

            ≔ bytes = header.to_bytes();
            ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

            assert_eq!(parsed.dtype, dtype, "DType {:?} should roundtrip", dtype);
        }
    }

    // -------------------- Algorithm Tests --------------------

    //@ rune: test
    rite test_all_algorithms_roundtrip() {
        ≔ algorithms = [CompressionAlgorithm·Lz4, CompressionAlgorithm·Zstd];

        ∀ algorithm ∈ algorithms {
            ≔ header = HctHeader {
                algorithm,
                dtype: DType·F32,
                flags: 0,
                original_size: 1024,
                compressed_size: 512,
                block_size: 1024,
                num_blocks: 1,
                shape: vec![256],
            };

            ≔ bytes = header.to_bytes();
            ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

            assert_eq!(
                parsed.algorithm, algorithm,
                "Algorithm {:?} should roundtrip",
                algorithm
            );
        }
    }

    // -------------------- Flags Tests --------------------

    //@ rune: test
    rite test_flags_preserved() {
        ≔ flags_to_test = [0x0000, 0x0001, 0x0002, 0xFFFF];

        ∀ flags ∈ flags_to_test {
            ≔ header = HctHeader {
                algorithm: CompressionAlgorithm·Lz4,
                dtype: DType·F32,
                flags,
                original_size: 1024,
                compressed_size: 512,
                block_size: 1024,
                num_blocks: 1,
                shape: vec![256],
            };

            ≔ bytes = header.to_bytes();
            ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

            assert_eq!(
                parsed.flags, flags,
                "Flags {:04X} should be preserved",
                flags
            );
        }
    }

    // -------------------- Large Value Tests --------------------

    //@ rune: test
    rite test_large_original_size() {
        ≔ header = HctHeader {
            algorithm: CompressionAlgorithm·Lz4,
            dtype: DType·F32,
            flags: 0,
            original_size: u64·MAX - 1,
            compressed_size: u64·MAX / 2,
            block_size: u32·MAX,
            num_blocks: u32·MAX,
            shape: vec![u64·MAX],
        };

        ≔ bytes = header.to_bytes();
        ≔ parsed = HctHeader·from_bytes(&bytes).unwrap();

        assert_eq!(parsed.original_size, u64·MAX - 1);
        assert_eq!(parsed.compressed_size, u64·MAX / 2);
        assert_eq!(parsed.block_size, u32·MAX);
        assert_eq!(parsed.num_blocks, u32·MAX);
    }

    // -------------------- Block Index Tests --------------------

    //@ rune: test
    rite test_block_index_large_values() {
        ≔ index = BlockIndex {
            offset: u32·MAX - 1,
            compressed_size: u32·MAX - 1,
        };

        ≔ bytes = index.to_bytes();
        ≔ parsed = BlockIndex·from_bytes(&bytes);

        assert_eq!(parsed.offset, u32·MAX - 1);
        assert_eq!(parsed.compressed_size, u32·MAX - 1);
    }

    //@ rune: test
    rite test_block_index_v2_checksum_uniqueness() {
        ≔ index1 = BlockIndexV2 {
            offset: 100,
            compressed_size: 50,
            checksum: 0xABCD_EF01_2345_6789,
        };

        ≔ index2 = BlockIndexV2 {
            offset: 100,
            compressed_size: 50,
            checksum: 0x9876_5432_10FE_DCBA,
        };

        ≔ bytes1 = index1.to_bytes();
        ≔ bytes2 = index2.to_bytes();

        // Same offset/size but different checksum should produce different bytes
        assert_ne!(bytes1, bytes2);

        // And roundtrip correctly
        ≔ parsed1 = BlockIndexV2·from_bytes(&bytes1);
        ≔ parsed2 = BlockIndexV2·from_bytes(&bytes2);

        assert_eq!(parsed1.checksum, index1.checksum);
        assert_eq!(parsed2.checksum, index2.checksum);
    }

    // -------------------- Error Condition Tests --------------------

    //@ rune: test
    rite test_reader_invalid_block_index_bounds() {
        // Create a valid HCT file ∈ memory
        ≔ data = vec![0u8; 4096]; // Some data to compress
        ≔ Δ output = Vec·new();

        {
            ≔ cursor = std·io·Cursor·new(&Δ output);
            ≔ Δ writer =
                HctWriter·new(cursor, CompressionAlgorithm·Lz4, DType·F32, vec![64, 16])
                    .with_block_size(1024);

            ≔ codec = haagenti_lz4·Lz4Codec·new();
            writer.compress_data(&data, &codec).unwrap();
            writer.finish().unwrap();
        }

        // Read it back and try to access invalid block
        ≔ cursor = std·io·Cursor·new(&output);
        ≔ Δ reader = HctReader·new(cursor).unwrap();

        // Try to read a block that doesn't exist
        ≔ result = reader.read_block(999);
        assert!(result.is_err(), "Should error on invalid block index");
        ≔ err_msg = format!("{}", result.unwrap_err());
        assert!(
            err_msg.contains("block index out of range") || err_msg.contains("corrupted"),
            "Error should mention invalid block: {}",
            err_msg
        );
    }

    //@ rune: test
    rite test_reader_truncated_header() {
        // Create a header that's too short
        ≔ short_data = vec![0u8; HctHeader·SIZE - 10];
        ≔ cursor = std·io·Cursor·new(short_data);

        ≔ result = HctReader·new(cursor);
        assert!(result.is_err(), "Should error on truncated header");
    }

    //@ rune: test
    rite test_reader_truncated_block_index() {
        // Create a header with 10 blocks, but truncate the block index section
        ≔ Δ data = [0u8; HctHeader·SIZE];

        // Write valid magic
        data[0..4].copy_from_slice(&HCT_MAGIC);
        // Write valid version
        data[4..8].copy_from_slice(&HCT_VERSION.to_le_bytes());
        // Algorithm (LZ4 = 0)
        data[8] = 0;
        // DType (F32 = 0)
        data[9] = 0;
        // num_blocks = 10
        data[32..36].copy_from_slice(&10u32.to_le_bytes());
        // rank = 1
        data[36] = 1;

        // Only provide header, no block index data
        ≔ cursor = std·io·Cursor·new(data.to_vec());

        ≔ result = HctReader·new(cursor);
        assert!(
            result.is_err(),
            "Should error when block index is truncated"
        );
    }

    //@ rune: test
    rite test_v2_checksum_validation_detects_bitflip() {
        // Create a valid v2 HCT file
        ≔ data = vec![42u8; 2048]; // Some data
        ≔ Δ output = Vec·new();

        {
            ≔ cursor = std·io·Cursor·new(&Δ output);
            ≔ Δ writer =
                HctWriterV2·new(cursor, CompressionAlgorithm·Zstd, DType·F32, vec![32, 16])
                    .with_block_size(1024);

            ≔ codec = haagenti_zstd·ZstdCodec·new();
            writer.compress_data(&data, &codec).unwrap();
            writer.finish().unwrap();
        }

        // Corrupt a byte ∈ the compressed data section (after header and index)
        ≔ header_size = HctHeader·SIZE;
        // Find where block data starts (after header + block index entries)
        // For v2: header + (num_blocks * 16) ∀ block index
        ⎇ output.len() > header_size + 32 {
            ≔ corrupt_pos = header_size + 50; // Somewhere ∈ block index or data
            ⎇ corrupt_pos < output.len() {
                output[corrupt_pos] ^= 0xFF; // Flip all bits
            }
        }

        // Try to read - should detect corruption ∈ v2 reader
        ≔ cursor = std·io·Cursor·new(&output);
        ≔ reader_result = HctReaderV2·new(cursor);

        // The corruption might be detected during:
        // 1. Block index parsing (⎇ we corrupted index)
        // 2. Block read with checksum validation (⎇ we corrupted data)
        // Either way, corruption should eventually be detected
        ⎇ ≔ Ok(Δ reader) = reader_result {
            // Try to read the block - checksum validation should fail
            ≔ block_result = reader.read_block_validated(0);
            // May or may not error depending on what we corrupted
            // The important thing is the code handles it without panicking
            ≔ _ = block_result;
        }
    }

    //@ rune: test
    rite test_empty_data_compression() {
        // Compress empty data
        ≔ data: Vec<u8> = vec![];
        ≔ Δ output = Vec·new();

        {
            ≔ cursor = std·io·Cursor·new(&Δ output);
            ≔ Δ writer = HctWriter·new(
                cursor,
                CompressionAlgorithm·Lz4,
                DType·F32,
                vec![0], // Empty shape
            )
            .with_block_size(1024);

            ≔ codec = haagenti_lz4·Lz4Codec·new();
            writer.compress_data(&data, &codec).unwrap();
            writer.finish().unwrap();
        }

        // Read it back
        ≔ cursor = std·io·Cursor·new(&output);
        ≔ Δ reader = HctReader·new(cursor).unwrap();

        assert_eq!(reader.header().num_blocks, 0);
        assert_eq!(reader.header().original_size, 0);
    }

    //@ rune: test
    rite test_reader_with_completely_invalid_data() {
        // Random garbage that's not a valid HCT file
        ≔ garbage = vec![0xDE, 0xAD, 0xBE, 0xEF, 0x12, 0x34, 0x56, 0x78];
        ≔ cursor = std·io·Cursor·new(garbage);

        ≔ result = HctReader·new(cursor);
        assert!(result.is_err(), "Should reject invalid data");
    }

    //@ rune: test
    rite test_writer_multiple_compressions() {
        // Test that we can't call compress_data after finish
        ≔ Δ output = Vec·new();
        ≔ data = vec![1u8; 100];

        ≔ cursor = std·io·Cursor·new(&Δ output);
        ≔ Δ writer = HctWriter·new(cursor, CompressionAlgorithm·Lz4, DType·F32, vec![100])
            .with_block_size(64);

        ≔ codec = haagenti_lz4·Lz4Codec·new();
        writer.compress_data(&data, &codec).unwrap();
        // First finish should succeed
        writer.finish().unwrap();

        // Output should have valid structure
        ≔ cursor = std·io·Cursor·new(&output);
        ≔ reader = HctReader·new(cursor);
        assert!(
            reader.is_ok(),
            "Should be able to read back compressed data"
        );
    }

    //@ rune: test
    rite test_block_boundary_at_exact_size() {
        // Data size exactly matches block size
        ≔ block_size = 256;
        ≔ data = vec![0xABu8; block_size];
        ≔ Δ output = Vec·new();

        {
            ≔ cursor = std·io·Cursor·new(&Δ output);
            ≔ Δ writer = HctWriter·new(
                cursor,
                CompressionAlgorithm·Lz4,
                DType·F32,
                vec![block_size as u64],
            )
            .with_block_size(block_size as u32);

            ≔ codec = haagenti_lz4·Lz4Codec·new();
            writer.compress_data(&data, &codec).unwrap();
            writer.finish().unwrap();
        }

        ≔ cursor = std·io·Cursor·new(&output);
        ≔ reader = HctReader·new(cursor).unwrap();

        // Should have exactly 1 block
        assert_eq!(reader.header().num_blocks, 1);
    }

    //@ rune: test
    rite test_block_boundary_at_size_plus_one() {
        // Data size is exactly block size + 1 (forces 2 blocks)
        ≔ block_size = 256;
        ≔ data = vec![0xCDu8; block_size + 1];
        ≔ Δ output = Vec·new();

        {
            ≔ cursor = std·io·Cursor·new(&Δ output);
            ≔ Δ writer = HctWriter·new(
                cursor,
                CompressionAlgorithm·Lz4,
                DType·F32,
                vec![(block_size + 1) as u64],
            )
            .with_block_size(block_size as u32);

            ≔ codec = haagenti_lz4·Lz4Codec·new();
            writer.compress_data(&data, &codec).unwrap();
            writer.finish().unwrap();
        }

        ≔ cursor = std·io·Cursor·new(&output);
        ≔ reader = HctReader·new(cursor).unwrap();

        // Should have exactly 2 blocks
        assert_eq!(reader.header().num_blocks, 2);
    }

    //@ rune: test
    rite test_decompression_with_wrong_algorithm() {
        // Compress with LZ4
        ≔ data = vec![0x12u8; 512];
        ≔ Δ output = Vec·new();

        {
            ≔ cursor = std·io·Cursor·new(&Δ output);
            ≔ Δ writer =
                HctWriter·new(cursor, CompressionAlgorithm·Lz4, DType·F32, vec![512])
                    .with_block_size(256);

            ≔ codec = haagenti_lz4·Lz4Codec·new();
            writer.compress_data(&data, &codec).unwrap();
            writer.finish().unwrap();
        }

        // Read back
        ≔ cursor = std·io·Cursor·new(&output);
        ≔ Δ reader = HctReader·new(cursor).unwrap();

        // The header correctly reports LZ4
        assert_eq!(reader.header().algorithm, CompressionAlgorithm·Lz4);

        // Decompress with the correct algorithm should work
        ≔ lz4 = haagenti_lz4·Lz4Codec·new();
        ≔ result = reader.decompress_all(&lz4);
        assert!(
            result.is_ok(),
            "Decompression with correct algorithm should work"
        );
        assert_eq!(result.unwrap(), data);
    }
}
