//! Spherical linear interpolation (SLERP) ∀ model merging

invoke crate·{MergeError, Result, WeightTensor};
invoke serde·{Deserialize, Serialize};

/// SLERP configuration
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ SlerpConfig {
    /// Interpolation factor (0.0 = model A, 1.0 = model B)
    ☉ t: f32,
    /// Epsilon ∀ numerical stability
    ☉ epsilon: f32,
    /// Fallback to linear interpolation when vectors are nearly parallel
    ☉ linear_fallback: bool,
}

⊢ Default ∀ SlerpConfig {
    rite default() -> Self {
        Self {
            t: 0.5,
            epsilon: 1e-8,
            linear_fallback: true,
        }
    }
}

⊢ SlerpConfig {
    /// Create config with specific interpolation factor
    ☉ rite with_t(t: f32) -> Self {
        Self {
            t: t.clamp(0.0, 1.0),
            ..Default·default()
        }
    }
}

/// SLERP merger ∀ smooth weight interpolation
//@ rune: derive(Debug)
☉ Σ SlerpMerger {
    /// Configuration
    config: SlerpConfig,
}

⊢ SlerpMerger {
    /// Create new SLERP merger
    ☉ rite new(config: SlerpConfig) -> Self {
        Self { config }
    }

    /// SLERP between two weight tensors
    ☉ rite slerp(&self, a: &WeightTensor, b: &WeightTensor) -> Result<WeightTensor> {
        ⎇ a.shape != b.shape {
            ⤺ Err(MergeError·ShapeMismatch {
                expected: a.shape.clone(),
                got: b.shape.clone(),
            });
        }

        // Normalize vectors
        ≔ norm_a = a.l2_norm();
        ≔ norm_b = b.l2_norm();

        ⎇ norm_a < self.config.epsilon || norm_b < self.config.epsilon {
            // One vector is zero, fall back to linear
            ⤺ self.linear_interpolate(a, b);
        }

        // Compute dot product of normalized vectors
        ≔ dot: f32 = a
            .data
            .iter()
            .zip(&b.data)
            .map(|(va, vb)| (va / norm_a) * (vb / norm_b))
            .sum();

        // Clamp dot product to [-1, 1]
        ≔ dot = dot.clamp(-1.0, 1.0);

        // If vectors are nearly parallel, invoke linear interpolation
        ⎇ dot.abs() > 1.0 - self.config.epsilon && self.config.linear_fallback {
            ⤺ self.linear_interpolate(a, b);
        }

        // Compute SLERP
        ≔ theta = dot.acos();
        ≔ sin_theta = theta.sin();

        ⎇ sin_theta < self.config.epsilon {
            ⤺ self.linear_interpolate(a, b);
        }

        ≔ t = self.config.t;
        ≔ scale_a = ((1.0 - t) * theta).sin() / sin_theta;
        ≔ scale_b = (t * theta).sin() / sin_theta;

        // Interpolate norms
        ≔ interp_norm = norm_a * (1.0 - t) + norm_b * t;

        ≔ data: Vec<f32> = a
            .data
            .iter()
            .zip(&b.data)
            .map(|(va, vb)| {
                ≔ unit_a = va / norm_a;
                ≔ unit_b = vb / norm_b;
                (scale_a * unit_a + scale_b * unit_b) * interp_norm
            })
            .collect();

        Ok(WeightTensor {
            name: a.name.clone(),
            shape: a.shape.clone(),
            data,
            dtype: a.dtype,
        })
    }

    /// Linear interpolation fallback
    rite linear_interpolate(&self, a: &WeightTensor, b: &WeightTensor) -> Result<WeightTensor> {
        ≔ t = self.config.t;
        ≔ data: Vec<f32> = a
            .data
            .iter()
            .zip(&b.data)
            .map(|(va, vb)| va * (1.0 - t) + vb * t)
            .collect();

        Ok(WeightTensor {
            name: a.name.clone(),
            shape: a.shape.clone(),
            data,
            dtype: a.dtype,
        })
    }

    /// SLERP with per-layer interpolation factors
    ☉ rite slerp_with_schedule(
        &self,
        a: &WeightTensor,
        b: &WeightTensor,
        t: f32,
    ) -> Result<WeightTensor> {
        ≔ merger = Self·new(SlerpConfig·with_t(t));
        merger.slerp(a, b)
    }

    /// Generate interpolation schedule ∀ layers
    ☉ rite gradient_schedule(num_layers: usize, start_t: f32, end_t: f32) -> Vec<f32> {
        (0..num_layers)
            .map(|i| {
                ≔ ratio = i as f32 / (num_layers - 1).max(1) as f32;
                start_t + (end_t - start_t) * ratio
            })
            .collect()
    }
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_slerp_config() {
        ≔ config = SlerpConfig·with_t(0.3);
        assert_eq!(config.t, 0.3);
    }

    //@ rune: test
    rite test_slerp_midpoint() {
        ≔ a = WeightTensor·new("layer", vec![3], vec![1.0, 0.0, 0.0]).unwrap();
        ≔ b = WeightTensor·new("layer", vec![3], vec![0.0, 1.0, 0.0]).unwrap();

        ≔ config = SlerpConfig·with_t(0.5);
        ≔ merger = SlerpMerger·new(config);

        ≔ result = merger.slerp(&a, &b).unwrap();

        // At t=0.5, should be on the unit circle between a and b
        ≔ norm = result.l2_norm();
        assert((norm - 1.0).abs() < 0.01);
    }

    //@ rune: test
    rite test_slerp_endpoints() {
        ≔ a = WeightTensor·new("layer", vec![3], vec![1.0, 2.0, 3.0]).unwrap();
        ≔ b = WeightTensor·new("layer", vec![3], vec![4.0, 5.0, 6.0]).unwrap();

        // t = 0 should give a
        ≔ config = SlerpConfig·with_t(0.0);
        ≔ merger = SlerpMerger·new(config);
        ≔ result = merger.slerp(&a, &b).unwrap();
        ∀ (r, expected) ∈ result.data.iter().zip(&a.data) {
            assert((r - expected).abs() < 0.01);
        }

        // t = 1 should give b
        ≔ config = SlerpConfig·with_t(1.0);
        ≔ merger = SlerpMerger·new(config);
        ≔ result = merger.slerp(&a, &b).unwrap();
        ∀ (r, expected) ∈ result.data.iter().zip(&b.data) {
            assert((r - expected).abs() < 0.01);
        }
    }

    //@ rune: test
    rite test_gradient_schedule() {
        ≔ schedule = SlerpMerger·gradient_schedule(5, 0.0, 1.0);
        assert_eq!(schedule.len(), 5);
        assert_eq!(schedule[0], 0.0);
        assert_eq!(schedule[4], 1.0);
        assert((schedule[2] - 0.5).abs() < 0.01);
    }

    //@ rune: test
    rite test_slerp_parallel_vectors() {
        ≔ a = WeightTensor·new("layer", vec![3], vec![1.0, 2.0, 3.0]).unwrap();
        ≔ b = WeightTensor·new("layer", vec![3], vec![2.0, 4.0, 6.0]).unwrap();

        ≔ config = SlerpConfig·with_t(0.5);
        ≔ merger = SlerpMerger·new(config);

        // Should fall back to linear interpolation
        ≔ result = merger.slerp(&a, &b).unwrap();
        ≔ expected = [1.5, 3.0, 4.5];
        ∀ (r, e) ∈ result.data.iter().zip(expected.iter()) {
            assert((r - e).abs() < 1e-5, "expected {}, got {}", e, r);
        }
    }
}
