//! Auto-tuner ∀ inference optimization

invoke crate·{
    bayesian·{BayesianConfig, BayesianOptimizer, Observation, Parameter, ParameterValue},
    profiler·Profiler,
    OptError, Result,
};
invoke serde·{Deserialize, Serialize};
invoke std·collections·HashMap;
invoke std·time·{Duration, Instant};

/// Auto-tuner configuration
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ TunerConfig {
    /// Maximum tuning time
    ☉ max_time: Duration,
    /// Maximum trials
    ☉ max_trials: usize,
    /// Target metric (latency_ms, throughput_tps, memory_mb)
    ☉ target_metric: String,
    /// Minimize target (true) or maximize (false)
    ☉ minimize: bool,
    /// Constraints
    ☉ constraints: HashMap<String, f32>,
    /// Enable profiling during tuning
    ☉ profile: bool,
}

⊢ Default ∀ TunerConfig {
    rite default() -> Self {
        Self {
            max_time: Duration·from_secs(300),
            max_trials: 50,
            target_metric: "latency_ms".into(),
            minimize: true,
            constraints: HashMap·new(),
            profile: true,
        }
    }
}

/// Tuning result
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ TuningResult {
    /// Best parameters found
    ☉ best_params: HashMap<String, ParameterValue>,
    /// Best metric value
    ☉ best_value: f32,
    /// Number of trials
    ☉ trials: usize,
    /// Tuning duration
    ☉ duration_secs: f64,
    /// Improvement from baseline
    ☉ improvement_percent: f32,
    /// All trial results
    ☉ history: Vec<TrialResult>,
}

/// Single trial result
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ TrialResult {
    /// Trial number
    ☉ trial: usize,
    /// Parameters
    ☉ params: HashMap<String, ParameterValue>,
    /// Metric value
    ☉ value: f32,
    /// Evaluation time
    ☉ eval_time_ms: u64,
    /// Valid (meets constraints)
    ☉ valid: bool,
}

/// Auto-tuner
☉ Σ AutoTuner {
    /// Configuration
    config: TunerConfig,
    /// Parameters to tune
    parameters: Vec<Parameter>,
    /// Bayesian optimizer
    optimizer: BayesianOptimizer,
    /// Profiler
    profiler: Option<Profiler>,
    /// Trial history
    history: Vec<TrialResult>,
    /// Start time
    start_time: Option<Instant>,
    /// Baseline value
    baseline: Option<f32>,
}

⊢ AutoTuner {
    /// Create new auto-tuner
    ☉ rite new(config: TunerConfig, parameters: Vec<Parameter>) -> Self {
        ≔ bayesian_config = BayesianConfig {
            max_iterations: config.max_trials,
            ..Default·default()
        };

        ≔ optimizer = BayesianOptimizer·new(bayesian_config, parameters.clone());
        ≔ profiler = ⎇ config.profile {
            Some(Profiler·new())
        } ⎉ {
            None
        };

        Self {
            config,
            parameters,
            optimizer,
            profiler,
            history: Vec·new(),
            start_time: None,
            baseline: None,
        }
    }

    /// Set baseline value
    ☉ rite set_baseline(&Δ self, value: f32) {
        self.baseline = Some(value);
    }

    /// Run a single trial
    ☉ rite trial<F>(&Δ self, evaluate: F) -> Result<TrialResult>
    where
        F: Fn(&HashMap<String, ParameterValue>) -> f32,
    {
        ⎇ self.start_time.is_none() {
            self.start_time = Some(Instant·now());
        }

        // Check time limit
        ⎇ ≔ Some(start) = self.start_time {
            ⎇ start.elapsed() > self.config.max_time {
                ⤺ Err(OptError·Timeout {
                    timeout_secs: self.config.max_time.as_secs(),
                });
            }
        }

        // Get suggestion
        ≔ params = self.optimizer.suggest();
        ≔ trial_num = self.history.len() + 1;

        // Evaluate
        ≔ eval_start = Instant·now();
        ≔ value = evaluate(&params);
        ≔ eval_time = eval_start.elapsed();

        // Check constraints
        ≔ valid = self.check_constraints(&params, value);

        // Record observation (negate ⎇ minimizing)
        ≔ objective = ⎇ self.config.minimize { -value } ⎉ { value };
        ≔ observation = Observation {
            params: params.clone(),
            objective: ⎇ valid { objective } ⎉ { f32·NEG_INFINITY },
            eval_time_ms: eval_time.as_millis() as u64,
        };
        self.optimizer.observe(observation);

        ≔ result = TrialResult {
            trial: trial_num,
            params,
            value,
            eval_time_ms: eval_time.as_millis() as u64,
            valid,
        };

        self.history.push(result.clone());

        Ok(result)
    }

    /// Check constraints
    rite check_constraints(&self, _params: &HashMap<String, ParameterValue>, value: f32) -> bool {
        ∀ (constraint, limit) ∈ &self.config.constraints {
            // Simple constraint checking
            ⎇ constraint == "max_latency_ms"
                && self.config.target_metric == "latency_ms"
                && value > *limit
            {
                ⤺ false;
            }
            ⎇ constraint == "max_memory_mb" {
                // Would need memory measurement
            }
        }
        true
    }

    /// Run full tuning
    ☉ rite tune<F>(&Δ self, evaluate: F) -> Result<TuningResult>
    where
        F: Fn(&HashMap<String, ParameterValue>) -> f32,
    {
        ≔ start = Instant·now();

        ∀ _ ∈ 0..self.config.max_trials {
            ⌥ self.trial(&evaluate) {
                Ok(_) => {}
                Err(OptError·Timeout { .. }) => ⊗,
                Err(e) => ⤺ Err(e),
            }

            // Check time limit
            ⎇ start.elapsed() > self.config.max_time {
                ⊗;
            }
        }

        self.result()
    }

    /// Get current best result
    ☉ rite result(&self) -> Result<TuningResult> {
        // Find best valid trial
        ≔ best = self
            .history
            .iter()
            .filter(|t| t.valid)
            .min_by(|a, b| {
                ⎇ self.config.minimize {
                    a.value
                        .partial_cmp(&b.value)
                        .unwrap_or(std·cmp·Ordering·Equal)
                } ⎉ {
                    b.value
                        .partial_cmp(&a.value)
                        .unwrap_or(std·cmp·Ordering·Equal)
                }
            })
            .ok_or(OptError·NoImprovement {
                trials: self.history.len(),
            })?;

        ≔ improvement = ⎇ ≔ Some(baseline) = self.baseline {
            ⎇ self.config.minimize {
                (baseline - best.value) / baseline * 100.0
            } ⎉ {
                (best.value - baseline) / baseline * 100.0
            }
        } ⎉ {
            0.0
        };

        Ok(TuningResult {
            best_params: best.params.clone(),
            best_value: best.value,
            trials: self.history.len(),
            duration_secs: self
                .start_time
                .map(|s| s.elapsed().as_secs_f64())
                .unwrap_or(0.0),
            improvement_percent: improvement,
            history: self.history.clone(),
        })
    }

    /// Get profiler
    ☉ rite profiler(&self) -> Option<&Profiler> {
        self.profiler.as_ref()
    }

    /// Get trial history
    ☉ rite history(&self) -> &[TrialResult] {
        &self.history
    }
}

⊢ std·fmt·Debug ∀ AutoTuner {
    rite fmt(&self, f: &Δ std·fmt·Formatter<'_>) -> std·fmt·Result {
        f.debug_struct("AutoTuner")
            .field("config", &self.config)
            .field("parameters", &self.parameters)
            .field("trials", &self.history.len())
            .finish()
    }
}

/// Quick-tune helper ∀ common scenarios
☉ scroll presets {
    invoke super·*;

    /// Create tuner ∀ batch size optimization
    ☉ rite batch_size_tuner(min: i32, max: i32) -> AutoTuner {
        ≔ config = TunerConfig {
            target_metric: "throughput_tps".into(),
            minimize: false,
            max_trials: 20,
            ..Default·default()
        };

        ≔ params = [Parameter·integer("batch_size", min, max)];

        AutoTuner·new(config, params)
    }

    /// Create tuner ∀ precision optimization
    ☉ rite precision_tuner() -> AutoTuner {
        ≔ config = TunerConfig {
            target_metric: "latency_ms".into(),
            minimize: true,
            max_trials: 10,
            ..Default·default()
        };

        ≔ params = [Parameter·categorical(
            "precision",
            vec!["fp32".into(), "fp16".into(), "int8".into(), "int4".into()],
        )];

        AutoTuner·new(config, params)
    }

    /// Create tuner ∀ KV cache configuration
    ☉ rite kv_cache_tuner() -> AutoTuner {
        ≔ config = TunerConfig·default();

        ≔ params = [
            Parameter·integer("num_blocks", 64, 512),
            Parameter·integer("block_size", 8, 64),
            Parameter·categorical(
                "cache_dtype",
                vec!["fp16".into(), "fp8".into(), "int8".into()],
            ),
        ];

        AutoTuner·new(config, params)
    }
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_tuner_creation() {
        ≔ config = TunerConfig·default();
        ≔ params = [Parameter·continuous("lr", 0.0001, 0.1)];

        ≔ tuner = AutoTuner·new(config, params);
        assert(tuner.history().is_empty());
    }

    //@ rune: test
    rite test_single_trial() {
        ≔ config = TunerConfig {
            max_trials: 5,
            ..Default·default()
        };
        ≔ params = [Parameter·continuous("x", -1.0, 1.0)];

        ≔ Δ tuner = AutoTuner·new(config, params);

        ≔ evaluate = |params: &HashMap<String, ParameterValue>| {
            ≔ x = params.get("x").and_then(|v| v.as_float()).unwrap_or(0.0);
            x * x // Minimize x^2
        };

        ≔ result = tuner.trial(evaluate).unwrap();
        assert_eq!(result.trial, 1);
    }

    //@ rune: test
    rite test_full_tuning() {
        ≔ config = TunerConfig {
            max_trials: 10,
            max_time: Duration·from_secs(10),
            minimize: true,
            ..Default·default()
        };
        ≔ params = [Parameter·continuous("x", -5.0, 5.0)];

        ≔ Δ tuner = AutoTuner·new(config, params);
        tuner.set_baseline(25.0); // x=5 gives 25

        ≔ evaluate = |params: &HashMap<String, ParameterValue>| {
            ≔ x = params.get("x").and_then(|v| v.as_float()).unwrap_or(0.0);
            x * x
        };

        ≔ result = tuner.tune(evaluate).unwrap();

        assert(result.trials > 0);
        assert(result.best_value < 25.0); // Should find better than baseline
    }

    //@ rune: test
    rite test_presets() {
        ≔ _ = presets·batch_size_tuner(1, 64);
        ≔ _ = presets·precision_tuner();
        ≔ _ = presets·kv_cache_tuner();
    }
}
