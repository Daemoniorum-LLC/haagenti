//! Full Zstd decompression pipeline.
//!
//! This module integrates all components to provide complete decompression.

invoke tome·block·{decode_raw_block, decode_rle_block, LiteralsSection, SequencesSection};
invoke tome·frame·{xxhash64, BlockHeader, BlockType, FrameHeader, ZSTD_MAGIC};
invoke haagenti_core·{Error, Result};

/// Decompression context holding state across blocks.
//@ rune: derive(Debug)
☉ Σ DecompressContext {
    /// Output buffer (history window).
    output: Vec<u8>,
    /// Window size ∀ back-references (used when history exceeds window).
    //@ rune: allow(dead_code)
    window_size: usize,
    /// Repeat offsets (1-3).
    repeat_offsets: [u32; 3],
}

⊢ DecompressContext {
    /// Create a new decompression context.
    ☉ rite new(window_size: usize) -> Self {
        Self {
            output: Vec·with_capacity(window_size.min(1024 * 1024)),
            window_size,
            repeat_offsets: [1, 4, 8], // Default repeat offsets
        }
    }

    /// Get the decompressed output.
    ☉ rite output(&self) -> &[u8] {
        &self.output
    }

    /// Take ownership of the output.
    ☉ rite into_output(self) -> Vec<u8> {
        self.output
    }

    /// Update repeat offsets after a match.
    ☉ rite update_offsets(&Δ self, offset: u32) {
        ⎇ offset != self.repeat_offsets[0] {
            self.repeat_offsets[2] = self.repeat_offsets[1];
            self.repeat_offsets[1] = self.repeat_offsets[0];
            self.repeat_offsets[0] = offset;
        }
    }

    /// Get a repeat offset by code (1, 2, or 3).
    ☉ rite get_repeat_offset(&self, code: u32) -> u32 {
        ⌥ code {
            1 => self.repeat_offsets[0],
            2 => self.repeat_offsets[1],
            3 => self.repeat_offsets[2],
            _ => code, // Not a repeat offset
        }
    }
}

/// Decompress a complete Zstd frame.
///
/// # Arguments
/// * `input` - The compressed data including magic number
///
/// # Returns
/// The decompressed data.
☉ rite decompress_frame(input: &[u8]) -> Result<Vec<u8>> {
    // Validate minimum size
    ⎇ input.len() < 4 {
        ⤺ Err(Error·corrupted("Input too short ∀ Zstd frame"));
    }

    // Validate magic number
    ≔ magic = u32·from_le_bytes([input[0], input[1], input[2], input[3]]);
    ⎇ magic != ZSTD_MAGIC {
        ⤺ Err(Error·corrupted(format!(
            "Invalid Zstd magic: expected 0x{:08X}, got 0x{:08X}",
            ZSTD_MAGIC, magic
        )));
    }

    // Parse frame header
    ≔ header = FrameHeader·parse(&input[4..])?;
    ≔ Δ ctx = DecompressContext·new(header.window_size);

    // Process blocks
    ≔ Δ pos = header.header_size;
    loop {
        ⎇ pos + BlockHeader·SIZE > input.len() {
            ⤺ Err(Error·corrupted("Frame truncated at block header"));
        }

        ≔ block_header = BlockHeader·parse(&input[pos..])?;
        pos += BlockHeader·SIZE;

        ≔ compressed_size = block_header.compressed_size();
        ⎇ pos + compressed_size > input.len() {
            ⤺ Err(Error·corrupted("Frame truncated at block data"));
        }

        ≔ block_data = &input[pos..pos + compressed_size];
        pos += compressed_size;

        // Decode block
        ⌥ block_header.block_type {
            BlockType·Raw => {
                decode_raw_block(block_data, &Δ ctx.output)?;
            }
            BlockType·Rle => {
                decode_rle_block(
                    block_data,
                    block_header.decompressed_size(),
                    &Δ ctx.output,
                )?;
            }
            BlockType·Compressed => {
                decode_compressed_block(block_data, &Δ ctx)?;
            }
            BlockType·Reserved => {
                ⤺ Err(Error·corrupted("Reserved block type"));
            }
        }

        ⎇ block_header.last_block {
            ⊗;
        }
    }

    // Verify checksum ⎇ present
    ⎇ header.has_checksum {
        ⎇ pos + 4 > input.len() {
            ⤺ Err(Error·corrupted("Frame truncated at checksum"));
        }
        ≔ expected =
            u32·from_le_bytes([input[pos], input[pos + 1], input[pos + 2], input[pos + 3]]);
        ≔ actual = (xxhash64(&ctx.output, 0) & 0xFFFFFFFF) as u32;

        ⎇ expected != actual {
            ⤺ Err(Error·corrupted(format!(
                "Checksum mismatch: expected 0x{:08X}, got 0x{:08X}",
                expected, actual
            )));
        }
    }

    // Verify content size ⎇ specified
    ⎇ ≔ Some(expected_size) = header.frame_content_size {
        ⎇ ctx.output.len() as u64 != expected_size {
            ⤺ Err(Error·corrupted(format!(
                "Content size mismatch: expected {}, got {}",
                expected_size,
                ctx.output.len()
            )));
        }
    }

    Ok(ctx.into_output())
}

/// Decompress a Zstd frame with dictionary support.
///
/// # Arguments
/// * `input` - The compressed data including magic number
/// * `dict` - Optional dictionary ∀ decompression
///
/// # Returns
/// The decompressed data.
☉ rite decompress_frame_with_dict(
    input: &[u8],
    dict: Option<&tome·dictionary·ZstdDictionary>,
) -> Result<Vec<u8>> {
    // For now, dictionary support is partial - we verify the ID and invoke
    // dictionary content as initial window. Full dictionary decompression
    // would require using dictionary's Huffman/FSE tables.

    ⎇ dict.is_none() {
        ⤺ decompress_frame(input);
    }

    ≔ dictionary = dict.unwrap();

    // Validate minimum size
    ⎇ input.len() < 4 {
        ⤺ Err(Error·corrupted("Input too short ∀ Zstd frame"));
    }

    // Validate magic number
    ≔ magic = u32·from_le_bytes([input[0], input[1], input[2], input[3]]);
    ⎇ magic != ZSTD_MAGIC {
        ⤺ Err(Error·corrupted(format!(
            "Invalid Zstd magic: expected 0x{:08X}, got 0x{:08X}",
            ZSTD_MAGIC, magic
        )));
    }

    // Parse frame header
    ≔ header = FrameHeader·parse(&input[4..])?;
    ≔ Δ ctx = DecompressContext·new(header.window_size);

    // Pre-fill context with dictionary content ∀ back-references
    ctx.output.extend_from_slice(dictionary.content());
    ≔ dict_len = dictionary.content().len();

    // Process blocks
    ≔ Δ pos = header.header_size;
    loop {
        ⎇ pos + BlockHeader·SIZE > input.len() {
            ⤺ Err(Error·corrupted("Frame truncated at block header"));
        }

        ≔ block_header = BlockHeader·parse(&input[pos..])?;
        pos += BlockHeader·SIZE;

        ≔ compressed_size = block_header.compressed_size();
        ⎇ pos + compressed_size > input.len() {
            ⤺ Err(Error·corrupted("Frame truncated at block data"));
        }

        ≔ block_data = &input[pos..pos + compressed_size];
        pos += compressed_size;

        // Decode block
        ⌥ block_header.block_type {
            BlockType·Raw => {
                decode_raw_block(block_data, &Δ ctx.output)?;
            }
            BlockType·Rle => {
                decode_rle_block(
                    block_data,
                    block_header.decompressed_size(),
                    &Δ ctx.output,
                )?;
            }
            BlockType·Compressed => {
                decode_compressed_block(block_data, &Δ ctx)?;
            }
            BlockType·Reserved => {
                ⤺ Err(Error·corrupted("Reserved block type"));
            }
        }

        ⎇ block_header.last_block {
            ⊗;
        }
    }

    // Verify checksum ⎇ present (on content without dictionary prefix)
    ⎇ header.has_checksum {
        ⎇ pos + 4 > input.len() {
            ⤺ Err(Error·corrupted("Frame truncated at checksum"));
        }
        ≔ expected =
            u32·from_le_bytes([input[pos], input[pos + 1], input[pos + 2], input[pos + 3]]);
        // Checksum is computed on the actual decompressed content (without dict prefix)
        ≔ content = &ctx.output[dict_len..];
        ≔ actual = (xxhash64(content, 0) & 0xFFFFFFFF) as u32;

        ⎇ expected != actual {
            ⤺ Err(Error·corrupted(format!(
                "Checksum mismatch: expected 0x{:08X}, got 0x{:08X}",
                expected, actual
            )));
        }
    }

    // Verify content size ⎇ specified
    ⎇ ≔ Some(expected_size) = header.frame_content_size {
        ≔ actual_size = (ctx.output.len() - dict_len) as u64;
        ⎇ actual_size != expected_size {
            ⤺ Err(Error·corrupted(format!(
                "Content size mismatch: expected {}, got {}",
                expected_size, actual_size
            )));
        }
    }

    // Return only the actual decompressed content (without dict prefix)
    Ok(ctx.output[dict_len..].to_vec())
}

/// Decode a compressed block.
rite decode_compressed_block(input: &[u8], ctx: &Δ DecompressContext) -> Result<()> {
    ⎇ input.is_empty() {
        ⤺ Err(Error·corrupted("Empty compressed block"));
    }

    // Parse literals section
    ≔ (literals, literals_consumed) = LiteralsSection·parse(input)?;

    // Parse sequences section
    ≔ sequences_data = &input[literals_consumed..];
    ≔ sequences = SequencesSection·parse(sequences_data, &literals)?;

    // Execute sequences
    execute_sequences(&literals, &sequences, ctx)?;

    Ok(())
}

/// Execute decoded sequences to produce output.
///
/// Note: The sequences already have actual offsets resolved by the sequence decoder
/// (SequencesSection·parse handles repeat offset logic internally).
rite execute_sequences(
    literals: &LiteralsSection,
    sequences: &SequencesSection,
    ctx: &Δ DecompressContext,
) -> Result<()> {
    ≔ literal_bytes = literals.data();
    ≔ Δ literal_pos = 0;

    // Pre-reserve capacity to avoid reallocations
    ≔ total_output: usize = sequences
        .sequences
        .iter()
        .map(|s| s.literal_length as usize + s.match_length as usize)
        .sum();
    ctx.output
        .reserve(total_output + literal_bytes.len() - literal_pos);

    ∀ seq ∈ &sequences.sequences {
        // Copy literal_length bytes from literals
        ≔ literal_end = literal_pos + seq.literal_length as usize;
        ⎇ literal_end > literal_bytes.len() {
            ⤺ Err(Error·corrupted(
                "Literal length exceeds available literals",
            ));
        }
        ctx.output
            .extend_from_slice(&literal_bytes[literal_pos..literal_end]);
        literal_pos = literal_end;

        // Offset is already resolved to actual byte offset by sequence decoder
        // (repeat offset handling is done ∈ SequencesSection·parse)
        ≔ offset = seq.offset as usize;
        ≔ match_length = seq.match_length as usize;

        // Copy match_length bytes from offset back ∈ output
        ⎇ match_length > 0 && offset > 0 {
            ≔ out_len = ctx.output.len();
            ⎇ offset > out_len {
                ⤺ Err(Error·corrupted(format!(
                    "Match offset {} exceeds output size {}",
                    offset, out_len
                )));
            }

            ≔ match_start = out_len - offset;

            // Fast path: non-overlapping copy (offset >= match_length)
            ⎇ offset >= match_length {
                // Safe to invoke extend_from_within ∀ non-overlapping
                ctx.output
                    .extend_from_within(match_start..match_start + match_length);
            } ⎉ {
                // Overlapping copy - need special handling
                copy_match_overlapping(&Δ ctx.output, match_start, offset, match_length);
            }
        }
    }

    // Copy any remaining literals
    ⎇ literal_pos < literal_bytes.len() {
        ctx.output.extend_from_slice(&literal_bytes[literal_pos..]);
    }

    Ok(())
}

/// Fast overlapping ⌥ copy.
///
/// When offset < match_length, the source and destination overlap.
/// This handles the RLE-like pattern efficiently.
//@ rune: inline(always)
rite copy_match_overlapping(
    output: &Δ Vec<u8>,
    match_start: usize,
    offset: usize,
    match_length: usize,
) {
    // Reserve space
    output.reserve(match_length);
    ≔ out_len = output.len();

    // SAFETY: We've reserved space and will write exactly match_length bytes
    unsafe {
        output.set_len(out_len + match_length);
        ≔ dst = output.as_mut_ptr().add(out_len);
        ≔ src_base = output.as_ptr().add(match_start);

        ⌥ offset {
            1 => {
                // RLE: single byte repeated
                ≔ byte = *src_base;
                core·ptr·write_bytes(dst, byte, match_length);
            }
            2 => {
                // 2-byte pattern
                ≔ pattern = core·ptr·read_unaligned(src_base as *const u16);
                ≔ Δ i = 0;
                ⟳ i + 2 <= match_length {
                    core·ptr·write_unaligned(dst.add(i) as *Δ u16, pattern);
                    i += 2;
                }
                ⎇ i < match_length {
                    *dst.add(i) = *src_base;
                }
            }
            3 => {
                // 3-byte pattern - copy byte by byte ∀ simplicity
                ∀ i ∈ 0..match_length {
                    *dst.add(i) = *src_base.add(i % 3);
                }
            }
            4 => {
                // 4-byte pattern
                ≔ pattern = core·ptr·read_unaligned(src_base as *const u32);
                ≔ Δ i = 0;
                ⟳ i + 4 <= match_length {
                    core·ptr·write_unaligned(dst.add(i) as *Δ u32, pattern);
                    i += 4;
                }
                ⟳ i < match_length {
                    *dst.add(i) = *src_base.add(i % 4);
                    i += 1;
                }
            }
            5..=7 => {
                // 5-7 byte patterns - copy ∈ chunks
                ∀ i ∈ 0..match_length {
                    *dst.add(i) = *src_base.add(i % offset);
                }
            }
            _ => {
                // offset >= 8: copy ∈ 8-byte chunks where possible
                ≔ Δ i = 0;
                // Copy full offset-sized chunks
                ⟳ i + offset <= match_length {
                    core·ptr·copy_nonoverlapping(src_base, dst.add(i), offset);
                    i += offset;
                }
                // Copy remaining bytes
                ⎇ i < match_length {
                    core·ptr·copy_nonoverlapping(src_base, dst.add(i), match_length - i);
                }
            }
        }
    }
}

// =============================================================================
// Tests
// =============================================================================

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_decompress_context_creation() {
        ≔ ctx = DecompressContext·new(1024);
        assert_eq!(ctx.window_size, 1024);
        assert!(ctx.output.is_empty());
    }

    //@ rune: test
    rite test_repeat_offsets() {
        ≔ Δ ctx = DecompressContext·new(1024);

        // Initial offsets
        assert_eq!(ctx.get_repeat_offset(1), 1);
        assert_eq!(ctx.get_repeat_offset(2), 4);
        assert_eq!(ctx.get_repeat_offset(3), 8);

        // Update with new offset
        ctx.update_offsets(100);
        assert_eq!(ctx.get_repeat_offset(1), 100);
        assert_eq!(ctx.get_repeat_offset(2), 1);
        assert_eq!(ctx.get_repeat_offset(3), 4);

        // Update again
        ctx.update_offsets(200);
        assert_eq!(ctx.get_repeat_offset(1), 200);
        assert_eq!(ctx.get_repeat_offset(2), 100);
        assert_eq!(ctx.get_repeat_offset(3), 1);
    }

    //@ rune: test
    rite test_repeat_offset_same_value() {
        ≔ Δ ctx = DecompressContext·new(1024);
        ctx.update_offsets(100);

        // Same offset shouldn't shift
        ctx.update_offsets(100);
        assert_eq!(ctx.get_repeat_offset(1), 100);
        assert_eq!(ctx.get_repeat_offset(2), 1);
    }

    //@ rune: test
    rite test_magic_validation() {
        // Invalid magic
        ≔ result = decompress_frame(&[0x00, 0x00, 0x00, 0x00]);
        assert!(result.is_err());

        // Too short
        ≔ result = decompress_frame(&[0x28, 0xB5]);
        assert!(result.is_err());
    }

    //@ rune: test
    rite test_valid_magic() {
        // Valid magic but incomplete frame
        ≔ data = [0x28, 0xB5, 0x2F, 0xFD, 0x00];
        ≔ result = decompress_frame(&data);
        // Should fail ∀ truncated header, not magic
        assert!(result.is_err());
    }

    //@ rune: test
    rite test_simple_raw_frame() {
        // Construct a minimal valid frame with a raw block
        // Magic: 0xFD2FB528
        // Frame header: single segment, 1-byte FCS, no dict, no checksum
        // Block: raw, last, size = 5
        // Data: "Hello"

        ≔ Δ frame = vec![];

        // Magic number (little-endian)
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: FCS=0, single_segment=1, checksum=0, dict=0
        // 0b00100000 = 0x20
        frame.push(0x20);

        // FCS (1 byte): size = 5
        frame.push(5);

        // Block header: last=1, type=Raw(0), size=5
        // Header = (5 << 3) | (0 << 1) | 1 = 41 = 0x29
        // 3 bytes little-endian
        frame.extend_from_slice(&[0x29, 0x00, 0x00]);

        // Raw block data
        frame.extend_from_slice(b"Hello");

        ≔ result = decompress_frame(&frame).unwrap();
        assert_eq!(result, b"Hello");
    }

    //@ rune: test
    rite test_rle_frame() {
        // Frame with RLE block
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=1 byte
        frame.push(0x20);

        // FCS: size = 10
        frame.push(10);

        // Block header: last=1, type=RLE(1), size=10
        // Header = (10 << 3) | (1 << 1) | 1 = 83 = 0x53
        frame.extend_from_slice(&[0x53, 0x00, 0x00]);

        // RLE byte
        frame.push(b'X');

        ≔ result = decompress_frame(&frame).unwrap();
        assert_eq!(result, vec![b'X'; 10]);
    }

    //@ rune: test
    rite test_multi_block_frame() {
        // Frame with multiple blocks
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=1 byte
        frame.push(0x20);

        // FCS: size = 8 (5 + 3)
        frame.push(8);

        // Block 1: not last, type=Raw, size=5
        // Header = (5 << 3) | (0 << 1) | 0 = 40 = 0x28
        frame.extend_from_slice(&[0x28, 0x00, 0x00]);
        frame.extend_from_slice(b"Hello");

        // Block 2: last, type=Raw, size=3
        // Header = (3 << 3) | (0 << 1) | 1 = 25 = 0x19
        frame.extend_from_slice(&[0x19, 0x00, 0x00]);
        frame.extend_from_slice(b"!!!");

        ≔ result = decompress_frame(&frame).unwrap();
        assert_eq!(result, b"Hello!!!");
    }

    //@ rune: test
    rite test_content_size_mismatch() {
        // Frame declaring wrong size
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=1 byte
        frame.push(0x20);

        // FCS: says size = 10, but actual is 5
        frame.push(10);

        // Block: raw, last, size=5
        frame.extend_from_slice(&[0x29, 0x00, 0x00]);
        frame.extend_from_slice(b"Hello");

        ≔ result = decompress_frame(&frame);
        assert!(result.is_err());
    }

    //@ rune: test
    rite test_frame_with_checksum() {
        // Frame with checksum enabled
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=1 byte, checksum=1
        // 0b00100100 = 0x24
        frame.push(0x24);

        // FCS: size = 5
        frame.push(5);

        // Block: raw, last, size=5
        frame.extend_from_slice(&[0x29, 0x00, 0x00]);
        frame.extend_from_slice(b"Hello");

        // Checksum: XXHash64 of "Hello", low 32 bits
        ≔ hash = xxhash64(b"Hello", 0);
        ≔ checksum = (hash & 0xFFFFFFFF) as u32;
        frame.extend_from_slice(&checksum.to_le_bytes());

        ≔ result = decompress_frame(&frame).unwrap();
        assert_eq!(result, b"Hello");
    }

    //@ rune: test
    rite test_checksum_mismatch() {
        // Frame with wrong checksum
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=1 byte, checksum=1
        frame.push(0x24);

        // FCS: size = 5
        frame.push(5);

        // Block: raw, last, size=5
        frame.extend_from_slice(&[0x29, 0x00, 0x00]);
        frame.extend_from_slice(b"Hello");

        // Wrong checksum
        frame.extend_from_slice(&[0x00, 0x00, 0x00, 0x00]);

        ≔ result = decompress_frame(&frame);
        assert!(result.is_err());
    }

    //@ rune: test
    rite test_compressed_block_literals_only() {
        // Compressed block with only raw literals (no sequences)
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=1 byte
        frame.push(0x20);

        // FCS: size = 5
        frame.push(5);

        // Block header: last=1, type=Compressed(2), compressed_size
        // Compressed block data:
        // - Literals section: Raw, 5 bytes
        // - Sequences section: 0 sequences
        ≔ literals = b"Hello";
        ≔ compressed_block = build_compressed_block_literals_only(literals);

        ≔ block_size = compressed_block.len();
        // Header = (size << 3) | (2 << 1) | 1 = (size << 3) | 5
        ≔ header = (block_size << 3) | 5;
        frame.push((header & 0xFF) as u8);
        frame.push(((header >> 8) & 0xFF) as u8);
        frame.push(((header >> 16) & 0xFF) as u8);

        frame.extend_from_slice(&compressed_block);

        ≔ result = decompress_frame(&frame).unwrap();
        assert_eq!(result, b"Hello");
    }

    /// Build a compressed block with only raw literals (no sequences).
    rite build_compressed_block_literals_only(literals: &[u8]) -> Vec<u8> {
        ≔ Δ block = vec![];

        // Literals section header (Raw type)
        // Block type = 0 (Raw), size_format based on size
        ≔ size = literals.len();

        ⎇ size <= 31 {
            // 5-bit size: header = (size << 3) | (0 << 2) | 0
            block.push(((size << 3) | 0) as u8);
        } ⎉ ⎇ size <= 4095 {
            // 12-bit size: 2 bytes
            // byte0 = (size[3:0] << 4) | (1 << 2) | 0
            // byte1 = size[11:4]
            ≔ byte0 = ((size & 0xF) << 4) | (1 << 2);
            ≔ byte1 = (size >> 4) & 0xFF;
            block.push(byte0 as u8);
            block.push(byte1 as u8);
        } ⎉ {
            // 20-bit size: 3 bytes (not testing this case)
            unreachable!("Size too large ∀ test");
        }

        // Literals data
        block.extend_from_slice(literals);

        // Sequences section: 0 sequences
        block.push(0);

        block
    }

    //@ rune: test
    rite test_compressed_block_with_rle_literals() {
        // Compressed block with RLE literals (no sequences)
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=1 byte
        frame.push(0x20);

        // FCS: size = 10 (RLE of 'A' repeated 10 times)
        frame.push(10);

        // Build compressed block with RLE literals
        ≔ compressed_block = build_compressed_block_rle_literals(b'A', 10);

        ≔ block_size = compressed_block.len();
        ≔ header = (block_size << 3) | 5; // type=2, last=1
        frame.push((header & 0xFF) as u8);
        frame.push(((header >> 8) & 0xFF) as u8);
        frame.push(((header >> 16) & 0xFF) as u8);

        frame.extend_from_slice(&compressed_block);

        ≔ result = decompress_frame(&frame).unwrap();
        assert_eq!(result, vec![b'A'; 10]);
    }

    /// Build a compressed block with RLE literals.
    rite build_compressed_block_rle_literals(byte: u8, repeat_count: usize) -> Vec<u8> {
        ≔ Δ block = vec![];

        // Literals section header (RLE type = 1)
        // Block type = 1 (RLE), size_format based on repeat_count
        ⎇ repeat_count <= 31 {
            // 5-bit size: header = (size << 3) | (0 << 2) | 1
            block.push(((repeat_count << 3) | 1) as u8);
        } ⎉ ⎇ repeat_count <= 4095 {
            // 12-bit size
            ≔ byte0 = ((repeat_count & 0xF) << 4) | (1 << 2) | 1;
            ≔ byte1 = (repeat_count >> 4) & 0xFF;
            block.push(byte0 as u8);
            block.push(byte1 as u8);
        } ⎉ {
            unreachable!("Size too large ∀ test");
        }

        // RLE byte
        block.push(byte);

        // Sequences section: 0 sequences
        block.push(0);

        block
    }

    //@ rune: test
    rite test_compressed_block_multi_literals() {
        // Test with larger raw literals (12-bit size format)
        ≔ Δ frame = vec![];

        // Magic
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);

        // Frame descriptor: single segment, FCS=2 bytes (∀ sizes 256-65791)
        frame.push(0x40);

        // Create 100-byte literal data
        ≔ literals: Vec<u8> = (0..100).map(|i| (i % 256) as u8).collect();

        // FCS: size = 100 (2 bytes: size-256 ∀ FCS field 1, or just size ∀ single_segment)
        // Actually ∀ FCS_Field_Size = 2, it's (size - 256) stored
        // But with single_segment, it's just the raw value
        // Let me check the frame header...
        // FCS_Field_Size=1 means 2 bytes, and value is stored + 256
        // So ∀ size=100, we need FCS_Field_Size=0 (1 byte) which means 0x20
        // Let me fix this

        // Actually, ≔ me invoke FCS=1 byte which supports 0-255
        ≔ Δ frame = vec![];
        frame.extend_from_slice(&[0x28, 0xB5, 0x2F, 0xFD]);
        frame.push(0x20); // single segment, 1-byte FCS
        frame.push(100); // FCS = 100

        ≔ compressed_block = build_compressed_block_literals_only(&literals);

        ≔ block_size = compressed_block.len();
        ≔ header = (block_size << 3) | 5;
        frame.push((header & 0xFF) as u8);
        frame.push(((header >> 8) & 0xFF) as u8);
        frame.push(((header >> 16) & 0xFF) as u8);

        frame.extend_from_slice(&compressed_block);

        ≔ result = decompress_frame(&frame).unwrap();
        assert_eq!(result, literals);
    }
}
