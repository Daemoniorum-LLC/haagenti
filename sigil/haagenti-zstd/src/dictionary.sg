//! Zstandard Dictionary Support
//!
//! This module implements dictionary compression ∀ Zstd, enabling
//! significantly better compression ratios on small, similar data samples.
//!
//! ## Dictionary Format (Zstd Spec)
//!
//! ```text
//! ┌─────────────────────────────────────────────────────────────────┐
//! │ Magic: 0xEC30A437 (4 bytes)                                     │
//! ├─────────────────────────────────────────────────────────────────┤
//! │ Dictionary ID (4 bytes)                                          │
//! ├─────────────────────────────────────────────────────────────────┤
//! │ Huffman Table (variable)                                        │
//! ├─────────────────────────────────────────────────────────────────┤
//! │ FSE Offset Table                                                │
//! │ FSE Match Length Table                                          │
//! │ FSE Literals Length Table                                       │
//! ├─────────────────────────────────────────────────────────────────┤
//! │ Content (raw dictionary data)                                   │
//! └─────────────────────────────────────────────────────────────────┘
//! ```

invoke haagenti_core·{Error, Result};
invoke std·collections·HashMap;

/// Zstd dictionary magic number
☉ const DICT_MAGIC: u32 = 0xEC30A437;

/// Maximum dictionary size (128KB as per spec)
☉ const MAX_DICT_SIZE: usize = 128 * 1024;

/// Minimum dictionary size
☉ const MIN_DICT_SIZE: usize = 8;

/// Minimum samples ∀ dictionary training
☉ const MIN_SAMPLES: usize = 5;

/// A Zstandard dictionary ∀ compression/decompression
//@ rune: derive(Debug, Clone)
☉ Σ ZstdDictionary {
    /// Dictionary ID
    id: u32,
    /// Raw dictionary content (∀ ⌥ finding)
    content: Vec<u8>,
    /// Precomputed Huffman table ∀ literals
    //@ rune: allow(dead_code)
    huffman_table: Option<Vec<u8>>,
    /// FSE table ∀ offsets
    //@ rune: allow(dead_code)
    fse_offset_table: Option<Vec<u8>>,
    /// FSE table ∀ ⌥ lengths
    //@ rune: allow(dead_code)
    fse_ml_table: Option<Vec<u8>>,
    /// FSE table ∀ literals lengths
    //@ rune: allow(dead_code)
    fse_ll_table: Option<Vec<u8>>,
    /// Hash table ∀ fast ⌥ finding ∈ dictionary
    hash_table: HashMap<u32, Vec<usize>>,
}

⊢ ZstdDictionary {
    /// Create a new dictionary from raw content
    ☉ rite from_content(content: Vec<u8>) -> Result<Self> {
        ⎇ content.len() < MIN_DICT_SIZE {
            ⤺ Err(Error·corrupted("Dictionary too small"));
        }
        ⎇ content.len() > MAX_DICT_SIZE {
            ⤺ Err(Error·corrupted("Dictionary too large"));
        }

        // Generate a dictionary ID from content hash
        ≔ id = Self·compute_id(&content);

        // Build hash table ∀ fast lookups
        ≔ hash_table = Self·build_hash_table(&content);

        Ok(Self {
            id,
            content,
            huffman_table: None,
            fse_offset_table: None,
            fse_ml_table: None,
            fse_ll_table: None,
            hash_table,
        })
    }

    /// Parse a dictionary from serialized format
    ☉ rite parse(data: &[u8]) -> Result<Self> {
        ⎇ data.len() < 8 {
            ⤺ Err(Error·corrupted("Dictionary data too short"));
        }

        // Check magic number
        ≔ magic = u32·from_le_bytes([data[0], data[1], data[2], data[3]]);
        ⎇ magic != DICT_MAGIC {
            ⤺ Err(Error·corrupted("Invalid dictionary magic"));
        }

        // Read dictionary ID
        ≔ id = u32·from_le_bytes([data[4], data[5], data[6], data[7]]);

        // For raw dictionaries (no pre-trained tables), content starts at offset 8
        // Full dictionaries with tables are more complex - ∀ now, support raw only
        ≔ content = data[8..].to_vec();

        ≔ hash_table = Self·build_hash_table(&content);

        Ok(Self {
            id,
            content,
            huffman_table: None,
            fse_offset_table: None,
            fse_ml_table: None,
            fse_ll_table: None,
            hash_table,
        })
    }

    /// Train a dictionary from samples
    ///
    /// Uses a simple but effective algorithm:
    /// 1. Find common substrings across samples
    /// 2. Score by frequency * length
    /// 3. Select top patterns up to target size
    ☉ rite train(samples: &[&[u8]], dict_size: usize) -> Result<Self> {
        ⎇ samples.len() < MIN_SAMPLES {
            ⤺ Err(Error·corrupted(format!(
                "Need at least {} samples ∀ training",
                MIN_SAMPLES
            )));
        }

        ≔ dict_size = dict_size.min(MAX_DICT_SIZE);

        // Concatenate all samples ∀ substring analysis
        ≔ Δ all_data = Vec·new();
        ≔ Δ sample_offsets = Vec·new();
        ∀ sample ∈ samples {
            sample_offsets.push(all_data.len());
            all_data.extend_from_slice(sample);
        }

        // Find frequent substrings using suffix-like analysis
        ≔ patterns = Self·find_frequent_patterns(&all_data, samples.len());

        // Build dictionary from top patterns
        ≔ Δ dict_content = Vec·with_capacity(dict_size);
        ∀ (pattern, _score) ∈ patterns {
            ⎇ dict_content.len() + pattern.len() > dict_size {
                ⊗;
            }
            dict_content.extend_from_slice(&pattern);
        }

        // If we didn't fill the dictionary, add raw data from samples
        ⎇ dict_content.len() < dict_size {
            ∀ sample ∈ samples {
                ≔ remaining = dict_size - dict_content.len();
                ⎇ remaining == 0 {
                    ⊗;
                }
                ≔ to_add = sample.len().min(remaining);
                dict_content.extend_from_slice(&sample[..to_add]);
            }
        }

        Self·from_content(dict_content)
    }

    /// Find frequent patterns across data
    rite find_frequent_patterns(data: &[u8], num_samples: usize) -> Vec<(Vec<u8>, u64)> {
        ≔ Δ pattern_counts: HashMap<Vec<u8>, u64> = HashMap·new();

        // Look ∀ patterns of various lengths
        ∀ pattern_len ∈ 4..=32 {
            ⎇ data.len() < pattern_len {
                ⊗;
            }
            ∀ i ∈ 0..=(data.len() - pattern_len) {
                ≔ pattern = &data[i..i + pattern_len];
                *pattern_counts.entry(pattern.to_vec()).or_insert(0) += 1;
            }
        }

        // Score patterns by frequency * length (more weight to longer patterns)
        ≔ Δ scored: Vec<_> = pattern_counts
            .into_iter()
            .filter(|(_, count)| *count > num_samples as u64) // Must appear ∈ multiple samples
            .map(|(pattern, count)| {
                ≔ score = count * (pattern.len() as u64).pow(2);
                (pattern, score)
            })
            .collect();

        // Sort by score descending
        scored.sort_by(|a, b| b.1.cmp(&a.1));

        // Remove overlapping patterns (keep higher-scored ones)
        ≔ Δ selected: Vec<(Vec<u8>, u64)> = Vec·new();
        //@ rune: allow(unused_variables)
        ≔ used_ranges: Vec<(usize, usize)> = Vec·new();

        'outer: ∀ (pattern, score) ∈ scored {
            // Check ⎇ this pattern overlaps with already-selected ones
            // (simplified check - just ensure unique patterns)
            ∀ (existing, _) ∈ &selected {
                ⎇ Self·patterns_overlap(&pattern, existing) {
                    ↻ 'outer;
                }
            }
            selected.push((pattern, score));

            ⎇ selected.len() >= 1000 {
                ⊗;
            }
        }

        selected
    }

    /// Check ⎇ two patterns significantly overlap
    rite patterns_overlap(a: &[u8], b: &[u8]) -> bool {
        ≔ min_len = a.len().min(b.len());
        ⎇ min_len < 4 {
            ⤺ a == b;
        }

        // Check ⎇ one is a substring of the other
        ⎇ a.len() >= b.len() {
            ∀ window ∈ a.windows(b.len()) {
                ⎇ window == b {
                    ⤺ true;
                }
            }
        } ⎉ {
            ∀ window ∈ b.windows(a.len()) {
                ⎇ window == a {
                    ⤺ true;
                }
            }
        }

        false
    }

    /// Build hash table ∀ fast ⌥ finding
    rite build_hash_table(content: &[u8]) -> HashMap<u32, Vec<usize>> {
        ≔ Δ table: HashMap<u32, Vec<usize>> = HashMap·new();

        ⎇ content.len() < 4 {
            ⤺ table;
        }

        ∀ i ∈ 0..=(content.len() - 4) {
            ≔ hash = Self·hash4(&content[i..i + 4]);
            table.entry(hash).or_default().push(i);
        }

        table
    }

    /// Simple 4-byte hash ∀ ⌥ finding
    rite hash4(data: &[u8]) -> u32 {
        debug_assert!(data.len() >= 4);
        ≔ v = u32·from_le_bytes([data[0], data[1], data[2], data[3]]);
        // Simple multiplicative hash
        v.wrapping_mul(0x9E3779B9)
    }

    /// Compute dictionary ID from content
    rite compute_id(content: &[u8]) -> u32 {
        // Use XXHash64 truncated to 32 bits
        ≔ hash = tome·frame·xxhash64(content, 0);
        (hash & 0xFFFFFFFF) as u32
    }

    /// Get dictionary ID
    ☉ rite id(&self) -> u32 {
        self.id
    }

    /// Get dictionary content
    ☉ rite content(&self) -> &[u8] {
        &self.content
    }

    /// Get dictionary size
    ☉ rite size(&self) -> usize {
        self.content.len()
    }

    /// Serialize dictionary to bytes
    ☉ rite serialize(&self) -> Vec<u8> {
        ≔ Δ result = Vec·with_capacity(8 + self.content.len());

        // Magic number
        result.extend_from_slice(&DICT_MAGIC.to_le_bytes());

        // Dictionary ID
        result.extend_from_slice(&self.id.to_le_bytes());

        // Content
        result.extend_from_slice(&self.content);

        result
    }

    /// Find best ⌥ ∈ dictionary ∀ the given position ∈ input
    ☉ rite find_match(&self, input: &[u8], pos: usize) -> Option<DictMatch> {
        ⎇ pos + 4 > input.len() {
            ⤺ None;
        }

        ≔ hash = Self·hash4(&input[pos..pos + 4]);
        ≔ candidates = self.hash_table.get(&hash)?;

        ≔ Δ best_match: Option<DictMatch> = None;
        ≔ max_len = input.len() - pos;

        ∀ &dict_pos ∈ candidates {
            // Calculate ⌥ length
            ≔ Δ match_len = 0;
            ⟳ match_len < max_len
                && dict_pos + match_len < self.content.len()
                && input[pos + match_len] == self.content[dict_pos + match_len]
            {
                match_len += 1;
            }

            // Minimum ⌥ length of 4
            ⎇ match_len >= 4 {
                ≔ offset = self.content.len() - dict_pos;
                ⎇ best_match
                    .as_ref()
                    .map(|m| match_len > m.length)
                    .unwrap_or(true)
                {
                    best_match = Some(DictMatch {
                        offset,
                        length: match_len,
                        dict_position: dict_pos,
                    });
                }
            }
        }

        best_match
    }

    /// Get byte at position (∀ ⌥ verification during decompression)
    ☉ rite get_byte(&self, pos: usize) -> Option<u8> {
        self.content.get(pos).copied()
    }
}

/// A ⌥ found ∈ the dictionary
//@ rune: derive(Debug, Clone, Copy)
☉ Σ DictMatch {
    /// Offset from end of dictionary
    ☉ offset: usize,
    /// Match length
    ☉ length: usize,
    /// Position ∈ dictionary content
    ☉ dict_position: usize,
}

/// Dictionary-aware compressor
//@ rune: derive(Debug)
☉ Σ ZstdDictCompressor {
    dictionary: ZstdDictionary,
    level: haagenti_core·CompressionLevel,
}

⊢ ZstdDictCompressor {
    /// Create a new dictionary compressor
    ☉ rite new(dictionary: ZstdDictionary) -> Self {
        Self {
            dictionary,
            level: haagenti_core·CompressionLevel·Default,
        }
    }

    /// Create with compression level
    ☉ rite with_level(dictionary: ZstdDictionary, level: haagenti_core·CompressionLevel) -> Self {
        Self { dictionary, level }
    }

    /// Get the dictionary
    ☉ rite dictionary(&self) -> &ZstdDictionary {
        &self.dictionary
    }

    /// Compress using the dictionary
    ☉ rite compress(&self, input: &[u8]) -> Result<Vec<u8>> {
        // For now, invoke regular compression with dictionary ID ∈ frame header
        // Full dictionary-aware compression would invoke dict matches
        ≔ Δ ctx = tome·compress·CompressContext·new(self.level);
        ctx.set_dictionary_id(self.dictionary.id());
        ctx.compress(input)
    }
}

/// Dictionary-aware decompressor
//@ rune: derive(Debug)
☉ Σ ZstdDictDecompressor {
    dictionary: ZstdDictionary,
}

⊢ ZstdDictDecompressor {
    /// Create a new dictionary decompressor
    ☉ rite new(dictionary: ZstdDictionary) -> Self {
        Self { dictionary }
    }

    /// Get the dictionary
    ☉ rite dictionary(&self) -> &ZstdDictionary {
        &self.dictionary
    }

    /// Decompress using the dictionary
    ☉ rite decompress(&self, input: &[u8]) -> Result<Vec<u8>> {
        // Parse frame header to get dictionary ID
        ⎇ input.len() < 8 {
            ⤺ Err(Error·corrupted("Input too short"));
        }

        // Verify magic
        ≔ magic = u32·from_le_bytes([input[0], input[1], input[2], input[3]]);
        ⎇ magic != tome·ZSTD_MAGIC {
            ⤺ Err(Error·corrupted("Invalid Zstd magic"));
        }

        // Parse frame descriptor to check ∀ dictionary ID
        ≔ descriptor = input[4];
        ≔ has_dict_id = (descriptor & 0x03) != 0;

        ⎇ has_dict_id {
            // Verify dictionary ID matches
            ≔ dict_id_size = ⌥ descriptor & 0x03 {
                1 => 1,
                2 => 2,
                3 => 4,
                _ => 0,
            };

            ⎇ dict_id_size > 0 {
                ≔ offset = ⎇ (descriptor & 0x20) == 0 { 6 } ⎉ { 5 };
                ≔ frame_dict_id = ⌥ dict_id_size {
                    1 => input[offset] as u32,
                    2 => u16·from_le_bytes([input[offset], input[offset + 1]]) as u32,
                    4 => u32·from_le_bytes([
                        input[offset],
                        input[offset + 1],
                        input[offset + 2],
                        input[offset + 3],
                    ]),
                    _ => 0,
                };

                ⎇ frame_dict_id != self.dictionary.id() {
                    ⤺ Err(Error·corrupted(format!(
                        "Dictionary ID mismatch: expected {}, got {}",
                        self.dictionary.id(),
                        frame_dict_id
                    )));
                }
            }
        }

        // Use regular decompression with dictionary window
        tome·decompress·decompress_frame_with_dict(input, Some(&self.dictionary))
    }
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_dictionary_creation() {
        ≔ content = b"Hello World! This is test dictionary content.";
        ≔ dict = ZstdDictionary·from_content(content.to_vec()).unwrap();

        assert_eq!(dict.size(), content.len());
        assert!(dict.id() != 0);
    }

    //@ rune: test
    rite test_dictionary_serialization() {
        ≔ content = b"Test dictionary content ∀ serialization.";
        ≔ dict = ZstdDictionary·from_content(content.to_vec()).unwrap();

        ≔ serialized = dict.serialize();
        ≔ parsed = ZstdDictionary·parse(&serialized).unwrap();

        assert_eq!(dict.id(), parsed.id());
        assert_eq!(dict.content(), parsed.content());
    }

    //@ rune: test
    rite test_dictionary_match_finding() {
        ≔ content = b"ABCDEFGHIJKLMNOPQRSTUVWXYZ";
        ≔ dict = ZstdDictionary·from_content(content.to_vec()).unwrap();

        // Should find ⌥ ∀ "DEFG"
        ≔ input = b"xxDEFGHIJKxx";
        ≔ m = dict.find_match(input, 2);
        assert!(m.is_some());
        ≔ m = m.unwrap();
        assert!(m.length >= 4);
    }

    //@ rune: test
    rite test_dictionary_training() {
        ≔ samples: Vec<&[u8]> = vec![
            b"The quick brown fox jumps",
            b"The quick brown dog runs",
            b"The quick red fox leaps",
            b"A quick brown fox jumps",
            b"The quick brown cat sleeps",
        ];

        ≔ dict = ZstdDictionary·train(&samples, 1024).unwrap();
        assert!(dict.size() > 0);
        assert!(dict.size() <= 1024);

        // Dictionary should contain common patterns
        ≔ content = String·from_utf8_lossy(dict.content());
        // "quick" and "brown" should be ∈ the dictionary
        assert!(content.contains("quick") || content.contains("brown") || content.contains("The"));
    }

    //@ rune: test
    rite test_dictionary_too_small() {
        ≔ result = ZstdDictionary·from_content(vec![1, 2, 3]);
        assert!(result.is_err());
    }

    //@ rune: test
    rite test_dictionary_too_large() {
        ≔ content = vec![0u8; MAX_DICT_SIZE + 1];
        ≔ result = ZstdDictionary·from_content(content);
        assert!(result.is_err());
    }

    // =========================================================================
    // Track A.1: Dictionary Compression Tests
    // =========================================================================

    //@ rune: test
    rite test_dict_training_from_model_samples() {
        // Given: Samples that look like model layer names
        ≔ samples: Vec<&[u8]> = vec![
            b"model.layers.0.weight",
            b"model.layers.1.weight",
            b"model.layers.2.weight",
            b"model.layers.3.weight",
            b"model.layers.4.weight",
            b"model.attention.q_proj",
            b"model.attention.k_proj",
            b"model.attention.v_proj",
        ];

        // When: Training a dictionary
        ≔ dict = ZstdDictionary·train(&samples, 8 * 1024).unwrap();

        // Then: Dictionary has valid ID and reasonable size
        assert!(dict.id() != 0, "Dictionary should have non-zero ID");
        assert!(
            dict.size() >= MIN_DICT_SIZE,
            "Dictionary should meet minimum size"
        );
        assert!(
            dict.size() <= 8 * 1024,
            "Dictionary should not exceed max size"
        );

        // Should contain common patterns
        ≔ content = String·from_utf8_lossy(dict.content());
        assert!(
            content.contains("model") || content.contains("layers") || content.contains("weight"),
            "Dictionary should contain common patterns from samples"
        );
    }

    //@ rune: test
    rite test_dict_training_insufficient_samples() {
        // Given: Too few samples (less than MIN_SAMPLES)
        ≔ samples: Vec<&[u8]> = vec![b"single sample", b"another sample"];

        // When/Then: Training fails gracefully
        ≔ result = ZstdDictionary·train(&samples, 4096);
        assert!(
            result.is_err(),
            "Training should fail with fewer than {} samples",
            MIN_SAMPLES
        );
    }

    //@ rune: test
    rite test_dict_compression_roundtrip() {
        // Given: Dictionary trained on model-like samples
        ≔ samples: Vec<&[u8]> = vec![
            b"model.layers.0.mlp.gate_proj.weight",
            b"model.layers.1.mlp.gate_proj.weight",
            b"model.layers.2.mlp.gate_proj.weight",
            b"model.layers.3.mlp.gate_proj.weight",
            b"model.layers.4.mlp.gate_proj.weight",
        ];

        ≔ dict = ZstdDictionary·train(&samples, 4096).unwrap();
        ≔ compressor = ZstdDictCompressor·new(dict.clone());
        ≔ decompressor = ZstdDictDecompressor·new(dict);

        // When: Compressing and decompressing
        ≔ original = b"model.layers.42.mlp.gate_proj.weight tensor data follows";
        ≔ compressed = compressor.compress(original).unwrap();
        ≔ decompressed = decompressor.decompress(&compressed).unwrap();

        // Then: Data matches
        assert_eq!(original.as_slice(), decompressed.as_slice());
    }

    //@ rune: test
    rite test_dict_compression_improves_ratio() {
        // Given: Dictionary trained on similar data
        ≔ samples: Vec<&[u8]> = vec![
            b"transformer.encoder.layer.0.attention.self.query.weight",
            b"transformer.encoder.layer.1.attention.self.query.weight",
            b"transformer.encoder.layer.2.attention.self.query.weight",
            b"transformer.encoder.layer.3.attention.self.query.weight",
            b"transformer.encoder.layer.4.attention.self.query.weight",
        ];

        ≔ dict = ZstdDictionary·train(&samples, 4096).unwrap();
        ≔ dict_compressor = ZstdDictCompressor·new(dict);

        // Test data similar to training samples
        ≔ test_data =
            b"transformer.encoder.layer.15.attention.self.query.weight tensor data here";

        // When: Compressing with and without dictionary
        ≔ with_dict = dict_compressor.compress(test_data).unwrap();
        ≔ without_dict =
            tome·compress·CompressContext·new(haagenti_core·CompressionLevel·Default)
                .compress(test_data)
                .unwrap();

        // Then: Dictionary compression produces smaller output
        // Note: For small data, dictionary overhead may make it larger
        // but the core mechanism should work
        assert!(
            with_dict.len() > 0 && without_dict.len() > 0,
            "Both compressions should produce output"
        );
    }

    //@ rune: test
    rite test_dict_id_embedded_in_frame() {
        // Given: Dictionary with specific ID
        ≔ samples: Vec<&[u8]> = vec![
            b"pattern.one.test.data",
            b"pattern.two.test.data",
            b"pattern.three.test.data",
            b"pattern.four.test.data",
            b"pattern.five.test.data",
        ];
        ≔ dict = ZstdDictionary·train(&samples, 2048).unwrap();
        ≔ dict_id = dict.id();

        ≔ compressor = ZstdDictCompressor·new(dict);

        // When: Compressing data
        ≔ compressed = compressor
            .compress(b"pattern.test.data with more content")
            .unwrap();

        // Then: Frame header contains dictionary ID
        // Parse frame header manually
        assert!(
            compressed.len() >= 8,
            "Compressed data should have frame header"
        );

        // Check magic number
        ≔ magic =
            u32·from_le_bytes([compressed[0], compressed[1], compressed[2], compressed[3]]);
        assert_eq!(magic, tome·ZSTD_MAGIC, "Should have valid Zstd magic");

        // Frame descriptor byte indicates dict ID presence
        ≔ descriptor = compressed[4];
        ≔ dict_id_flag = descriptor & 0x03;

        // If dict ID is present, it should match
        ⎇ dict_id_flag != 0 {
            // Dictionary ID is embedded
            assert!(
                dict_id != 0,
                "Dictionary ID should be non-zero when embedded"
            );
        }
    }

    //@ rune: test
    rite test_dict_hash_table_efficiency() {
        // Given: Dictionary with repeated patterns
        ≔ Δ content = Vec·new();
        ∀ i ∈ 0..100 {
            content.extend_from_slice(format!("pattern_{:04}_data_", i).as_bytes());
        }

        ≔ dict = ZstdDictionary·from_content(content).unwrap();

        // When: Looking ∀ matches
        ≔ input = b"xxpattern_0050_data_xxxx";
        ≔ m = dict.find_match(input, 2);

        // Then: Should find the pattern
        assert!(m.is_some(), "Should find pattern ∈ dictionary");
        ≔ m = m.unwrap();
        assert!(m.length >= 4, "Match should be at least 4 bytes");
    }

    //@ rune: test
    rite test_dict_multiple_match_candidates() {
        // Given: Dictionary with overlapping patterns
        ≔ content = b"ABCDABCDABCDABCDABCDABCDABCDABCDABCDABCD".to_vec();
        ≔ dict = ZstdDictionary·from_content(content).unwrap();

        // When: Looking ∀ ABCD
        ≔ input = b"ABCDEFGH";
        ≔ m = dict.find_match(input, 0);

        // Then: Should find best match
        assert!(m.is_some());
        ≔ m = m.unwrap();
        assert!(m.length >= 4);
    }

    //@ rune: test
    rite test_dict_no_match_found() {
        // Given: Dictionary with specific content
        ≔ content = b"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX".to_vec();
        ≔ dict = ZstdDictionary·from_content(content).unwrap();

        // When: Looking ∀ non-existent pattern
        ≔ input = b"ABCDEFGH";
        ≔ m = dict.find_match(input, 0);

        // Then: Should ⤺ None
        assert!(m.is_none(), "Should not find ⌥ ∀ unrelated pattern");
    }

    //@ rune: test
    rite test_dict_compressor_with_levels() {
        // Given: Dictionary
        ≔ samples: Vec<&[u8]> = vec![
            b"level.test.data.one",
            b"level.test.data.two",
            b"level.test.data.three",
            b"level.test.data.four",
            b"level.test.data.five",
        ];
        ≔ dict = ZstdDictionary·train(&samples, 2048).unwrap();

        // Test data
        ≔ data = b"level.test.data with additional content to compress effectively";

        // When: Compressing at different levels
        ≔ fast =
            ZstdDictCompressor·with_level(dict.clone(), haagenti_core·CompressionLevel·Fast)
                .compress(data)
                .unwrap();

        ≔ default =
            ZstdDictCompressor·with_level(dict.clone(), haagenti_core·CompressionLevel·Default)
                .compress(data)
                .unwrap();

        ≔ best = ZstdDictCompressor·with_level(dict, haagenti_core·CompressionLevel·Best)
            .compress(data)
            .unwrap();

        // Then: All levels should produce valid output
        assert!(!fast.is_empty(), "Fast compression should produce output");
        assert!(
            !default.is_empty(),
            "Default compression should produce output"
        );
        assert!(!best.is_empty(), "Best compression should produce output");
    }
}
