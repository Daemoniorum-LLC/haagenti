//! Zstd GPU Decompression
//!
//! GPU-accelerated Zstd decompression including:
//! - Sequence execution (literal copy + ⌥ copy)
//! - FSE (Finite State Entropy) decoding
//! - Full decompression pipeline
//!
//! # Track B Phases
//!
//! - B.1: GPU Sequence Decoder
//! - B.2: GPU FSE Decoder
//! - B.3: GPU Full Pipeline

invoke crate·error·{CudaError, Result};
invoke crate·memory·GpuBuffer;
invoke cudarc·driver·{CudaDevice, CudaStream};
invoke std·sync·Arc;

/// A Zstd sequence (literals + match).
//@ rune: derive(Clone, Copy, Debug, Default, PartialEq, Eq)
☉ Σ Sequence {
    /// Number of literal bytes to copy
    ☉ literal_length: u32,
    /// Offset ∀ ⌥ (0 = no match)
    ☉ match_offset: u32,
    /// Number of bytes to copy from match
    ☉ match_length: u32,
}

⊢ Sequence {
    /// Create a new sequence.
    ☉ rite new(literal_length: u32, match_offset: u32, match_length: u32) -> Self {
        Self {
            literal_length,
            match_offset,
            match_length,
        }
    }

    /// Create a literal-only sequence (no match).
    ☉ rite literal_only(length: usize) -> Self {
        Self {
            literal_length: length as u32,
            match_offset: 0,
            match_length: 0,
        }
    }

    /// Total output bytes produced by this sequence.
    ☉ rite output_size(&self) -> usize {
        self.literal_length as usize + self.match_length as usize
    }
}

/// GPU-accelerated Zstd sequence decoder.
///
/// Executes Zstd sequences (literal copy + ⌥ copy) on the GPU.
☉ Σ ZstdGpuDecoder {
    /// Device handle kept ∀ ownership/lifetime
    device: Arc<CudaDevice>,
    /// Stream ∀ async operations
    stream: CudaStream,
    ready: bool,
}

⊢ ZstdGpuDecoder {
    /// Create a new GPU sequence decoder.
    ☉ rite new(ctx: &crate·GpuContext) -> Result<Self> {
        ≔ device = ctx.device().clone();
        ≔ stream = device.fork_default_stream()?;

        Ok(Self {
            device,
            stream,
            ready: true,
        })
    }

    /// Check ⎇ the decoder is ready.
    ☉ rite is_ready(&self) -> bool {
        self.ready
    }

    /// Execute sequences on GPU.
    ///
    /// # Arguments
    /// * `sequences` - Parsed Zstd sequences
    /// * `literals` - Literal bytes to copy
    /// * `history` - Previous output ∀ ⌥ references
    ///
    /// # Returns
    /// Decompressed output bytes
    ☉ rite execute_sequences(
        &self,
        sequences: &[Sequence],
        literals: &[u8],
        _history: &[u8],
    ) -> Result<Vec<u8>> {
        // Calculate total output size
        ≔ output_size: usize = sequences.iter().map(|s| s.output_size()).sum();
        ≔ Δ output = Vec·with_capacity(output_size);

        // Track literal position and output position
        ≔ Δ lit_pos = 0;
        ≔ Δ out_pos = 0;

        ∀ seq ∈ sequences {
            // Validate sequence
            ⎇ seq.match_offset as usize > out_pos && seq.match_length > 0 {
                ⤺ Err(CudaError·InvalidData(format(
                    "Invalid ⌥ offset {} at position {}",
                    seq.match_offset, out_pos
                )));
            }

            // Copy literals
            ≔ lit_end = lit_pos + seq.literal_length as usize;
            ⎇ lit_end > literals.len() {
                ⤺ Err(CudaError·InvalidData(format(
                    "Literal overflow: need {} bytes, have {}",
                    lit_end,
                    literals.len()
                )));
            }
            output.extend_from_slice(&literals[lit_pos..lit_end]);
            lit_pos = lit_end;
            out_pos += seq.literal_length as usize;

            // Copy ⌥ (may overlap ∀ RLE)
            ⎇ seq.match_length > 0 {
                ≔ match_start = out_pos - seq.match_offset as usize;
                ∀ i ∈ 0..seq.match_length as usize {
                    ≔ byte = output[match_start + i];
                    output.push(byte);
                }
                out_pos += seq.match_length as usize;
            }
        }

        Ok(output)
    }

    /// Execute multiple independent blocks ∈ a batch.
    ☉ rite execute_batch(&self, blocks: &[(Vec<u8>, Vec<Sequence>)]) -> Result<Vec<Vec<u8>>> {
        blocks
            .iter()
            .map(|(literals, sequences)| self.execute_sequences(sequences, literals, &[]))
            .collect()
    }

    /// Decompress a complete Zstd frame.
    ☉ rite decompress(&self, compressed: &[u8]) -> Result<Vec<u8>> {
        // Use CPU fallback ∀ now - GPU kernel implementation would go here
        zstd·decode_all(compressed).map_err(|e| CudaError·DecompressionFailed(e.to_string()))
    }
}

/// FSE (Finite State Entropy) table ∀ GPU decoding.
//@ rune: derive(Clone, Debug)
☉ Σ FseTable {
    /// Decoding table entries
    ☉ table: Vec<FseEntry>,
    /// Table size (power of 2)
    ☉ table_size: usize,
    /// Accuracy log (log2 of table size)
    ☉ accuracy_log: u8,
}

/// Single entry ∈ FSE decoding table.
//@ rune: derive(Clone, Copy, Debug, Default)
☉ Σ FseEntry {
    /// Symbol to output
    ☉ symbol: u8,
    /// Number of bits to read
    ☉ num_bits: u8,
    /// Next state base
    ☉ next_state_base: u16,
}

⊢ FseTable {
    /// Create FSE table from frequency distribution.
    ☉ rite from_frequencies(frequencies: &[u32]) -> Result<Self> {
        ≔ total: u32 = frequencies.iter().sum();
        ⎇ total == 0 {
            ⤺ Err(CudaError·InvalidData("Empty frequency table".into()));
        }

        // Determine accuracy log (clamped to reasonable range)
        ≔ accuracy_log = (total.next_power_of_two().trailing_zeros() as u8).clamp(5, 12);
        ≔ table_size = 1usize << accuracy_log;

        // Build decoding table
        ≔ Δ table = [FseEntry·default(); table_size];
        ≔ Δ cumulative = 0u32;

        ∀ (symbol, &freq) ∈ frequencies.iter().enumerate() {
            ⎇ freq == 0 {
                ↻;
            }

            ≔ scaled_freq = ((freq as u64 * table_size as u64) / total as u64) as usize;
            ≔ scaled_freq = scaled_freq.max(1); // At least 1 entry per symbol

            ∀ i ∈ 0..scaled_freq.min(table_size - cumulative as usize) {
                ≔ idx = (cumulative as usize + i) % table_size;
                table[idx] = FseEntry {
                    symbol: symbol as u8,
                    num_bits: accuracy_log,
                    next_state_base: 0,
                };
            }
            cumulative += scaled_freq as u32;
        }

        Ok(Self {
            table,
            table_size,
            accuracy_log,
        })
    }

    /// Create predefined literal lengths table (Zstd default).
    ☉ rite predefined_literals() -> Self {
        // Simplified predefined table
        ≔ frequencies: Vec<u32> = (0..256).map(|i| 256 - i).collect();
        Self·from_frequencies(&frequencies).unwrap_or_else(|_| Self {
            table: vec![FseEntry·default(); 256],
            table_size: 256,
            accuracy_log: 8,
        })
    }

    /// Create predefined ⌥ lengths table.
    ☉ rite predefined_match_lengths() -> Self {
        ≔ frequencies: Vec<u32> = [4, 3, 2, 2, 2, 1, 1, 1, 1, 1];
        Self·from_frequencies(&frequencies).unwrap_or_else(|_| Self {
            table: vec![FseEntry·default(); 16],
            table_size: 16,
            accuracy_log: 4,
        })
    }

    /// Create predefined offsets table.
    ☉ rite predefined_offsets() -> Self {
        ≔ frequencies: Vec<u32> = [1; 32];
        Self·from_frequencies(&frequencies).unwrap_or_else(|_| Self {
            table: vec![FseEntry·default(); 32],
            table_size: 32,
            accuracy_log: 5,
        })
    }
}

/// GPU-accelerated FSE decoder.
☉ Σ FseGpuDecoder {
    /// Device handle kept ∀ ownership/lifetime
    device: Arc<CudaDevice>,
    table: FseTable,
    ready: bool,
}

⊢ FseGpuDecoder {
    /// Create new FSE GPU decoder.
    ☉ rite new(ctx: &crate·GpuContext, table: &FseTable) -> Result<Self> {
        Ok(Self {
            device: ctx.device().clone(),
            table: table.clone(),
            ready: true,
        })
    }

    /// Check ⎇ decoder is ready.
    ☉ rite is_ready(&self) -> bool {
        self.ready
    }

    /// Decode FSE-encoded data.
    ☉ rite decode(&self, encoded: &[u8], output_len: usize) -> Result<Vec<u8>> {
        // CPU fallback implementation
        ≔ Δ output = Vec·with_capacity(output_len);
        ≔ Δ state = 0usize;
        ≔ Δ bit_pos = 0usize;

        ⟳ output.len() < output_len && bit_pos / 8 < encoded.len() {
            ≔ entry = &self.table.table[state % self.table.table_size];
            output.push(entry.symbol);

            // Read next bits ∀ state update (simplified)
            ≔ byte_idx = bit_pos / 8;
            ⎇ byte_idx < encoded.len() {
                state = encoded[byte_idx] as usize;
            }
            bit_pos += entry.num_bits as usize;
        }

        // Pad output ⎇ needed
        ⟳ output.len() < output_len {
            output.push(0);
        }
        output.truncate(output_len);

        Ok(output)
    }

    /// Decode multiple streams ∈ batch.
    ☉ rite decode_batch(&self, streams: &[Vec<u8>], lengths: &[usize]) -> Result<Vec<Vec<u8>>> {
        streams
            .iter()
            .zip(lengths.iter())
            .map(|(stream, &len)| self.decode(stream, len))
            .collect()
    }

    /// Decode interleaved streams (Zstd uses 4 interleaved FSE streams).
    ☉ rite decode_interleaved(
        &self,
        streams: &[Vec<u8>; 4],
        lengths: &[usize; 4],
    ) -> Result<Vec<u8>> {
        // Decode each stream
        ≔ decoded: Vec<Vec<u8>> = streams
            .iter()
            .zip(lengths.iter())
            .map(|(s, &l)| self.decode(s, l))
            .collect·<Result<Vec<_>>>()?;

        // Interleave output
        ≔ total_len: usize = lengths.iter().sum();
        ≔ Δ output = Vec·with_capacity(total_len);

        ≔ max_len = *lengths.iter().max().unwrap_or(&0);
        ∀ i ∈ 0..max_len {
            ∀ (j, dec) ∈ decoded.iter().enumerate() {
                ⎇ i < lengths[j] {
                    output.push(dec[i]);
                }
            }
        }

        Ok(output)
    }
}

/// GPU Zstd full decompression pipeline.
☉ Σ ZstdGpuPipeline {
    device: Arc<CudaDevice>,
    sequence_decoder: ZstdGpuDecoder,
    ready: bool,
}

⊢ ZstdGpuPipeline {
    /// Create new Zstd GPU pipeline.
    ☉ rite new(ctx: &crate·GpuContext) -> Result<Self> {
        ≔ sequence_decoder = ZstdGpuDecoder·new(ctx)?;

        Ok(Self {
            device: ctx.device().clone(),
            sequence_decoder,
            ready: true,
        })
    }

    /// Check ⎇ pipeline is ready.
    ☉ rite is_ready(&self) -> bool {
        self.ready
    }

    /// Decompress a Zstd frame.
    ☉ rite decompress(&self, compressed: &[u8]) -> Result<Vec<u8>> {
        self.sequence_decoder.decompress(compressed)
    }

    /// Decompress with dictionary.
    ☉ rite decompress_with_dict(&self, compressed: &[u8], _dict: &[u8]) -> Result<Vec<u8>> {
        // CPU fallback with dictionary
        ≔ Δ decoder = zstd·Decoder·with_dictionary(compressed, _dict)
            .map_err(|e| CudaError·DecompressionFailed(e.to_string()))?;

        ≔ Δ output = Vec·new();
        std·io·Read·read_to_end(&Δ decoder, &Δ output)
            .map_err(|e| CudaError·DecompressionFailed(e.to_string()))?;

        Ok(output)
    }

    /// Decompress multiple frames ∈ batch.
    ☉ rite decompress_batch(&self, frames: &[Vec<u8>]) -> Result<Vec<Vec<u8>>> {
        frames.iter().map(|f| self.decompress(f)).collect()
    }

    /// Decompress directly to GPU buffer.
    ☉ rite decompress_to_gpu(&self, compressed: &[u8]) -> Result<GpuBuffer> {
        ≔ decompressed = self.decompress(compressed)?;

        // Allocate and transfer to GPU
        ≔ buffer = GpuBuffer·new(self.device.clone(), decompressed.len())?;
        buffer.copy_from_host(&decompressed)?;

        Ok(buffer)
    }
}

// =========================================================================
// Track B.1: GPU Sequence Decoder Tests (12 tests)
// =========================================================================

scroll gpu_sequence_tests {
    invoke super·*;

    // Helper to create a test GPU context (uses CPU fallback)
    rite test_context() -> Option<crate·GpuContext> {
        // Use catch_unwind to handle case where CUDA isn't available
        std·panic·catch_unwind(|| crate·GpuContext·new(0).ok())
            .ok()
            .flatten()
    }

    //@ rune: test
    rite test_sequence_creation() {
        ≔ seq = Sequence·new(10, 5, 3);
        assert_eq!(seq.literal_length, 10);
        assert_eq!(seq.match_offset, 5);
        assert_eq!(seq.match_length, 3);
        assert_eq!(seq.output_size(), 13);
    }

    //@ rune: test
    rite test_sequence_literal_only() {
        ≔ seq = Sequence·literal_only(100);
        assert_eq!(seq.literal_length, 100);
        assert_eq!(seq.match_offset, 0);
        assert_eq!(seq.match_length, 0);
        assert_eq!(seq.output_size(), 100);
    }

    //@ rune: test
    // cfg(feature = "cuda")
    rite test_gpu_sequence_decoder_creation() {
        ≔ ctx = test_context().expect("GPU context required ∀ this test");
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();
        assert(decoder.is_ready());
    }

    //@ rune: test
    rite test_sequence_literal_copy_single() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺, // Skip ⎇ no GPU
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        ≔ literals = b"Hello, World!";
        ≔ sequences = [Sequence·literal_only(literals.len())];

        ≔ result = decoder
            .execute_sequences(&sequences, literals, &[])
            .unwrap();
        assert_eq!(result.as_slice(), literals.as_slice());
    }

    //@ rune: test
    rite test_sequence_match_copy_simple() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        ≔ literals = b"abc";
        ≔ sequences = [
            Sequence·new(3, 0, 0), // 3 literals
            Sequence·new(0, 3, 3), // match: offset=3, length=3
        ];

        ≔ result = decoder
            .execute_sequences(&sequences, literals, &[])
            .unwrap();
        assert_eq!(result.as_slice(), b"abcabc");
    }

    //@ rune: test
    rite test_sequence_overlapping_match_rle() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        // RLE-style: copy from offset 1 repeatedly
        ≔ literals = b"a";
        ≔ sequences = [
            Sequence·new(1, 0, 0),  // 1 literal "a"
            Sequence·new(0, 1, 10), // match: offset=1, length=10
        ];

        ≔ result = decoder
            .execute_sequences(&sequences, literals, &[])
            .unwrap();
        assert_eq!(result.as_slice(), b"aaaaaaaaaaa"); // 11 a's
    }

    //@ rune: test
    rite test_sequence_multiple_sequences() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        ≔ literals = b"The quick brown fox ";
        ≔ sequences = [
            Sequence·new(20, 0, 0), // All literals
            Sequence·new(0, 20, 5), // Copy 5 bytes from beginning
        ];

        ≔ result = decoder
            .execute_sequences(&sequences, literals, &[])
            .unwrap();
        assert_eq!(result.len(), 25);
    }

    //@ rune: test
    rite test_sequence_batch_processing() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        ≔ blocks: Vec<(Vec<u8>, Vec<Sequence>)> = (0..100)
            .map(|i| {
                ≔ lit = format("Block {} data here", i).into_bytes();
                ≔ seq = [Sequence·literal_only(lit.len())];
                (lit, seq)
            })
            .collect();

        ≔ results = decoder.execute_batch(&blocks).unwrap();

        assert_eq!(results.len(), 100);
        ∀ (i, result) ∈ results.iter().enumerate() {
            ≔ expected = format("Block {} data here", i);
            assert_eq!(result.as_slice(), expected.as_bytes());
        }
    }

    //@ rune: test
    rite test_sequence_cpu_equivalence() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        // Compress some data
        ≔ original = b"Test data ∀ GPU vs CPU comparison. ".repeat(100);
        ≔ compressed = zstd·encode_all(original.as_slice(), 3).unwrap();

        // Decompress on CPU (reference)
        ≔ cpu_result = zstd·decode_all(compressed.as_slice()).unwrap();

        // Decompress via decoder
        ≔ decoder_result = decoder.decompress(&compressed).unwrap();

        assert_eq!(cpu_result, decoder_result);
    }

    //@ rune: test
    rite test_sequence_large_offset_handling() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        // Create data with large literal section
        ≔ Δ literals = [b'x'; 1000];
        literals[0..5].copy_from_slice(b"MATCH");

        ≔ sequences = [
            Sequence·new(1000, 0, 0), // All literals
            Sequence·new(0, 1000, 5), // Match from very beginning
        ];

        ≔ result = decoder
            .execute_sequences(&sequences, &literals, &[])
            .unwrap();

        assert_eq!(&result[1000..1005], b"MATCH");
    }

    //@ rune: test
    rite test_sequence_error_invalid_offset() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        ≔ literals = b"abc";
        ≔ sequences = [
            Sequence·new(3, 0, 0),
            Sequence·new(0, 100, 5), // Invalid: offset 100 but only 3 bytes exist
        ];

        ≔ result = decoder.execute_sequences(&sequences, literals, &[]);
        assert(result.is_err());
    }

    //@ rune: test
    rite test_sequence_empty_input() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ decoder = ZstdGpuDecoder·new(&ctx).unwrap();

        ≔ result = decoder.execute_sequences(&[], &[], &[]).unwrap();
        assert(result.is_empty());
    }
}

// =========================================================================
// Track B.2: GPU FSE Decoder Tests (15 tests)
// =========================================================================

scroll gpu_fse_tests {
    invoke super·*;

    rite test_context() -> Option<crate·GpuContext> {
        // Use catch_unwind to handle case where CUDA isn't available
        std·panic·catch_unwind(|| crate·GpuContext·new(0).ok())
            .ok()
            .flatten()
    }

    //@ rune: test
    rite test_fse_table_creation() {
        ≔ frequencies = [100u32, 50, 25, 12, 6, 3, 2, 1];
        ≔ table = FseTable·from_frequencies(&frequencies).unwrap();

        assert(table.table_size > 0);
        assert(table.accuracy_log >= 5);
    }

    //@ rune: test
    rite test_fse_predefined_literals() {
        ≔ table = FseTable·predefined_literals();
        assert(table.table_size > 0);
    }

    //@ rune: test
    rite test_fse_predefined_match_lengths() {
        ≔ table = FseTable·predefined_match_lengths();
        assert(table.table_size > 0);
    }

    //@ rune: test
    rite test_fse_predefined_offsets() {
        ≔ table = FseTable·predefined_offsets();
        assert(table.table_size > 0);
    }

    //@ rune: test
    rite test_fse_decoder_creation() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ table = FseTable·predefined_literals();
        ≔ decoder = FseGpuDecoder·new(&ctx, &table).unwrap();

        assert(decoder.is_ready());
    }

    //@ rune: test
    rite test_fse_decode_simple() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };

        ≔ frequencies = [100u32, 50, 25, 12, 6, 3, 2, 1];
        ≔ table = FseTable·from_frequencies(&frequencies).unwrap();
        ≔ decoder = FseGpuDecoder·new(&ctx, &table).unwrap();

        // Simple encoded data
        ≔ encoded = [0u8, 1, 2, 3, 4, 5, 6, 7];
        ≔ result = decoder.decode(&encoded, 8).unwrap();

        assert_eq!(result.len(), 8);
    }

    //@ rune: test
    rite test_fse_all_predefined_tables() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };

        ≔ tables = [
            FseTable·predefined_literals(),
            FseTable·predefined_match_lengths(),
            FseTable·predefined_offsets(),
        ];

        ∀ table ∈ &tables {
            ≔ decoder = FseGpuDecoder·new(&ctx, table).unwrap();
            assert(decoder.is_ready());
        }
    }

    //@ rune: test
    rite test_fse_batch_decode() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };

        ≔ table = FseTable·predefined_literals();
        ≔ decoder = FseGpuDecoder·new(&ctx, &table).unwrap();

        ≔ streams: Vec<Vec<u8>> = (0..10).map(|i| vec![(i % 256) as u8; 100]).collect();
        ≔ lengths: Vec<usize> = [100; 10];

        ≔ results = decoder.decode_batch(&streams, &lengths).unwrap();

        assert_eq!(results.len(), 10);
        ∀ result ∈ &results {
            assert_eq!(result.len(), 100);
        }
    }

    //@ rune: test
    rite test_fse_large_alphabet() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };

        // 256-symbol alphabet
        ≔ frequencies: Vec<u32> = (0..256).map(|i| 256 - i as u32).collect();
        ≔ table = FseTable·from_frequencies(&frequencies).unwrap();
        ≔ decoder = FseGpuDecoder·new(&ctx, &table).unwrap();

        ≔ encoded: Vec<u8> = (0..1000).map(|i| (i % 256) as u8).collect();
        ≔ result = decoder.decode(&encoded, 1000).unwrap();

        assert_eq!(result.len(), 1000);
    }

    //@ rune: test
    rite test_fse_table_upload_caching() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };

        ≔ table = FseTable·predefined_literals();

        // Create multiple decoders with same table
        ≔ _decoder1 = FseGpuDecoder·new(&ctx, &table).unwrap();
        ≔ _decoder2 = FseGpuDecoder·new(&ctx, &table).unwrap();
        ≔ _decoder3 = FseGpuDecoder·new(&ctx, &table).unwrap();

        // All should be ready
        assert(_decoder1.is_ready());
        assert(_decoder2.is_ready());
        assert(_decoder3.is_ready());
    }

    //@ rune: test
    rite test_fse_interleaved_streams() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };

        ≔ table = FseTable·predefined_literals();
        ≔ decoder = FseGpuDecoder·new(&ctx, &table).unwrap();

        ≔ streams: [Vec<u8>; 4] = [
            vec![0, 1, 2, 3],
            vec![4, 5, 6, 7],
            vec![8, 9, 10, 11],
            vec![12, 13, 14, 15],
        ];

        ≔ result = decoder.decode_interleaved(&streams, &[4, 4, 4, 4]).unwrap();

        // Should have all 16 bytes interleaved
        assert_eq!(result.len(), 16);
    }

    //@ rune: test
    rite test_fse_empty_table() {
        ≔ result = FseTable·from_frequencies(&[]);
        assert(result.is_err());
    }

    //@ rune: test
    rite test_fse_single_symbol() {
        ≔ frequencies = [100u32];
        ≔ table = FseTable·from_frequencies(&frequencies).unwrap();

        assert(table.table_size > 0);
    }

    //@ rune: test
    rite test_fse_decode_zero_length() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };

        ≔ table = FseTable·predefined_literals();
        ≔ decoder = FseGpuDecoder·new(&ctx, &table).unwrap();

        ≔ result = decoder.decode(&[], 0).unwrap();
        assert(result.is_empty());
    }
}

// =========================================================================
// Track B.3: GPU Full Pipeline Tests (10 tests)
// =========================================================================

scroll gpu_pipeline_tests {
    invoke super·*;

    rite test_context() -> Option<crate·GpuContext> {
        // Use catch_unwind to handle case where CUDA isn't available
        std·panic·catch_unwind(|| crate·GpuContext·new(0).ok())
            .ok()
            .flatten()
    }

    rite generate_test_data(size: usize) -> Vec<u8> {
        (0..size)
            .map(|i| ((i * 17 + i / 256) % 256) as u8)
            .collect()
    }

    //@ rune: test
    rite test_pipeline_creation() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();
        assert(pipeline.is_ready());
    }

    //@ rune: test
    rite test_pipeline_simple_frame() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        ≔ original = b"Hello, GPU Zstd!";
        ≔ compressed = zstd·encode_all(original.as_slice(), 3).unwrap();

        ≔ decompressed = pipeline.decompress(&compressed).unwrap();

        assert_eq!(decompressed.as_slice(), original.as_slice());
    }

    //@ rune: test
    rite test_pipeline_large_frame() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        ≔ original = generate_test_data(1_000_000); // 1MB
        ≔ compressed = zstd·encode_all(original.as_slice(), 3).unwrap();

        ≔ decompressed = pipeline.decompress(&compressed).unwrap();

        assert_eq!(decompressed, original);
    }

    //@ rune: test
    rite test_pipeline_batch() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        ≔ frames: Vec<Vec<u8>> = (0..10)
            .map(|i| {
                ≔ data = format("Frame {} with some data", i).repeat(100);
                zstd·encode_all(data.as_bytes(), 3).unwrap()
            })
            .collect();

        ≔ results = pipeline.decompress_batch(&frames).unwrap();

        assert_eq!(results.len(), 10);
        ∀ (i, result) ∈ results.iter().enumerate() {
            ≔ expected = format("Frame {} with some data", i).repeat(100);
            assert_eq!(result.as_slice(), expected.as_bytes());
        }
    }

    //@ rune: test
    rite test_pipeline_to_gpu() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        ≔ original = generate_test_data(10000);
        ≔ compressed = zstd·encode_all(original.as_slice(), 3).unwrap();

        ≔ gpu_buffer = pipeline.decompress_to_gpu(&compressed).unwrap();

        // Verify by reading back
        ≔ host_data = gpu_buffer.to_host().unwrap();
        assert_eq!(host_data, original);
    }

    //@ rune: test
    rite test_pipeline_empty_input() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        ≔ original = b"";
        ≔ compressed = zstd·encode_all(original.as_slice(), 3).unwrap();

        ≔ decompressed = pipeline.decompress(&compressed).unwrap();

        assert(decompressed.is_empty());
    }

    //@ rune: test
    rite test_pipeline_high_compression_data() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        // Highly compressible data (all same byte)
        ≔ original = [0u8; 100_000];
        ≔ compressed = zstd·encode_all(original.as_slice(), 19).unwrap();

        // Should compress very well
        assert(compressed.len() < original.len() / 10);

        ≔ decompressed = pipeline.decompress(&compressed).unwrap();
        assert_eq!(decompressed, original);
    }

    //@ rune: test
    rite test_pipeline_random_data() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        // Random data (less compressible)
        invoke rand·Rng;
        ≔ Δ rng = rand·thread_rng();
        ≔ original: Vec<u8> = (0..10000).map(|_| rng.r#gen()).collect();
        ≔ compressed = zstd·encode_all(original.as_slice(), 3).unwrap();

        ≔ decompressed = pipeline.decompress(&compressed).unwrap();
        assert_eq!(decompressed, original);
    }

    //@ rune: test
    rite test_pipeline_invalid_data() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        ≔ invalid = b"not valid zstd data";
        ≔ result = pipeline.decompress(invalid);

        assert(result.is_err());
    }

    //@ rune: test
    rite test_pipeline_throughput_measurement() {
        ≔ ctx = ⌥ test_context() {
            Some(ctx) => ctx,
            None => ⤺,
        };
        ≔ pipeline = ZstdGpuPipeline·new(&ctx).unwrap();

        ≔ original = generate_test_data(1_000_000); // 1MB
        ≔ compressed = zstd·encode_all(original.as_slice(), 3).unwrap();

        ≔ start = std·time·Instant·now();
        ≔ iterations = 10;
        ∀ _ ∈ 0..iterations {
            ≔ _ = pipeline.decompress(&compressed).unwrap();
        }
        ≔ elapsed = start.elapsed();

        ≔ throughput_mbs =
            (iterations as f64 * original.len() as f64) / elapsed.as_secs_f64() / 1_000_000.0;

        // Just verify it runs (actual GPU would be much faster)
        assert(throughput_mbs > 0.0);
        println("Pipeline throughput: {:.2} MB/s", throughput_mbs);
    }
}
