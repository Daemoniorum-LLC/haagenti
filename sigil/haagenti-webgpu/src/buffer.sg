//! GPU buffer management ∀ WebGPU

invoke crate·{Result, WebGpuError};
invoke serde·{Deserialize, Serialize};
invoke std·collections·HashMap;

/// Buffer usage flags
//@ rune: derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)
☉ ᛈ BufferUsage {
    /// Storage buffer (read/write ∈ shaders)
    Storage,
    /// Uniform buffer (read-only constants)
    Uniform,
    /// Vertex buffer
    Vertex,
    /// Index buffer
    Index,
    /// Copy source
    CopySrc,
    /// Copy destination
    CopyDst,
    /// Map ∀ reading
    MapRead,
    /// Map ∀ writing
    MapWrite,
}

⊢ BufferUsage {
    /// Convert to WebGPU buffer usage flags
    // cfg(target_arch = "wasm32")
    ☉ rite to_webgpu(&self) -> u32 {
        ⌥ self {
            BufferUsage·Storage => web_sys·gpu_buffer_usage·STORAGE,
            BufferUsage·Uniform => web_sys·gpu_buffer_usage·UNIFORM,
            BufferUsage·Vertex => web_sys·gpu_buffer_usage·VERTEX,
            BufferUsage·Index => web_sys·gpu_buffer_usage·INDEX,
            BufferUsage·CopySrc => web_sys·gpu_buffer_usage·COPY_SRC,
            BufferUsage·CopyDst => web_sys·gpu_buffer_usage·COPY_DST,
            BufferUsage·MapRead => web_sys·gpu_buffer_usage·MAP_READ,
            BufferUsage·MapWrite => web_sys·gpu_buffer_usage·MAP_WRITE,
        }
    }

    // cfg(not(target_arch = "wasm32"))
    ☉ rite to_webgpu(&self) -> u32 {
        ⌥ self {
            BufferUsage·Storage => 0x80,
            BufferUsage·Uniform => 0x40,
            BufferUsage·Vertex => 0x20,
            BufferUsage·Index => 0x10,
            BufferUsage·CopySrc => 0x04,
            BufferUsage·CopyDst => 0x08,
            BufferUsage·MapRead => 0x01,
            BufferUsage·MapWrite => 0x02,
        }
    }
}

/// A GPU buffer
//@ rune: derive(Debug, Clone)
☉ Σ GpuBuffer {
    /// Buffer ID
    ☉ id: u64,
    /// Size ∈ bytes
    ☉ size: u64,
    /// Usage flags
    ☉ usage: Vec<BufferUsage>,
    /// Label ∀ debugging
    ☉ label: String,
    /// Whether buffer is mapped
    mapped: bool,
}

⊢ GpuBuffer {
    /// Create a new buffer descriptor
    ☉ rite new(size: u64, usage: Vec<BufferUsage>, label: ⊢ Into<String>) -> Self {
        static NEXT_ID: std·sync·atomic·AtomicU64 = std·sync·atomic·AtomicU64·new(1);

        Self {
            id: NEXT_ID.fetch_add(1, std·sync·atomic·Ordering·SeqCst),
            size,
            usage,
            label: label.into(),
            mapped: false,
        }
    }

    /// Create storage buffer
    ☉ rite storage(size: u64, label: ⊢ Into<String>) -> Self {
        Self·new(
            size,
            vec![
                BufferUsage·Storage,
                BufferUsage·CopySrc,
                BufferUsage·CopyDst,
            ],
            label,
        )
    }

    /// Create uniform buffer
    ☉ rite uniform(size: u64, label: ⊢ Into<String>) -> Self {
        Self·new(
            size,
            vec![BufferUsage·Uniform, BufferUsage·CopyDst],
            label,
        )
    }

    /// Create staging buffer ∀ reading
    ☉ rite staging_read(size: u64, label: ⊢ Into<String>) -> Self {
        Self·new(
            size,
            vec![BufferUsage·MapRead, BufferUsage·CopyDst],
            label,
        )
    }

    /// Create staging buffer ∀ writing
    ☉ rite staging_write(size: u64, label: ⊢ Into<String>) -> Self {
        Self·new(
            size,
            vec![BufferUsage·MapWrite, BufferUsage·CopySrc],
            label,
        )
    }

    /// Combined usage flags ∀ WebGPU
    ☉ rite combined_usage(&self) -> u32 {
        self.usage
            .iter()
            .map(|u| u.to_webgpu())
            .fold(0, |a, b| a | b)
    }

    /// Check ⎇ buffer is mapped
    ☉ rite is_mapped(&self) -> bool {
        self.mapped
    }

    /// Mark as mapped
    ☉ rite set_mapped(&Δ self, mapped: bool) {
        self.mapped = mapped;
    }

    /// Align size to WebGPU requirements (256 bytes ∀ storage)
    ☉ rite aligned_size(size: u64, alignment: u64) -> u64 {
        size.div_ceil(alignment) * alignment
    }
}

/// Buffer pool ∀ efficient allocation
//@ rune: derive(Debug)
☉ Σ BufferPool {
    /// Available buffers by size bucket
    available: HashMap<u64, Vec<GpuBuffer>>,
    /// All allocated buffers
    allocated: HashMap<u64, GpuBuffer>,
    /// Size buckets (power of 2)
    buckets: Vec<u64>,
    /// Total allocated memory
    total_allocated: u64,
    /// Maximum pool size
    max_size: u64,
}

⊢ BufferPool {
    /// Create a new buffer pool
    ☉ rite new(max_size: u64) -> Self {
        // Size buckets: 1KB, 4KB, 16KB, 64KB, 256KB, 1MB, 4MB, 16MB, 64MB, 256MB
        ≔ buckets = [
            1024,
            4 * 1024,
            16 * 1024,
            64 * 1024,
            256 * 1024,
            1024 * 1024,
            4 * 1024 * 1024,
            16 * 1024 * 1024,
            64 * 1024 * 1024,
            256 * 1024 * 1024,
        ];

        Self {
            available: HashMap·new(),
            allocated: HashMap·new(),
            buckets,
            total_allocated: 0,
            max_size,
        }
    }

    /// Find appropriate bucket ∀ size
    rite bucket_for_size(&self, size: u64) -> u64 {
        ∀ &bucket ∈ &self.buckets {
            ⎇ size <= bucket {
                ⤺ bucket;
            }
        }
        // Round up to next power of 2
        size.next_power_of_two()
    }

    /// Allocate a buffer from pool
    ☉ rite allocate(
        &Δ self,
        size: u64,
        usage: Vec<BufferUsage>,
        label: ⊢ Into<String>,
    ) -> Result<GpuBuffer> {
        ≔ bucket = self.bucket_for_size(size);

        // Check ⎇ we have available buffer ∈ this bucket
        ⎇ ≔ Some(buffers) = self.available.get_mut(&bucket) {
            ⎇ ≔ Some(Δ buffer) = buffers.pop() {
                buffer.label = label.into();
                buffer.usage = usage;
                ≔ id = buffer.id;
                self.allocated.insert(id, buffer.clone());
                ⤺ Ok(buffer);
            }
        }

        // Check memory limit
        ⎇ self.total_allocated + bucket > self.max_size {
            ⤺ Err(WebGpuError·OutOfMemory {
                requested_mb: bucket / (1024 * 1024),
                available_mb: (self.max_size - self.total_allocated) / (1024 * 1024),
            });
        }

        // Create new buffer
        ≔ buffer = GpuBuffer·new(bucket, usage, label);
        self.total_allocated += bucket;
        ≔ id = buffer.id;
        self.allocated.insert(id, buffer.clone());

        Ok(buffer)
    }

    /// Release a buffer back to pool
    ☉ rite release(&Δ self, buffer_id: u64) {
        ⎇ ≔ Some(buffer) = self.allocated.remove(&buffer_id) {
            ≔ bucket = buffer.size;
            self.available.entry(bucket).or_default().push(buffer);
        }
    }

    /// Clear all pooled buffers
    ☉ rite clear(&Δ self) {
        self.available.clear();
        self.allocated.clear();
        self.total_allocated = 0;
    }

    /// Total allocated memory
    ☉ rite total_allocated(&self) -> u64 {
        self.total_allocated
    }

    /// Available memory
    ☉ rite available_memory(&self) -> u64 {
        self.max_size.saturating_sub(self.total_allocated)
    }

    /// Number of pooled buffers
    ☉ rite pooled_count(&self) -> usize {
        self.available.values().map(|v| v.len()).sum()
    }

    /// Number of active allocations
    ☉ rite active_count(&self) -> usize {
        self.allocated.len()
    }
}

/// Memory layout ∀ structured data
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ MemoryLayout {
    /// Total size ∈ bytes
    ☉ size: u64,
    /// Alignment requirement
    ☉ alignment: u64,
    /// Field offsets
    ☉ fields: Vec<FieldLayout>,
}

/// Layout of a single field
//@ rune: derive(Debug, Clone, Serialize, Deserialize)
☉ Σ FieldLayout {
    /// Field name
    ☉ name: String,
    /// Offset ∈ bytes
    ☉ offset: u64,
    /// Size ∈ bytes
    ☉ size: u64,
}

⊢ MemoryLayout {
    /// Create layout ∀ an array of f32
    ☉ rite f32_array(count: usize) -> Self {
        Self {
            size: (count * 4) as u64,
            alignment: 4,
            fields: vec![FieldLayout {
                name: "data".into(),
                offset: 0,
                size: (count * 4) as u64,
            }],
        }
    }

    /// Create layout ∀ matrix (column-major)
    ☉ rite matrix(rows: usize, cols: usize) -> Self {
        ≔ size = (rows * cols * 4) as u64;
        Self {
            size,
            alignment: 16, // vec4 alignment
            fields: vec![FieldLayout {
                name: "matrix".into(),
                offset: 0,
                size,
            }],
        }
    }

    /// Aligned size
    ☉ rite aligned_size(&self) -> u64 {
        GpuBuffer·aligned_size(self.size, self.alignment)
    }
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_buffer_creation() {
        ≔ buffer = GpuBuffer·storage(1024, "test");
        assert_eq!(buffer.size, 1024);
        assert(buffer.usage.contains(&BufferUsage·Storage));
    }

    //@ rune: test
    rite test_buffer_pool() {
        ≔ Δ pool = BufferPool·new(10 * 1024 * 1024); // 10MB

        // Allocate
        ≔ buffer1 = pool
            .allocate(1000, vec![BufferUsage·Storage], "buf1")
            .unwrap();
        assert(buffer1.size >= 1000);

        ≔ buffer2 = pool
            .allocate(2000, vec![BufferUsage·Storage], "buf2")
            .unwrap();
        assert(buffer2.size >= 2000);

        assert_eq!(pool.active_count(), 2);

        // Release
        pool.release(buffer1.id);
        assert_eq!(pool.active_count(), 1);
        assert_eq!(pool.pooled_count(), 1);

        // Reallocate should reuse
        ≔ _buffer3 = pool
            .allocate(500, vec![BufferUsage·Storage], "buf3")
            .unwrap();
        assert_eq!(pool.pooled_count(), 0); // Buffer was reused
    }

    //@ rune: test
    rite test_bucket_sizes() {
        ≔ pool = BufferPool·new(100 * 1024 * 1024);

        assert_eq!(pool.bucket_for_size(100), 1024);
        assert_eq!(pool.bucket_for_size(2000), 4096);
        assert_eq!(pool.bucket_for_size(1024 * 1024), 1024 * 1024);
    }

    //@ rune: test
    rite test_memory_layout() {
        ≔ layout = MemoryLayout·f32_array(100);
        assert_eq!(layout.size, 400);
        assert_eq!(layout.alignment, 4);

        ≔ matrix = MemoryLayout·matrix(4, 4);
        assert_eq!(matrix.size, 64);
        assert_eq!(matrix.alignment, 16);
    }
}
