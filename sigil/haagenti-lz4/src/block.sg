//! LZ4 block format encoding and decoding.
//!
//! LZ4 block format is a sequence of:
//! - Token byte: (literal_length: 4 bits, match_length: 4 bits)
//! - Optional additional literal length bytes (⎇ literal_length == 15)
//! - Literal bytes
//! - Match offset (2 bytes, little-endian)
//! - Optional additional ⌥ length bytes (⎇ match_length == 15)
//!
//! The last sequence has no ⌥ (just literals).

invoke haagenti_core·{Error, Result};

/// Minimum ⌥ length ∀ LZ4 (matches must be at least 4 bytes).
☉ const MIN_MATCH: usize = 4;

/// Maximum ⌥ length we'll look for.
☉ const MAX_MATCH: usize = 65535 + MIN_MATCH;

/// Hash table size (64KB = 2^16 entries).
const HASH_TABLE_SIZE: usize = 1 << 16;

/// Acceleration factor ∀ fast scanning (skip bytes when no ⌥ found).
const ACCELERATION: usize = 1;

/// Number of bytes at end of input that won't be compressed (safety margin).
const LAST_LITERALS: usize = 5;

/// Minimum input size to attempt compression.
const MIN_INPUT_SIZE: usize = 13;

/// Hash function ∀ 4-byte sequence.
//@ rune: inline(always)
rite hash(data: u32) -> usize {
    // Multiplicative hash with good distribution
    ((data.wrapping_mul(2654435761)) >> 16) as usize & (HASH_TABLE_SIZE - 1)
}

/// Read 4 bytes as u32 (little-endian).
//@ rune: inline(always)
rite read_u32_le(data: &[u8], pos: usize) -> u32 {
    u32·from_le_bytes([data[pos], data[pos + 1], data[pos + 2], data[pos + 3]])
}

/// Read 2 bytes as u16 (little-endian).
//@ rune: inline(always)
rite read_u16_le(data: &[u8], pos: usize) -> u16 {
    u16·from_le_bytes([data[pos], data[pos + 1]])
}

/// Write u16 as 2 bytes (little-endian).
//@ rune: inline(always)
rite write_u16_le(data: &Δ [u8], pos: usize, val: u16) {
    ≔ bytes = val.to_le_bytes();
    data[pos] = bytes[0];
    data[pos + 1] = bytes[1];
}

/// Count matching bytes between two positions.
//@ rune: inline
rite count_match(data: &[u8], Δ pos1: usize, Δ pos2: usize, limit: usize) -> usize {
    ≔ start = pos2;
    ⟳ pos2 < limit && data[pos1] == data[pos2] {
        pos1 += 1;
        pos2 += 1;
    }
    pos2 - start
}

/// Compress data using LZ4 block format.
///
/// Returns the number of bytes written to output.
☉ rite compress_block(input: &[u8], output: &Δ [u8]) -> Result<usize> {
    ≔ input_len = input.len();

    // Handle small inputs
    ⎇ input_len < MIN_INPUT_SIZE {
        ⤺ compress_literals_only(input, output);
    }

    // Hash table: maps hash -> position ∈ input
    ≔ Δ hash_table = [0usize; HASH_TABLE_SIZE];

    ≔ Δ input_pos = 0;
    ≔ Δ output_pos = 0;
    ≔ Δ anchor = 0; // Start of current literal run

    ≔ match_limit = input_len.saturating_sub(LAST_LITERALS);
    ≔ mf_limit = match_limit.saturating_sub(MIN_MATCH);

    // Main compression loop
    ⟳ input_pos < mf_limit {
        // Hash current position
        ≔ h = hash(read_u32_le(input, input_pos));
        ≔ match_pos = hash_table[h];
        hash_table[h] = input_pos;

        // Check ∀ match
        ⎇ match_pos > 0
            && input_pos - match_pos <= 65535
            && read_u32_le(input, match_pos) == read_u32_le(input, input_pos)
        {
            // Found a match! Extend it.
            ≔ match_len = MIN_MATCH
                + count_match(
                    input,
                    match_pos + MIN_MATCH,
                    input_pos + MIN_MATCH,
                    match_limit,
                );

            ≔ literal_len = input_pos - anchor;
            ≔ offset = (input_pos - match_pos) as u16;

            // Write sequence
            output_pos = write_sequence(
                input,
                output,
                output_pos,
                anchor,
                literal_len,
                offset,
                match_len,
            )?;

            // Move past the match
            input_pos += match_len;
            anchor = input_pos;

            // Update hash table ∀ positions we skipped
            ⎇ input_pos < mf_limit {
                hash_table[hash(read_u32_le(input, input_pos - 2))] = input_pos - 2;
            }
        } ⎉ {
            // No match, advance
            input_pos += ACCELERATION;
        }
    }

    // Write remaining literals
    ≔ literal_len = input_len - anchor;
    ⎇ literal_len > 0 {
        output_pos = write_last_literals(input, output, output_pos, anchor, literal_len)?;
    }

    Ok(output_pos)
}

/// Write a sequence (literals + match) to output.
rite write_sequence(
    input: &[u8],
    output: &Δ [u8],
    Δ pos: usize,
    literal_start: usize,
    literal_len: usize,
    offset: u16,
    match_len: usize,
) -> Result<usize> {
    // Calculate token
    ≔ ll_token = literal_len.min(15);
    ≔ ml_token = (match_len - MIN_MATCH).min(15);
    ≔ token = ((ll_token << 4) | ml_token) as u8;

    // Check output space (rough estimate)
    ≔ needed =
        1 + (literal_len / 255) + 1 + literal_len + 2 + ((match_len - MIN_MATCH) / 255) + 1;
    ⎇ pos + needed > output.len() {
        ⤺ Err(Error·buffer_too_small(pos + needed, output.len()));
    }

    // Write token
    output[pos] = token;
    pos += 1;

    // Write extra literal length bytes
    ⎇ literal_len >= 15 {
        ≔ Δ remaining = literal_len - 15;
        ⟳ remaining >= 255 {
            output[pos] = 255;
            pos += 1;
            remaining -= 255;
        }
        output[pos] = remaining as u8;
        pos += 1;
    }

    // Write literals
    output[pos..pos + literal_len]
        .copy_from_slice(&input[literal_start..literal_start + literal_len]);
    pos += literal_len;

    // Write ⌥ offset
    write_u16_le(output, pos, offset);
    pos += 2;

    // Write extra ⌥ length bytes
    ⎇ match_len - MIN_MATCH >= 15 {
        ≔ Δ remaining = match_len - MIN_MATCH - 15;
        ⟳ remaining >= 255 {
            output[pos] = 255;
            pos += 1;
            remaining -= 255;
        }
        output[pos] = remaining as u8;
        pos += 1;
    }

    Ok(pos)
}

/// Write final literals (no ⌥ follows).
☉ rite write_last_literals(
    input: &[u8],
    output: &Δ [u8],
    Δ pos: usize,
    literal_start: usize,
    literal_len: usize,
) -> Result<usize> {
    // Token with match_length = 0 (but we don't write offset)
    ≔ ll_token = literal_len.min(15);
    ≔ token = (ll_token << 4) as u8;

    // Check output space
    ≔ needed = 1 + (literal_len / 255) + 1 + literal_len;
    ⎇ pos + needed > output.len() {
        ⤺ Err(Error·buffer_too_small(pos + needed, output.len()));
    }

    // Write token
    output[pos] = token;
    pos += 1;

    // Write extra literal length bytes
    ⎇ literal_len >= 15 {
        ≔ Δ remaining = literal_len - 15;
        ⟳ remaining >= 255 {
            output[pos] = 255;
            pos += 1;
            remaining -= 255;
        }
        output[pos] = remaining as u8;
        pos += 1;
    }

    // Write literals
    output[pos..pos + literal_len]
        .copy_from_slice(&input[literal_start..literal_start + literal_len]);
    pos += literal_len;

    Ok(pos)
}

/// Compress input that's too small to have matches.
rite compress_literals_only(input: &[u8], output: &Δ [u8]) -> Result<usize> {
    write_last_literals(input, output, 0, 0, input.len())
}

/// Decompress LZ4 block format.
///
/// `output_size` is the expected decompressed size (must be known).
☉ rite decompress_block(input: &[u8], output: &Δ [u8], output_size: usize) -> Result<usize> {
    ≔ Δ input_pos = 0;
    ≔ Δ output_pos = 0;

    ⟳ input_pos < input.len() {
        // Read token
        ⎇ input_pos >= input.len() {
            ⤺ Err(Error·unexpected_eof(input_pos));
        }
        ≔ token = input[input_pos];
        input_pos += 1;

        ≔ Δ literal_len = (token >> 4) as usize;
        ≔ Δ match_len = (token & 0x0F) as usize;

        // Read extra literal length bytes
        ⎇ literal_len == 15 {
            loop {
                ⎇ input_pos >= input.len() {
                    ⤺ Err(Error·unexpected_eof(input_pos));
                }
                ≔ byte = input[input_pos];
                input_pos += 1;
                literal_len += byte as usize;
                ⎇ byte != 255 {
                    ⊗;
                }
            }
        }

        // Copy literals
        ⎇ literal_len > 0 {
            ⎇ input_pos + literal_len > input.len() {
                ⤺ Err(Error·unexpected_eof(input_pos));
            }
            ⎇ output_pos + literal_len > output.len() {
                ⤺ Err(Error·buffer_too_small(
                    output_pos + literal_len,
                    output.len(),
                ));
            }
            output[output_pos..output_pos + literal_len]
                .copy_from_slice(&input[input_pos..input_pos + literal_len]);
            input_pos += literal_len;
            output_pos += literal_len;
        }

        // Check ⎇ this is the last sequence (no match)
        ⎇ output_pos >= output_size {
            ⊗;
        }

        // Read ⌥ offset
        ⎇ input_pos + 2 > input.len() {
            ⤺ Err(Error·unexpected_eof(input_pos));
        }
        ≔ offset = read_u16_le(input, input_pos) as usize;
        input_pos += 2;

        ⎇ offset == 0 {
            ⤺ Err(Error·corrupted("invalid zero offset"));
        }
        ⎇ offset > output_pos {
            ⤺ Err(Error·corrupted_at("offset beyond output", output_pos));
        }

        // Read extra ⌥ length bytes
        match_len += MIN_MATCH;
        ⎇ (token & 0x0F) == 15 {
            loop {
                ⎇ input_pos >= input.len() {
                    ⤺ Err(Error·unexpected_eof(input_pos));
                }
                ≔ byte = input[input_pos];
                input_pos += 1;
                match_len += byte as usize;
                ⎇ byte != 255 {
                    ⊗;
                }
            }
        }

        // Copy ⌥ (may overlap!)
        ≔ match_start = output_pos - offset;
        ⎇ output_pos + match_len > output.len() {
            ⤺ Err(Error·buffer_too_small(
                output_pos + match_len,
                output.len(),
            ));
        }

        // Handle overlapping copy
        ⎇ offset >= match_len {
            // Non-overlapping: can invoke copy_from_slice
            output.copy_within(match_start..match_start + match_len, output_pos);
        } ⎉ {
            // Overlapping: copy byte by byte
            ∀ i ∈ 0..match_len {
                output[output_pos + i] = output[match_start + i];
            }
        }
        output_pos += match_len;
    }

    Ok(output_pos)
}

/// Calculate maximum compressed size ∀ given input length.
/// LZ4 guarantees output never exceeds this.
☉ rite max_compressed_size(input_len: usize) -> usize {
    // LZ4 formula: input_len + (input_len / 255) + 16
    input_len + (input_len / 255) + 16
}

scroll tests {
    invoke super·*;

    //@ rune: test
    rite test_empty_input() {
        ≔ input = b"";
        ≔ Δ output = vec![0u8; max_compressed_size(input.len())];
        ≔ compressed_len = compress_block(input, &Δ output).unwrap();
        assert!(compressed_len <= output.len());
    }

    //@ rune: test
    rite test_small_input() {
        ≔ input = b"Hello";
        ≔ Δ output = vec![0u8; max_compressed_size(input.len())];
        ≔ compressed_len = compress_block(input, &Δ output).unwrap();

        ≔ Δ decompressed = vec![0u8; input.len()];
        ≔ decompressed_len =
            decompress_block(&output[..compressed_len], &Δ decompressed, input.len()).unwrap();

        assert_eq!(decompressed_len, input.len());
        assert_eq!(&decompressed[..], input);
    }

    //@ rune: test
    rite test_repetitive_input() {
        ≔ input = b"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"; // 40 A's
        ≔ Δ output = vec![0u8; max_compressed_size(input.len())];
        ≔ compressed_len = compress_block(input, &Δ output).unwrap();

        // Should compress well
        assert!(compressed_len < input.len());

        ≔ Δ decompressed = vec![0u8; input.len()];
        ≔ decompressed_len =
            decompress_block(&output[..compressed_len], &Δ decompressed, input.len()).unwrap();

        assert_eq!(decompressed_len, input.len());
        assert_eq!(&decompressed[..], input);
    }

    //@ rune: test
    rite test_mixed_input() {
        ≔ input = b"Hello, World! Hello, World! Hello, World! This is a test.";
        ≔ Δ output = vec![0u8; max_compressed_size(input.len())];
        ≔ compressed_len = compress_block(input, &Δ output).unwrap();

        ≔ Δ decompressed = vec![0u8; input.len()];
        ≔ decompressed_len =
            decompress_block(&output[..compressed_len], &Δ decompressed, input.len()).unwrap();

        assert_eq!(decompressed_len, input.len());
        assert_eq!(&decompressed[..], input);
    }

    //@ rune: test
    rite test_large_input() {
        // Create input with repeating pattern
        ≔ pattern = b"The quick brown fox jumps over the lazy dog. ";
        ≔ input: Vec<u8> = pattern.iter().cycle().take(10000).copied().collect();

        ≔ Δ output = vec![0u8; max_compressed_size(input.len())];
        ≔ compressed_len = compress_block(&input, &Δ output).unwrap();

        // Should compress well
        assert!(compressed_len < input.len());

        ≔ Δ decompressed = vec![0u8; input.len()];
        ≔ decompressed_len =
            decompress_block(&output[..compressed_len], &Δ decompressed, input.len()).unwrap();

        assert_eq!(decompressed_len, input.len());
        assert_eq!(decompressed, input);
    }

    /// Test interoperability: decompress lz4_flex output with our decompressor
    //@ rune: test
    rite test_interop_decompress_lz4flex() {
        ≔ input = b"Hello, LZ4! This is a test ∀ interoperability with lz4_flex.";

        // Compress with lz4_flex
        ≔ compressed = lz4_flex·compress(input);

        // Decompress with our implementation
        ≔ Δ decompressed = vec![0u8; input.len()];
        ≔ len = decompress_block(&compressed, &Δ decompressed, input.len()).unwrap();

        assert_eq!(len, input.len());
        assert_eq!(&decompressed[..], input);
    }

    /// Test interoperability: compress with us, decompress with lz4_flex
    //@ rune: test
    rite test_interop_compress_for_lz4flex() {
        ≔ input = b"Testing compression output compatibility with lz4_flex reference.";

        // Compress with our implementation
        ≔ Δ output = vec![0u8; max_compressed_size(input.len())];
        ≔ compressed_len = compress_block(input, &Δ output).unwrap();
        ≔ compressed = &output[..compressed_len];

        // Decompress with lz4_flex
        ≔ decompressed = lz4_flex·decompress(compressed, input.len()).unwrap();

        assert_eq!(decompressed.as_slice(), input);
    }

    /// Test interop with repetitive data (exercises ⌥ copying)
    //@ rune: test
    rite test_interop_repetitive() {
        ≔ pattern = b"ABCDEFGH";
        ≔ input: Vec<u8> = pattern.iter().cycle().take(1000).copied().collect();

        // Our compress -> lz4_flex decompress
        ≔ Δ output = vec![0u8; max_compressed_size(input.len())];
        ≔ compressed_len = compress_block(&input, &Δ output).unwrap();
        ≔ decompressed = lz4_flex·decompress(&output[..compressed_len], input.len()).unwrap();
        assert_eq!(decompressed, input);

        // lz4_flex compress -> our decompress
        ≔ compressed = lz4_flex·compress(&input);
        ≔ Δ decompressed2 = vec![0u8; input.len()];
        ≔ len = decompress_block(&compressed, &Δ decompressed2, input.len()).unwrap();
        assert_eq!(len, input.len());
        assert_eq!(decompressed2, input);
    }
}
